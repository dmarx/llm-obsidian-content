---
date: 1713907694.03013
tags:
- autogenerated
- source__oai
- conversation_id__9f8c6c88-3adc-4b4b-af9c-e569eada9468
- msg_aaa231bd-abea-4655-8763-01f2026f75ea
- msg_ddc79bc9-3248-4428-99a2-6ef744f82ac5
- colorclass/energy-dissipation
title: cook's distance
---

**USER**

cook's distance


**ASSISTANT**

Cook's distance is a measure used in regression analysis to identify influential observations that might have a disproportionate impact on the calculated coefficients of a regression model. It is a diagnostic tool that helps in detecting outliers and points with high leverage that could potentially distort the results of the fit.

### Definition and Calculation

Cook's distance combines information on both the leverage of observations, as provided by the hat matrix, and the residuals from the regression to evaluate the influence of each data point. The formula for Cook's distance for the \(i\)-th observation is given by:

$$
D_i = \frac{(e_i^2)}{p \times \text{MSE}} \times \frac{h_{ii}}{(1-h_{ii})^2}
$$

where:
- \(e_i\) is the residual for the \(i\)-th observation, which is the difference between the observed value and the value predicted by the regression model.
- \(p\) is the number of regression coefficients (parameters), including the intercept.
- \(\text{MSE}\) is the [[mean squared error]] of the model.
- \(h_{ii}\) is the leverage of the \(i\)-th observation, which is the \(i\)-th diagonal element of the hat matrix \(H\).

An alternative, and often more intuitive formula for Cook's distance is based on the change in the regression coefficients when the \(i\)-th observation is omitted:

$$
D_i = \frac{\sum_{j=1}^n (\hat{y}_j - \hat{y}_{j(i)})^2}{p \times \text{MSE}}
$$

where \(\hat{y}_j\) is the predicted value with all observations included, and \(\hat{y}_{j(i)}\) is the predicted value with the \(i\)-th observation omitted.

### Interpretation

- **High Cook's Distance**: Observations with a high Cook's distance are considered to be influential, suggesting that removing the observation would markedly change the result of the regression. The threshold for "high" can vary, but a common rule of thumb is that observations with a Cook's distance greater than \(4/n\) (where \(n\) is the total number of observations) may be unduly influencing the model.

- **Combination of Leverage and Residuals**: Because Cook's distance accounts for both the leverage and the residuals, it provides a comprehensive measure of influence. High leverage points that align well with the model may not have a high Cook's distance if their residuals are small.

### Practical Usage

1. **Model Diagnostics**: After fitting a regression model, Cook's distance can be plotted for each observation. Points that stand out as having a high Cook's distance warrant closer examination and potentially could be excluded if there is justification to do so (e.g., data entry errors, measurement errors).

2. **Robustness Checks**: By identifying influential points, analysts can check the robustness of their model's conclusions. Removing these points and refitting the model can provide insights into how sensitive the model is to specific data points.

3. **Outlier Detection**: While Cook's distance is primarily a measure of influence and not exactly an outlier detection tool, high values may coincide with outliers, particularly those that not only deviate from the norm but also leverage sufficient influence to skew the model.

### Conclusion

Cook's distance is an essential tool in the repertoire of regression analysis techniques, providing critical insights into the data's influence on statistical models. By identifying and examining influential observations, analysts can ensure the integrity and reliability of their analyses. In advanced applications, combining Cook's distance with other diagnostics like DFBETAS, DFFITS, and studentized residuals can give a comprehensive view of potential data issues and model vulnerabilities.


---

preceding: [[hat matrix]]  


following: [[studentized residuals]]