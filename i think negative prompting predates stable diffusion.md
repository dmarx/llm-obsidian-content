---
date: '2025-06-22T07:58:44.769306Z'
tags:
- autogenerated
- source__claude
- conversation_id__8fcecd0f-193e-4b76-b760-649e0798cf8e
- msg_aadf1f24-15e0-416d-9554-0059a2e70d4d
- msg_83b95075-8122-4bc9-9a62-505b5ec96874
- colorclass/information-theory
title: i think negative prompting predates stable diffusion
---

**USER**

i think [[negative prompting]] predates stable diffusion


**ASSISTANT**

That's a really interesting claim. Let me think about this. The user is suggesting that [[negative prompting]] predates Stable Diffusion, which was released in August 2022. If this is true, it would mean that the technique existed before the popular implementation in AUTOMATIC1111's interface and before Stable Diffusion became widely available.

Let me think about what we know:
1. Classifier-Free Guidance was introduced by Ho & Salimans in 2021
2. The mathematical foundation for [[negative prompting]] is essentially using negative weights in CFG
3. There were earlier diffusion models and research before Stable Diffusion
4. Katherine Crowson was working on diffusion models and k-diffusion
5. There were earlier text-to-image models like VQGAN+CLIP

The user might be onto something. If [[negative prompting]] is just a natural extension of CFG with negative weights, it's quite possible that researchers were experimenting with this much earlier, perhaps in:
- VQGAN+CLIP implementations
- Earlier diffusion model research
- CLIP-guided generation
- Other text-to-image systems

Let me search for evidence of [[negative prompting]] or negative conditioning in earlier systems before Stable Diffusion.
```
This block is not supported on your current device yet.
```

Excellent! This is exactly what I was looking for. The search results clearly show that [[negative prompting]] existed in VQGAN+CLIP implementations well before Stable Diffusion was released. Let me look at the key evidence:

1. From Max Woolf's blog post from August 18, 2021 (well before Stable Diffusion's August 2022 release): "Lastly, we can use negative weights for prompts such that the model targets the opposite of that prompt. Let's do the opposite of green and white to see if the AI tries to remove those two colors from the palette and maybe make the final image more cyberpunky. cyberpunk forest by Salvador Dali:3 | artstationHQ | green and white:-1"

2. From the Unlimited Dream Co guide: "You can mitigate these effects by using zero or negative prompt weighting, for example by adding 'face:0' or 'face:-1' to stop CLIP from creating faces, but it's not always successful."

This clearly shows that [[negative prompting]] was already a known technique in the VQGAN+CLIP community in 2021, a full year before Stable Diffusion was released. The user is absolutely correct!

This is actually a really important correction to the historical record. It shows that [[negative prompting]] wasn't invented by AUTOMATIC1111 for Stable Diffusion, but rather was already a established technique in the earlier VQGAN+CLIP ecosystem.You are **absolutely correct**! The evidence clearly shows that [[negative prompting]] predated Stable Diffusion by at least a year.

## VQGAN+CLIP Origins (2021)

Max Woolf's blog post from August 18, 2021 explicitly demonstrates [[negative prompting]]: "Lastly, we can use negative weights for prompts such that the model targets the opposite of that prompt. Let's do the opposite of green and white to see if the AI tries to remove those two colors from the palette and maybe make the final image more cyberpunky. cyberpunk forest by Salvador Dali:3 | artstationHQ | green and white:-1"

The Unlimited Dream Co guides also document the technique: "You can mitigate these effects by using zero or negative prompt weighting, for example by adding 'face:0' or 'face:-1' to stop CLIP from creating faces, but it's not always successful."

## Timeline Correction

- **2021**: VQGAN+CLIP implementations already featured [[negative prompting]] with syntax like `green and white:-1`
- **August 2022**: Stable Diffusion released
- **Late 2022**: AUTOMATIC1111 implemented [[negative prompting]] in Stable Diffusion WebUI

## The Real Innovation

AUTOMATIC1111's contribution wasn't **inventing** [[negative prompting]], but rather:
1. **Adapting** the existing VQGAN+CLIP technique to Classifier-Free Guidance
2. **Implementing** it as a separate interface element rather than inline syntax
3. **Popularizing** it through the most widely-used Stable Diffusion interface

## Community Knowledge Transfer

This reveals how techniques **migrated** from the earlier VQGAN+CLIP community into the Stable Diffusion ecosystem. The mathematical foundation was already understood - using negative weights to steer generation away from unwanted concepts.

Your insight highlights an important pattern in AI development: how **community knowledge** evolves across different model architectures. The technique that became "[[negative prompting]]" in Stable Diffusion was already an established practice in the VQGAN+CLIP community, demonstrating the continuity of ideas across the rapidly evolving landscape of text-to-image generation.

This correction significantly changes the attribution story - [[negative prompting]] should be credited to the **VQGAN+CLIP community** circa 2021, not to AUTOMATIC1111's 2022 implementation.


---

preceding: [[i have a hunch that maybe this originated from the eleutherlaion open source ml research community]]  


following: [[are we sure katherine crowson didn't demonstrate this first i feel like this is the sort of thing that she might've posted about on twitter and never been properly cited for]]

See also: [[negative prompting]]


See also: [[diffusion models]]