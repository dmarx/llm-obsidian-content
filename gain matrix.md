---
date: 1717810139.972169
tags:
- autogenerated
- source__oai
- conversation_id__77e70e10-f02a-4f98-bd5c-6217b10122cf
- msg_aaa255cb-4a13-41db-97b5-a4ebec9427c2
- msg_f840519f-17a2-499b-90ce-169cef2bb53e
- colorclass/system-dynamics
title: gain matrix
---

**USER**

gain matrix


**ASSISTANT**

In the context of the Linear Quadratic Regulator (LQR) problem, the gain matrix \( K \) is a crucial component of the optimal control law. It determines how the state vector \( \mathbf{x}(t) \) is mapped to the control input \( \mathbf{u}(t) \) to minimize the quadratic cost function. 

### LQR Problem Recap

Consider the linear time-invariant system described by:
\[ \dot{\mathbf{x}}(t) = A\mathbf{x}(t) + B\mathbf{u}(t), \]
where:
- \(\mathbf{x}(t) \in \mathbb{R}^n\) is the state vector,
- \(\mathbf{u}(t) \in \mathbb{R}^m\) is the control input,
- \(A \in \mathbb{R}^{n \times n}\) is the system matrix,
- \(B \in \mathbb{R}^{n \times m}\) is the input matrix.

The objective is to minimize the cost function:
\[ J = \int_{0}^{\infty} \left( \mathbf{x}(t)^T Q \mathbf{x}(t) + \mathbf{u}(t)^T R \mathbf{u}(t) \right) dt, \]
where:
- \(Q \in \mathbb{R}^{n \times n}\) is a symmetric positive semi-definite matrix (state weighting matrix),
- \(R \in \mathbb{R}^{m \times m}\) is a symmetric positive definite matrix (control weighting matrix).

### Optimal Control Law

The optimal control law for the LQR problem is a state feedback law of the form:
\[ \mathbf{u}^*(t) = -K \mathbf{x}(t), \]
where \( K \) is the optimal feedback gain matrix.

### Computing the Gain Matrix \( K \)

The gain matrix \( K \) is computed using the solution \( P \) to the Algebraic Riccati Equation (ARE):

\[ A^T P + P A - P B R^{-1} B^T P + Q = 0, \]

Once \( P \) is found, the optimal gain matrix \( K \) is given by:

\[ K = R^{-1} B^T P. \]

### Example

Let's go through an example to compute the gain matrix \( K \).

Consider a system with:
\[ A = \begin{bmatrix} 0 & 1 \\ 0 & -1 \end{bmatrix}, \quad B = \begin{bmatrix} 0 \\ 1 \end{bmatrix}, \quad Q = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}, \quad R = \begin{bmatrix} 1 \end{bmatrix}. \]

1. **Formulate the ARE**:
   \[ A^T P + P A - P B R^{-1} B^T P + Q = 0. \]

2. **Solve the ARE**:
   This can be done numerically using software tools like MATLAB, SciPy in Python, or other specialized software. Here, we will use Python with SciPy:

```python
import numpy as np
from scipy.linalg import solve_continuous_are
from scipy.linalg import inv

# Define system matrices
A = np.array([[0, 1],
              [0, -1]])
B = np.array([[0],
              [1]])
Q = np.array([[1, 0],
              [0, 1]])
R = np.array([[1]])

# Solve the continuous-time Algebraic Riccati Equation (ARE)
P = solve_continuous_are(A, B, Q, R)

# Compute the LQR gain
K = inv(R).dot(B.T).dot(P)

print("Optimal gain matrix K:")
print(K)
```

### Explanation of Output

- **Matrix \( P \)**: The solution to the ARE, which encapsulates the trade-offs between state deviations and control effort.
- **Matrix \( K \)**: The gain matrix that determines the control input based on the current state. It is computed as \( K = R^{-1} B^T P \).

### Properties of the Gain Matrix

1. **Stabilizing**: The gain matrix \( K \) ensures that the closed-loop system \(\dot{\mathbf{x}}(t) = (A - BK)\mathbf{x}(t)\) is stable.
2. **Optimality**: The gain matrix \( K \) minimizes the quadratic cost function \( J \), achieving the best trade-off between the state deviations and control effort as specified by the matrices \( Q \) and \( R \).

### Practical Considerations

1. **Weighting Matrices \( Q \) and \( R \)**:
   - **\( Q \)**: Penalizes deviations of the state variables. Higher values in \( Q \) indicate that certain state variables are more critical and should be kept small.
   - **\( R \)**: Penalizes the control effort. Higher values in \( R \) indicate a preference for using less control input.

2. **Choosing \( Q \) and \( R \)**:
   - The choice of \( Q \) and \( R \) reflects the relative importance of state deviations versus control effort. These matrices must be chosen based on the specific requirements and constraints of the problem.

3. **Numerical Stability and Solvers**:
   - Solving the ARE numerically can be sensitive to the problem's conditioning. It is important to use reliable numerical solvers and validate the results.

### Conclusion

The gain matrix \( K \) in the LQR problem is a fundamental component that maps the state vector to the control input, ensuring optimal performance by minimizing a quadratic cost function. By solving the Algebraic Riccati Equation, the gain matrix can be computed efficiently, providing a robust and effective control law for linear systems. Understanding and implementing the LQR method is crucial for designing optimal controllers in various engineering and control applications.


---

preceding: [[linear quadratic regulator]]  


following: [[algebraic riccati equation]]

See also: [[technology adoption modeling using the shifted gompertz]]


See also: [[sliding mode control]]


See also: [[linear quadratic regulator (lqr)]]


See also: [[lyapunov-based methods in adaptive control]]


See also: [[adaptation mechanisms in adaptive control]]


See also: [[desirable states as attractors]]


See also: [[state feedback control]]


See also: [[ocs method (ott, grebogi, yorke method)]]


See also: [[observer design]]


See also: [[pole placement]]


See also: [[self-tuning regulators (str)]]


See also: [[control law design]]


See also: [[ontology of control theory]]


See also: [[multi-input, multi-output (mimo) systems]]