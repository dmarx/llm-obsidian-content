---
date: 1732950517.877
tags:
- autogenerated
- source__oai
- conversation_id__674ab96e-0030-8008-811b-df1a12b1e598
- msg_aaa29338-ec7e-4e98-9539-3aba0eb74d68
- msg_6d852591-d4d2-4041-92b0-e6884d971564
- colorclass/information-theory
title: kolmogorov complexity
---

**USER**

kolmogorov complexity


**ASSISTANT**

### Kolmogorov Complexity

**Kolmogorov Complexity** (or **Algorithmic Complexity**) is a measure of the informational content of a finite object, typically a string, defined as the length of the shortest description of that object in a fixed computational framework. It formalizes the idea of "simplicity" and "compressibility" and is central to [[Algorithmic Information Theory]].

---

### Definition

Let \( U \) be a universal Turing machine. The **Kolmogorov complexity** of a string \( x \), denoted \( K(x) \), is the length of the shortest binary program \( p \) that generates \( x \) when run on \( U \) and then halts:
$$
K(x) = \min \{|p| : U(p) = x\}.
$$

Here, \( |p| \) represents the length of the program \( p \) in bits.

---

### Key Properties

1. **Machine Independence**
   The complexity \( K(x) \) depends on the choice of the universal Turing machine \( U \), but only up to an additive constant. This is captured by the **Invariance Theorem**:
   $$
   |K_U(x) - K_V(x)| \leq c,
   $$
   where \( c \) is a constant depending on the universality of \( U \) and \( V \).

2. **Non-Computability**
   Kolmogorov complexity is not computable because there is no algorithm to determine the shortest program \( p \) for an arbitrary \( x \). This is a direct consequence of the [[Halting Problem]].

3. **Compressibility**
   - A string \( x \) is **compressible** if \( K(x) < |x| \), meaning that \( x \) can be described by a shorter program.
   - A string is **incompressible** if \( K(x) \approx |x| \), meaning it is algorithmically random and cannot be described more succinctly than its explicit representation.

4. **Prefix-Free Kolmogorov Complexity**
   The **prefix-free Kolmogorov complexity**, \( K_{\text{prefix}}(x) \), restricts programs \( p \) such that no valid program is a prefix of another. This ensures a unique decodability and aligns with [[Kraft's Inequality]].

---

### Types of Kolmogorov Complexity

1. **Unconditional Complexity \( K(x) \):**
   The shortest program to generate \( x \).

2. **Conditional Complexity \( K(x \mid y) \):**
   The complexity of \( x \) given auxiliary information \( y \). Formally:
   $$
   K(x \mid y) = \min \{|p| : U(p, y) = x\}.
   $$

3. **Joint Complexity \( K(x, y) \):**
   The complexity of \( x \) and \( y \) treated as a single string:
   $$
   K(x, y) = \min \{|p| : U(p) = (x, y)\}.
   $$

4. **Mutual Information \( I(x : y) \):**
   The shared information between \( x \) and \( y \), defined as:
   $$
   I(x : y) = K(x) + K(y) - K(x, y).
   $$

---

### Examples and Intuition

1. **Highly Compressible Strings:**
   The string \( x = 000\ldots0 \) (100 zeros) has low complexity, as it can be described succinctly:
   $$
   K(x) \approx \log_2(100) + c,
   $$
   where \( c \) is the cost of encoding the program structure.

2. **Random Strings:**
   A string of 100 random bits \( x = 101010\ldots \) has \( K(x) \approx 100 \), as no shorter description exists.

3. **Structured Strings:**
   A string \( x = \text{"ABABABABAB"} \) (10 repetitions of "AB") has \( K(x) \ll |x| \), since the pattern "AB" and its repetition can be encoded compactly.

---

### Applications

1. **Data Compression**
   Kolmogorov complexity establishes theoretical limits for lossless compression. An optimal compressor approximates \( K(x) \).

2. **Randomness**
   Algorithmic randomness is defined in terms of incompressibility: a string \( x \) is random if \( K(x) \approx |x| \).

3. **Occam’s Razor**
   In science and machine learning, simpler models (low \( K(x) \)) are preferred unless complexity is justified by explanatory power.

4. **Minimum Description Length Principle**
   Kolmogorov complexity underpins the [[Minimum Description Length Principle]], which optimizes data encoding and model selection.

---

### Limitations and Extensions

1. **Non-Computability**
   While theoretically insightful, \( K(x) \) cannot be directly computed, limiting practical application without approximations.

2. **Resource-Bounded Complexity**
   Extensions like time-bounded Kolmogorov complexity, \( K^t(x) \), restrict the computation time of the generating program.

3. **Quantum Kolmogorov Complexity**
   This generalizes \( K(x) \) to quantum systems, where complexity is measured using quantum Turing machines.

Kolmogorov complexity is a cornerstone of [[Algorithmic Information Theory]], providing profound insights into the structure and randomness of data, and linking computation, information, and probability in a rigorous mathematical framework.


---

preceding: [[algorithmic information theory (ait)]]  


following: [[martin-löf randomness]]---
date: 1715185051.270903
tags:
- autogenerated
- source__oai
- conversation_id__e5835629-6c5f-4dfb-8760-4d9d50c3520d
- msg_aaa2b563-7592-46ae-ab31-80a7060dee8c
- msg_1352dd5a-1d17-4aa1-a6ec-ee93405e024c
title: kolmogorov complexity
---


**USER**

kolmogorov complexity


**ASSISTANT**

### Kolmogorov Complexity

Kolmogorov complexity, also known as algorithmic complexity or descriptive complexity, is a measure of the computational resources needed to specify a given string or a data object (such as a file or an image). The concept is named after Andrey Kolmogorov, who introduced it in the 1960s. It is a fundamental concept in the theory of computation, information theory, and complexity theory.

#### Definition

The Kolmogorov complexity $K(x)$ of a string $x$ is defined as the length of the shortest possible description of $x$ in some fixed universal description language. More formally, if $\{U\}$ is a universal Turing machine, then $K(x)$ is defined as:

$$K(x) = \min\{ |p| : U(p) = x \}$$

Here, $|p|$ denotes the length of the program $p$ when encoded in a fixed universal Turing machine's language, and $U(p) = x$ indicates that the Turing machine $U$, when running program $p$, outputs string $x$.

#### Properties

1. **Uncomputability**: One of the pivotal properties of Kolmogorov complexity is that it is uncomputable. This means there is no general algorithm that can compute the exact Kolmogorov complexity $K(x)$ for any arbitrary string $x$. This is primarily due to the halting problem.

2. **Invariance Theorem**: While the value of $K(x)$ depends on the choice of the universal machine $U$, the invariance theorem states that for any two universal Turing machines $U$ and $V$, there exists a constant $c$ such that for all strings $x$,

   $$|K_U(x) - K_V(x)| \leq c$$

   This property ensures that the Kolmogorov complexity is machine-independent up to an additive constant and thus provides a robust measure of complexity.

3. **Application to Randomness**: A string $x$ is considered to be algorithmically random if $K(x) \approx |x|$, which means no shorter description of $x$ exists than $x$ itself. Such strings are also called Kolmogorov random.

#### Applications

Kolmogorov complexity has numerous applications across different fields:
- **Information Theory**: It provides a theoretical foundation for understanding the amount of information in a data object.
- **Cryptography**: Analysis of the randomness properties of cryptographic keys.
- **Machine Learning**: Used in model selection, where simpler models (with lower complexity) are preferred under the principle of Occam's Razor.
- **Philosophy of Science**: It offers insights into the theory of scientific explanation, supporting a preference for simpler theories over more complex ones.

#### Limitations

Despite its theoretical importance, the uncomputability of Kolmogorov complexity limits its practical applications. Approximations and bounded versions of complexity, such as resource-bounded complexity, are often used in practical scenarios.

For more detailed exploration, one might consider reviewing related topics like [[Algorithmic Information Theory]], [[Turing Machines]], and [[Universal Turing Machine|universal computation models]] in computational theory.

See also: [[modeling as notational compression]]


See also: [[algorithmic information theory]]


See also: [[information theory]]