---
date: '2025-06-07T16:47:00.853516Z'
tags:
- autogenerated
- source__claude
- conversation_id__6482c91e-50e7-4cea-aa76-40451ddf3faf
- msg_8f70ca5e-b420-4f88-b26f-20c9f5c2ff0c
- msg_435fd3b0-5f41-4c99-b271-e828fe03df9a
- colorclass/informed-decision
title: fsdp vs megatron tp+pp
---

**USER**

fsdp vs megatron tp+pp


**ASSISTANT**

The user wants a wiki-style technical comparison between FSDP and Megatron's tensor parallelism (TP) + pipeline parallelism (PP) approach. This should be written as a standalone wiki article with deep technical detail, mathematical formalism, and no conversational elements.

I need to cover:
1. Mathematical framework for both approaches
2. Memory scaling analysis
3. Communication patterns and complexity
4. Performance characteristics
5. Implementation trade-offs
6. When to use which approach

The user has graduate degrees in applied math and stats, so I should use rigorous mathematical notation and provide detailed analysis.# FSDP vs Megatron Tensor Parallelism + Pipeline Parallelism

A comprehensive analysis comparing **[[Fully Sharded Data Parallel]] (FSDP)** with **[[Megatron]]'s combined [[Tensor Parallelism]] (TP) and [[Pipeline Parallelism]] (PP)** approaches for large-scale neural network training.

## Mathematical Framework Comparison

### FSDP Parameter Distribution

In FSDP, the complete parameter tensor $\Theta \in \mathbb{R}^d$ is sharded across $P$ devices:

$$\mathcal{S}_{\text{FSDP}}(\Theta) = \{\Theta^{(1)}, \Theta^{(2)}, \ldots, \Theta^{(P)}\}$$

where $\bigcup_{i=1}^P \Theta^{(i)} = \Theta$ and $|\Theta^{(i)}| \approx \frac{d}{P}$.

### Megatron TP+PP Distribution

Megatron employs a two-dimensional decomposition. For a model with $L$ layers organized into $P_p$ pipeline stages and $P_t$ tensor parallel groups:

**Pipeline Dimension**: $\mathcal{P}_{\text{pipe}}: \{1, 2, \ldots, L\} \rightarrow \{1, 2, \ldots, P_p\}$

**Tensor Dimension**: For each linear transformation $W \in \mathbb{R}^{m \times n}$:
$$\mathcal{T}_{\text{col}}(W) = [W^{(1)}, W^{(2)}, \ldots, W^{(P_t)}] \text{ where } W^{(i)} \in \mathbb{R}^{m \times \frac{n}{P_t}}$$

$$\mathcal{T}_{\text{row}}(W) = \begin{bmatrix} W^{(1)} \\ W^{(2)} \\ \vdots \\ W^{(P_t)} \end{bmatrix} \text{ where } W^{(i)} \in \mathbb{R}^{\frac{m}{P_t} \times n}$$

Total device count: $P = P_p \times P_t$

## Memory Scaling Analysis

### Per-Device Memory Requirements

**FSDP Memory Profile**:
$$M_{\text{FSDP}} = \underbrace{\frac{d}{P}}_{\text{params}} + \underbrace{\frac{d}{P}}_{\text{gradients}} + \underbrace{\frac{2d}{P}}_{\text{optimizer}} + \underbrace{A}_{\text{activations}} + \underbrace{d \cdot \tau}_{\text{temp reconstruction}}$$

where $\tau \in [0,1]$ represents the fraction of model temporarily reconstructed.

**Megatron TP+PP Memory Profile**:
$$M_{\text{Megatron}} = \underbrace{\frac{d}{P_t \cdot P_p}}_{\text{params}} + \underbrace{\frac{d}{P_t \cdot P_p}}_{\text{gradients}} + \underbrace{\frac{2d}{P_t \cdot P_p}}_{\text{optimizer}} + \underbrace{\frac{A}{P_t}}_{\text{activations}} + \underbrace{0}_{\text{reconstruction}}$$

### Memory Efficiency Ratio

The memory efficiency of Megatron relative to FSDP is:

$$\eta_{\text{memory}} = \frac{M_{\text{FSDP}}}{M_{\text{Megatron}}} = \frac{4\frac{d}{P} + A + d \cdot \tau}{4\frac{d}{P} + \frac{A}{P_t}}$$

For activation-dominated regimes ($A \gg \frac{d}{P}$):
$$\eta_{\text{memory}} \approx P_t \quad \text{(Megatron advantage)}$$

For parameter-dominated regimes ($\frac{d}{P} \gg A$):
$$\eta_{\text{memory}} \approx 1 + \frac{P \cdot \tau}{4} \quad \text{(FSDP disadvantage due to reconstruction)}$$

## Communication Complexity Analysis

### FSDP Communication Pattern

**Per Training Step**:
- **All-gather phase**: $C_{\text{AG}} = d \cdot s \cdot \log_2(P)$
- **Reduce-scatter phase**: $C_{\text{RS}} = d \cdot s \cdot \log_2(P)$
- **Total**: $C_{\text{FSDP}} = 2d \cdot s \cdot \log_2(P)$

where $s$ is the size of the data type in bytes.

### Megatron TP+PP Communication Pattern

**Tensor Parallelism Communication** (per layer):
- **All-reduce**: $C_{\text{AR}} = 2h^2 \cdot s \cdot \log_2(P_t)$
- **All-gather**: $C_{\text{AG}} = h^2 \cdot s \cdot \log_2(P_t)$

where $h$ is the hidden dimension.

**Pipeline Parallelism Communication**:
- **Point-to-point**: $C_{\text{P2P}} = 2 \cdot B \cdot h \cdot s$

where $B$ is the micro-batch size.

**Total Megatron Communication**:
$$C_{\text{Megatron}} = L \cdot (3h^2 \cdot s \cdot \log_2(P_t)) + 2 \cdot B \cdot h \cdot s \cdot P_p$$

### Communication Scaling Comparison

For transformer models where $d \approx L \cdot h^2$:

$$\frac{C_{\text{FSDP}}}{C_{\text{Megatron}}} \approx \frac{2 \log_2(P)}{3 \log_2(P_t) + \frac{2BhP_p}{Lh^2}}$$

In the parameter-dominated regime ($Lh \gg BP_p$):
$$\frac{C_{\text{FSDP}}}{C_{\text{Megatron}}} \approx \frac{2 \log_2(P)}{3 \log_2(P_t)}$$

## Computational Efficiency Metrics

### Pipeline Bubble Analysis

Pipeline parallelism introduces **bubble overhead** during the ramp-up and ramp-down phases:

$$\text{Bubble Ratio} = \frac{(P_p - 1) \cdot t_{\text{micro}}}{P_p \cdot m \cdot t_{\text{micro}}} = \frac{P_p - 1}{P_p \cdot m}$$

where $m$ is the number of micro-batches and $t_{\text{micro}}$ is the micro-batch computation time.

For efficiency $\geq 90\%$: $m \geq \frac{10(P_p - 1)}{P_p}$

### Load Balancing Constraints

**FSDP Load Balance**: Naturally balanced due to uniform parameter sharding.

**Megatron Load Balance**: Requires:
1. **Pipeline balance**: $\max_i(T_i) - \min_i(T_i) \leq \epsilon \cdot \bar{T}$
2. **Tensor balance**: Matrix dimensions must be divisible by $P_t$

where $T_i$ is the computation time for pipeline stage $i$.

## Scalability Analysis

### Strong Scaling Characteristics

**FSDP Strong Scaling**:
$$T_{\text{FSDP}}(P) = \frac{T_{\text{comp}}}{P} + T_{\text{comm}} \cdot \log_2(P)$$

**Megatron Strong Scaling**:
$$T_{\text{Megatron}}(P_t, P_p) = \frac{T_{\text{comp}}}{P_t \cdot P_p} + T_{\text{comm}}^{TP} \cdot \log_2(P_t) + T_{\text{comm}}^{PP} + T_{\text{bubble}}$$

### Optimal Parallelization Strategy

For a fixed total device count $P = P_t \times P_p$, the optimal configuration minimizes:

$$\mathcal{L}(P_t, P_p) = \frac{\alpha}{P_t \cdot P_p} + \beta \log_2(P_t) + \gamma P_p + \delta \frac{P_p}{m}$$

where $\alpha, \beta, \gamma, \delta$ are model-dependent constants.

Taking partial derivatives:
$$\frac{\partial \mathcal{L}}{\partial P_t} = -\frac{\alpha}{P_t^2 \cdot P_p} + \frac{\beta}{P_t \ln(2)} = 0$$

$$\frac{\partial \mathcal{L}}{\partial P_p} = -\frac{\alpha}{P_t \cdot P_p^2} + \gamma + \frac{\delta}{m} = 0$$

## Implementation Complexity Matrix

| Aspect | FSDP | Megatron TP+PP |
|--------|------|----------------|
| **Code Complexity** | $\mathcal{O}(1)$ | $\mathcal{O}(L \times C)$ |
| **Debugging Difficulty** | Low | High |
| **Model Architecture Constraints** | None | [[Transformer-specific]] |
| **Communication Topology** | Ring/Tree | 2D Mesh |
| **Fault Tolerance** | High | Low (pipeline fragility) |

where $L$ is the number of layers and $C$ is the model complexity factor.

## Performance Regimes

### FSDP-Favorable Conditions

$$\text{FSDP Optimal when: } \begin{cases}
P_t^* < 4 & \text{(small tensor parallel benefit)} \\
\frac{A}{d/P} > 2 & \text{(activation-dominated)} \\
\text{Model irregular} & \text{(non-transformer architectures)}
\end{cases}$$

### Megatron-Favorable Conditions

$$\text{Megatron Optimal when: } \begin{cases}
P_t^* \geq 8 & \text{(large tensor parallel benefit)} \\
\frac{d/P}{A} > 4 & \text{(parameter-dominated)} \\
m \geq 4P_p & \text{(sufficient micro-batches)}
\end{cases}$$

## Hybrid Strategies

### FSDP + Tensor Parallelism

Combine FSDP parameter sharding with limited tensor parallelism:

$$\Theta^{(i,j)} = \text{FSDP-shard}_i(\text{TP-shard}_j(\Theta))$$

**Memory scaling**: $M \propto \frac{d}{P_{\text{fsdp}} \times P_t}$
**Communication**: $C = C_{\text{FSDP}} + C_{\text{TP}}$

### Optimal Hybrid Configuration

For total devices $P = P_{\text{fsdp}} \times P_t$:

$$P_t^* = \min\left(\arg\min_{P_t} \frac{C_{\text{total}}(P_t)}{B_{\text{eff}}(P_t)}, \frac{h}{\text{min-tensor-size}}\right)$$

where $B_{\text{eff}}$ represents effective bandwidth utilization.

## Convergence Properties

### Mathematical Equivalence

Both approaches maintain gradient unbiasedness:

$$\mathbb{E}[\nabla_{\text{FSDP}} \mathcal{L}] = \mathbb{E}[\nabla_{\text{Megatron}} \mathcal{L}] = \nabla \mathcal{L}$$

### Numerical Precision Effects

**FSDP precision**: Uniform across all parameters
**Megatron precision**: May vary between tensor and pipeline dimensions due to different reduction patterns

$$\sigma^2_{\text{numerical}} \propto \begin{cases}
\frac{1}{P} & \text{FSDP} \\
\frac{1}{P_t} + \epsilon_{\text{pipeline}} & \text{Megatron}
\end{cases}$$

## Decision Framework

### Selection Criteria Matrix

$$\text{Strategy} = \arg\max_{s \in \{\text{FSDP}, \text{Megatron}, \text{Hybrid}\}} \mathcal{U}(s)$$

where the utility function incorporates:

$$\mathcal{U}(s) = w_1 \cdot \text{Throughput}(s) - w_2 \cdot \text{Memory}(s) - w_3 \cdot \text{Complexity}(s)$$

The optimal choice depends on the specific ratios of model size, available memory, network topology, and engineering constraints.


---

preceding: [[fsdp]]  


following: [[jax fsdp (on gpu clusters)]]

See also: [[partial derivatives]]