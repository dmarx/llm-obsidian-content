---
date: '2025-02-23T19:20:57.500136Z'
tags:
- autogenerated
- source__claude
- conversation_id__c070c5c2-d023-4efc-b584-890b0a667e02
- msg_bb384690-0615-4af5-a7cf-c0bb47c989f9
- msg_d72058b9-b054-499e-9019-91ed5238c0e6
- colorclass/information-theory
title: information geometry
---

**USER**

Information Geometry


**ASSISTANT**

# Information Geometry

[[Information Geometry]] provides a geometric framework for studying statistical manifolds and information structures, applying differential geometric methods to probability theory and information theory.

## Mathematical Foundation

### Statistical Manifold

A [[statistical manifold]] $\mathcal{S}$ is defined as:

$\mathcal{S} = \{p_\theta(x) | \theta \in \Theta\}$

where:
- $p_\theta(x)$ is a probability distribution
- $\theta$ represents the parameters
- $\Theta$ is the parameter space

### Fisher-Rao Metric

The [[Fisher-Rao metric]] $g_{ij}(\theta)$ is defined as:

$g_{ij}(\theta) = \mathbb{E}_{p_\theta}\left[\frac{\partial \log p_\theta}{\partial \theta^i}\frac{\partial \log p_\theta}{\partial \theta^j}\right]$

This metric is the unique Riemannian metric invariant under sufficient statistics.

## Connections and Curvature

### α-Connections

The [[α-connection]] $\nabla^{(\alpha)}$ is defined by its coefficients:

$\Gamma_{ij,k}^{(\alpha)} = \mathbb{E}_{p_\theta}\left[\frac{\partial^2 \log p_\theta}{\partial \theta^i \partial \theta^j}\frac{\partial \log p_\theta}{\partial \theta^k} + \frac{1-\alpha}{2}\frac{\partial \log p_\theta}{\partial \theta^i}\frac{\partial \log p_\theta}{\partial \theta^j}\frac{\partial \log p_\theta}{\partial \theta^k}\right]$

Special cases:
- $\alpha = 1$: [[e-connection]]
- $\alpha = -1$: [[m-connection]]
- $\alpha = 0$: [[Levi-Civita connection]]

### Dualistic Structure

The [[dual structure]] $(g, \nabla^{(\alpha)}, \nabla^{(-\alpha)})$ satisfies:

$X g(Y,Z) = g(\nabla^{(\alpha)}_X Y,Z) + g(Y,\nabla^{(-\alpha)}_X Z)$

## Divergence Measures

### Bregman Divergence

The [[Bregman divergence]] is:

$D_F(p||q) = F(p) - F(q) - \langle \nabla F(q), p-q \rangle$

where $F$ is a strictly convex function.

### f-Divergence

The [[f-divergence]] family:

$D_f(p||q) = \int q(x)f\left(\frac{p(x)}{q(x)}\right)dx$

where $f$ is a convex function with $f(1)=0$.

## Applications

1. [[Statistical Inference]]
2. [[Machine Learning]]
3. [[Information Theory]]
4. [[Quantum Information]]

### Optimization on Manifolds

The [[natural gradient]] method:

$\theta_{t+1} = \theta_t - \eta g^{ij}(\theta_t)\frac{\partial L}{\partial \theta^j}$

where $g^{ij}$ is the inverse Fisher-Rao metric.

## Advanced Topics

### Tensorial Structures

The [[information tensor]]:

$T_{ijk}(\theta) = \mathbb{E}_{p_\theta}\left[\frac{\partial \log p_\theta}{\partial \theta^i}\frac{\partial \log p_\theta}{\partial \theta^j}\frac{\partial \log p_\theta}{\partial \theta^k}\right]$

### Quantum Extensions

The [[quantum information geometry]] extends to density matrices:

$g_{ij}(\rho) = \text{Tr}\left[\rho(L_i L_j + L_j L_i)/2\right]$

where $L_i$ are symmetric logarithmic derivatives.

## Research Directions

1. [[Infinite-Dimensional Extensions]]
2. [[Non-parametric Information Geometry]]
3. [[Geometric Deep Learning]]
4. [[Quantum Statistical Manifolds]]

Information Geometry continues to provide insights into the geometric structure of probability and information.


---

preceding: [[multi-scale embedding]]  


following: [[information gainedlost in scale transition]]

See also: [[dual affine connections in information geometry]]


See also: [[what is the class of spaces that is used for analysis of geometric and topological properties of statistical divergences like kl-divergence]]


See also: [[geometric interpretation of conditional entropy]]


See also: [[affine connections fundamentals and applications]]


See also: [[tell me more about information geometry]]


See also: [[geometric interpretation of mutual information]]


See also: [[what might we be able to learn by applying principles of ricci curvature analysis to clip space what might be consequences for the interpretation of the fim]]


See also: [[hint consider fitting a model from the perspective of a path through parameter space. what path minimizes action in the space]]


See also: [[in the moment parameter space, these paths represent different statistical properties.]]


See also: [[invariance under reparameterization is related to noether's theorem]]


See also: [[skip to main content]]


See also: [[fisher information and differential geometry]]


See also: [[potential function and fisher information metric]]


See also: [[probability theory]]


See also: [[replicator dynamics]]


See also: [[dual structures are particularly prominent in the study of exponential and mixture families of distributions, which form dual pairs on a statistical manifold. the natural parameter space of an exponen]]


See also: [[information geometry and the space of positive definite matrices]]


See also: [[non-extensive statistical mechanics]]


See also: [[dual spaces fundamentals and mathematical insight]]


See also: [[fisher information metric endows a statistical manifold with a riemannian metric and provides a natural way to measure distances and angles between probability distributions on the manifold, faci]]


See also: [[dual spaces in information geometry]]


See also: [[information theory]]


See also: [[sufficient statistic]]


See also: [[relate the fisher information matrix to the lagrangian]]


See also: [[what about topological or geometric features we can infer based on these relations]]


See also: [[principal geodesic analysis (pga)]]


See also: [[dually flat manifold structure in binary choice models]]


See also: [[what about topological or geometric invariants we can infer based on these relations]]


See also: [[revisit the relationship between variance explained and least action, taking into consideration the relationship between the fisher information matrix and the lagrangian]]


See also: [[invariance under parameter transformations in a statistical model is related to the conservation of information along geodesics, reflecting a symmetry principle at work.]]


See also: [[consider a model f that maps events x in x to a probability y in y. consider a reparameterization of x-x' (change of basis), and a model g parameterized wrt x' that maps events x' in x' to y in y. if]]


See also: [[space of positive definite matrices overview]]


See also: [[this matrix acts as a riemannian metric tensor on the statistical manifold, with element $i_{ij}(theta)$ providing a measure of the curvature or stiffness of the manifold in the directions of $theta_i]]


See also: [[measure of information geometrically, the fim can be interpreted as a measure of the curvature or shape of the statistical model in the parameter space. a higher value in the fim indicates a steeper]]


See also: [[geometric insight dual structures in statistical manifolds]]


See also: [[riemannian metric on the space of positive definite matrices]]


See also: [[fisher information and information geometry]]


See also: [[invariance under reparameterization]]


See also: [[duality in information geometry]]


See also: [[how have noether's symmetry principles been applied to information geometry]]


See also: [[gradient and hessian of the log-partition function]]


See also: [[geometric interpretation of jensen-shannon divergence]]


See also: [[lie groups and statistical models for some statistical models, the parameter space forms a lie group, where the group operations correspond to combining statistical models or updating them with new da]]


See also: [[geometry of spaces of probability distributions]]


See also: [[metric tensor fundamentals and applications]]


See also: [[expectation parameters in statistical models]]


See also: [[how have noether's symmetry principles been applied to information theory]]


See also: [[symmetry and conservation of information the symmetry in this context is the invariance of the geodesic distance under reparameterization of the statistical model. this symmetry leads to the conserva]]