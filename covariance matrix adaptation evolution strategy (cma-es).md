---
date: '2024-11-17T06:18:46.860070Z'
tags:
- autogenerated
- source__claude
- conversation_id__b3f2ed55-b755-416d-84ec-241252872ae4
- msg_b67acc31-737c-417e-8740-338f63a30aa5
- msg_da66b468-4fac-4076-b769-d9bf456092ec
title: covariance matrix adaptation evolution strategy (cma-es)
---


**USER**

CMA-ES


**ASSISTANT**

# Covariance Matrix Adaptation Evolution Strategy (CMA-ES)

The [[Covariance Matrix Adaptation Evolution Strategy]] (CMA-ES) is a state-of-the-art [[evolutionary algorithm]] for continuous [[black-box optimization]]. It adapts the search distribution by learning a second-order model of the underlying objective function, represented through a [[multivariate normal distribution]].

## Mathematical Formalization

Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be the objective function to be minimized. CMA-ES maintains a probability distribution over candidate solutions, parameterized at iteration $t$ by:

- Mean vector $\mathbf{m}^{(t)} \in \mathbb{R}^n$
- Step size $\sigma^{(t)} \in \mathbb{R}_+$
- Covariance matrix $\mathbf{C}^{(t)} \in \mathbb{R}^{n \times n}$

The algorithm generates $\lambda$ new candidate solutions through:

$\mathbf{x}_k^{(t+1)} = \mathbf{m}^{(t)} + \sigma^{(t)} \mathcal{N}(\mathbf{0}, \mathbf{C}^{(t)})$ for $k = 1,\ldots,\lambda$

where $\mathcal{N}(\mathbf{0}, \mathbf{C}^{(t)})$ denotes a multivariate normal distribution.

## Update Equations

### Mean Update
The mean is updated using [[weighted recombination]] of the $\mu$ best solutions:

$\mathbf{m}^{(t+1)} = \mathbf{m}^{(t)} + c_m \sum_{i=1}^{\mu} w_i (\mathbf{x}_{i:\lambda}^{(t+1)} - \mathbf{m}^{(t)})$

where:
- $w_i$ are positive weights summing to 1
- $c_m$ is the learning rate
- $\mathbf{x}_{i:\lambda}$ denotes the $i$th best solution

### Evolution Path Updates
Two [[evolution paths]] are maintained:

1. Cumulative step-size path $\mathbf{p}_\sigma^{(t+1)}$:
```
ùê©_œÉ^(t+1) = (1-c_œÉ)ùê©_œÉ^(t) + ‚àö(c_œÉ(2-c_œÉ))‚àö(Œº_w) ùêÇ^(t)^(-1/2) (ùê¶^(t+1)-ùê¶^(t))/œÉ^(t)
```

2. Covariance path $\mathbf{p}_c^{(t+1)}$:
```
ùê©_c^(t+1) = (1-c_c)ùê©_c^(t) + h_œÉ‚àö(c_c(2-c_c))‚àö(Œº_w) (ùê¶^(t+1)-ùê¶^(t))/œÉ^(t)
```

### Covariance Matrix Update
The covariance matrix combines [[rank-Œº update]] and [[rank-one update]]:

$\mathbf{C}^{(t+1)} = (1-c_1-c_\mu)\mathbf{C}^{(t)} + c_1\mathbf{p}_c^{(t+1)}{\mathbf{p}_c^{(t+1)}}^T + c_\mu\sum_{i=1}^{\mu} w_i \mathbf{y}_i^{(t+1)}{\mathbf{y}_i^{(t+1)}}^T$

where $\mathbf{y}_i^{(t+1)} = (\mathbf{x}_{i:\lambda}^{(t+1)} - \mathbf{m}^{(t)})/\sigma^{(t)}$

### Step-Size Update
The step size is updated using [[cumulative step-size adaptation]]:

$\sigma^{(t+1)} = \sigma^{(t)} \exp\left(\frac{c_\sigma}{d_\sigma}\left(\frac{\|\mathbf{p}_\sigma^{(t+1)}\|}{\mathbb{E}\|\mathcal{N}(\mathbf{0},\mathbf{I})\|} - 1\right)\right)$

## Key Properties

- [[Invariance]] under:
  - [[Monotonic transformation]] of objective function
  - [[Rotation]] and [[translation]] of search space
  - [[Linear transformation]] of search space
- [[Sample efficiency]] through:
  - [[Derandomization]] via evolution paths
  - [[Variable correlation]] learning
  - [[Step size control]] adaptation

## Applications

CMA-ES is particularly effective for:
- [[Non-convex optimization]]
- [[Non-smooth optimization]]
- [[Non-linear optimization]]
- [[Multi-modal optimization]]
- Problems with up to ~100 dimensions

## Related Algorithms

- [[Natural Evolution Strategies]]
- [[xNES]]
- [[sep-CMA-ES]]
- [[active-CMA-ES]]
- [[IPOP-CMA-ES]]