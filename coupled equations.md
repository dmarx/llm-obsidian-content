---
date: 1717811840.56527
tags:
- autogenerated
- source__oai
- conversation_id__77e70e10-f02a-4f98-bd5c-6217b10122cf
- msg_aaa2500a-c7e3-4711-b2d2-ad99453ff3d3
- msg_26944908-6bf5-4281-ad93-7aa6a2e2bab0
- colorclass/vector-space
title: coupled equations
---

**USER**

coupled equations


**ASSISTANT**

In the context of mean field game (MFG) theory and McKean-Vlasov dynamics, coupled equations typically refer to a system of partial differential equations (PDEs) that jointly describe the evolution of the agents' value function and the probability distribution of their states. These coupled equations are central to solving MFG problems and include the Hamilton-Jacobi-Bellman (HJB) equation for the value function and the Fokker-Planck (FP) equation for the probability density function.

### Coupled HJB-FP Equations

The coupled HJB-FP system consists of the Hamilton-Jacobi-Bellman equation and the Fokker-Planck equation. These equations capture the optimal control strategy for agents and the evolution of the state distribution under this strategy.

#### Hamilton-Jacobi-Bellman (HJB) Equation

The HJB equation represents the optimization problem for a representative agent. It determines the value function \( V(\mathbf{x}, t) \), which indicates the minimum expected cost starting from state \( \mathbf{x} \) at time \( t \).

\[ \frac{\partial V}{\partial t} + \min_{\alpha} \left[ L(\mathbf{x}, \alpha, m) + \nabla V \cdot \mathbf{f}(\mathbf{x}, \alpha, m) + \frac{1}{2} \text{Tr}(\mathbf{G} \mathbf{G}^T \mathbf{H} V) \right] = 0, \]

where:
- \( V(\mathbf{x}, t) \) is the value function,
- \( \mathbf{f}(\mathbf{x}, \alpha, m) \) is the drift term influenced by the control \(\alpha\) and the mean field \(m\),
- \( \mathbf{G}(\mathbf{x}, t) \) is the diffusion term,
- \( L(\mathbf{x}, \alpha, m) \) is the running cost,
- \( \mathbf{H} V \) is the Hessian matrix of second-order partial derivatives of \( V \),
- \( \text{Tr}(\cdot) \) denotes the trace operator,
- The minimization is performed over the control variable \(\alpha\).

The terminal condition for the HJB equation is given by the terminal cost function:
\[ V(\mathbf{x}, T) = \phi(\mathbf{x}, m(T)), \]

where \(\phi(\mathbf{x}, m(T))\) is the terminal cost depending on the final state \(\mathbf{x}\) and the terminal distribution \(m(T)\).

#### Fokker-Planck (FP) Equation

The FP equation describes the time evolution of the probability density function \( p(\mathbf{x}, t) \), representing the distribution of the agents' states.

\[ \frac{\partial p}{\partial t} = -\nabla \cdot (\mathbf{f}(\mathbf{x}, \alpha^*, m) p) + \frac{1}{2} \nabla \cdot \nabla \cdot (\mathbf{G} \mathbf{G}^T p), \]

where:
- \( p(\mathbf{x}, t) \) is the probability density function of the state \(\mathbf{x}\) at time \( t \),
- \( \alpha^*(\mathbf{x}, t) \) is the optimal control derived from the HJB equation,
- The term \( -\nabla \cdot (\mathbf{f}(\mathbf{x}, \alpha^*, m) p) \) represents the drift,
- The term \( \frac{1}{2} \nabla \cdot \nabla \cdot (\mathbf{G} \mathbf{G}^T p) \) represents the diffusion.

The initial condition for the FP equation is given by the initial distribution of the states:
\[ p(\mathbf{x}, 0) = p_0(\mathbf{x}), \]

where \( p_0(\mathbf{x}) \) is the initial probability density function.

### Solving the Coupled System

The coupled HJB-FP system is typically solved iteratively or simultaneously, as the solution of one equation depends on the solution of the other. Here is a general approach to solving the system:

1. **Initialize**:
   - Set an initial guess for the mean field \( m_0 \).
   - Define initial and terminal conditions for the FP and HJB equations, respectively.

2. **Iterate**:
   - **Step 1**: Solve the HJB equation given the current mean field \( m \) to find the value function \( V \) and the optimal control \( \alpha^* \).
   - **Step 2**: Solve the FP equation using the optimal control \( \alpha^* \) to update the probability density function \( p \).
   - **Step 3**: Update the mean field \( m \) based on the new probability density \( p \).

3. **Convergence Check**:
   - Check for convergence of the mean field. If the changes are below a predefined threshold, stop. Otherwise, repeat the iteration.

### Example: Linear-Quadratic Mean Field Game

Consider a linear-quadratic MFG where the dynamics and cost functions are linear and quadratic, respectively.

#### Dynamics

\[ d\mathbf{x}_i(t) = (A \mathbf{x}_i(t) + B \alpha_i(t) + F \mathbb{E}[\mathbf{x}_i(t)]) dt + \sigma d\mathbf{w}_i(t), \]

#### Cost Functional

\[ J_i(\alpha_i) = \mathbb{E} \left[ \int_0^T \left( \mathbf{x}_i(t)^T Q \mathbf{x}_i(t) + \alpha_i(t)^T R \alpha_i(t) + \mathbb{E}[\mathbf{x}_i(t)]^T S \mathbb{E}[\mathbf{x}_i(t)] \right) dt + \mathbf{x}_i(T)^T P \mathbf{x}_i(T) \right], \]

#### Solving the System

1. **HJB Equation**:
   \[ \frac{\partial V}{\partial t} + \min_{\alpha} \left[ \mathbf{x}^T Q \mathbf{x} + \alpha^T R \alpha + \mathbb{E}[\mathbf{x}]^T S \mathbb{E}[\mathbf{x}] + \nabla V \cdot (A \mathbf{x} + B \alpha + F \mathbb{E}[\mathbf{x}]) + \frac{1}{2} \text{Tr}(\sigma \sigma^T \mathbf{H} V) \right] = 0, \]
   with terminal condition:
   \[ V(\mathbf{x}, T) = \mathbf{x}^T P \mathbf{x}. \]

2. **Optimal Control**:
   \[ \alpha^*(t) = -R^{-1} B^T \nabla V(\mathbf{x}(t), t). \]

3. **FP Equation**:
   \[ \frac{\partial p}{\partial t} = -\nabla \cdot ((A \mathbf{x} + B \alpha^* + F \mathbb{E}[\mathbf{x}]) p) + \frac{1}{2} \nabla \cdot \nabla \cdot (\sigma \sigma^T p), \]
   with initial condition:
   \[ p(\mathbf{x}, 0) = p_0(\mathbf{x}). \]

### Numerical Solution

Numerical methods are essential for solving the coupled HJB-FP system. Common approaches include:

1. **Finite Difference Methods**: Discretize the spatial and temporal domains and solve the PDEs iteratively.
2. **Spectral Methods**: Use basis functions to approximate the solutions and solve the resulting system of equations.
3. **Particle Methods**: Simulate a large number of agents and use their empirical distribution to approximate the mean field.

### Conclusion

The coupled HJB-FP equations form the backbone of [[mean field game theory]], providing a rigorous framework for analyzing and solving large-scale optimization problems involving many interacting agents. These equations capture both the optimal strategies for individual agents and the evolution of the population distribution, enabling the design of effective and efficient control policies in complex, dynamic environments.


---

preceding: [[mckean-vlasov dynamics]]  


following: [[spectral methods for solving coupled systems of equations]]

See also: [[bifurcation from a simple eigenvalue (bse) theorem]]


See also: [[spectral methods]]


See also: [[nakajima-zwanzig equation]]


See also: [[mathematical foundations of quantum hydrodynamics]]


See also: [[vibracoustics]]


See also: [[poroelasticity]]


See also: [[partial derivatives]]


See also: [[game theory]]


See also: [[partial differential equations]]


See also: [[biot's effective stress]]