---
date: '2025-06-22T09:03:36.370976Z'
tags:
- autogenerated
- source__claude
- conversation_id__9b94ea9a-2594-48f2-b5a8-86ebb44d387a
- msg_7877f21f-b331-44f8-9ef2-e7d1a2f7be89
- msg_81832b98-d51f-4246-9458-96d85c4ca048
- colorclass/decision-making-processes
title: multi-criteria decision analysis
---

**USER**

Multi-Criteria Decision Analysis


**ASSISTANT**

The user is asking for a detailed technical article on Multi-Criteria Decision Analysis (MCDA). This needs to be comprehensive and technical, covering the mathematical foundations, various methods, and applications. Let me structure this properly:

1. Definition and overview
2. Mathematical foundations
3. Main MCDA methods (AHP, TOPSIS, ELECTRE, PROMETHEE, etc.)
4. Preference modeling
5. Weight determination methods
6. Sensitivity analysis
7. Group decision making
8. Fuzzy MCDA
9. Applications
10. Software and computational aspects
11. Limitations and challenges

I need to include detailed mathematical formulations, practical examples, and maintain the technical depth expected for this knowledge base.# Multi-Criteria Decision Analysis

## Definition

**Multi-Criteria Decision Analysis (MCDA)** is a [[mathematical framework]] for evaluating and ranking [[decision alternatives]] based on [[multiple conflicting criteria]], providing systematic methodologies to support [[complex decision-making]] when [[trade-offs]] exist between different [[objectives]]. MCDA transforms [[subjective preferences]] into [[quantitative assessments]] through [[preference modeling]], [[weight elicitation]], and [[aggregation functions]] that enable [[rational choice]] among alternatives with [[incommensurable attributes]].

## Mathematical Foundations

### Decision Matrix

The fundamental [[decision matrix]] $\mathbf{X}$ is defined as:

$$\mathbf{X} = \begin{pmatrix}
x_{11} & x_{12} & \cdots & x_{1n} \\
x_{21} & x_{22} & \cdots & x_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{m1} & x_{m2} & \cdots & x_{mn}
\end{pmatrix}$$

where $x_{ij}$ represents the [[performance]] of alternative $i$ on criterion $j$, with $m$ alternatives and $n$ criteria.

### Preference Structure

A [[preference relation]] $\succeq$ on the set of alternatives $\mathcal{A}$ satisfies:
- **Completeness:** $\forall a, b \in \mathcal{A}: a \succeq b \text{ or } b \succeq a$
- **Transitivity:** $a \succeq b \text{ and } b \succeq c \Rightarrow a \succeq c$

The [[strict preference]] $\succ$ and [[indifference]] $\sim$ relations are derived:
$$a \succ b \iff a \succeq b \text{ and } \neg(b \succeq a)$$
$$a \sim b \iff a \succeq b \text{ and } b \succeq a$$

### Value Function

The [[multi-attribute value function]] $V: \mathbb{R}^n \rightarrow \mathbb{R}$ represents preferences:

$$V(\mathbf{x}) = f(v_1(x_1), v_2(x_2), \ldots, v_n(x_n))$$

where $v_j(x_j)$ are [[single-attribute value functions]] and $f$ is an [[aggregation function]].

### Additive Model

Under [[preferential independence]], the additive form:

$$V(\mathbf{x}) = \sum_{j=1}^n w_j v_j(x_j)$$

where $w_j \geq 0$ are [[criterion weights]] with $\sum_{j=1}^n w_j = 1$.

## Analytical Hierarchy Process (AHP)

### Hierarchical Structure

AHP decomposes decision problems into [[hierarchical levels]]:
- **Goal Level:** Overall objective
- **Criteria Level:** Major criteria and sub-criteria
- **Alternative Level:** Decision options

### Pairwise Comparison Matrix

The [[pairwise comparison matrix]] $\mathbf{A}$ has elements:

$$a_{ij} = \frac{w_i}{w_j}$$

where $w_i$ and $w_j$ are the [[true weights]] of criteria $i$ and $j$.

**Reciprocal property:** $a_{ji} = \frac{1}{a_{ij}}$

**Saaty's scale:**
- 1: Equal importance
- 3: Moderate importance  
- 5: Strong importance
- 7: Very strong importance
- 9: Extreme importance

### Weight Derivation

The [[principal eigenvector]] method solves:

$$\mathbf{A}\mathbf{w} = \lambda_{\max} \mathbf{w}$$

where $\lambda_{\max}$ is the [[largest eigenvalue]] and $\mathbf{w}$ is the corresponding [[normalized eigenvector]].

Alternative methods include:
- **Geometric mean:** $w_i = \frac{\sqrt[n]{\prod_{j=1}^n a_{ij}}}{\sum_{k=1}^n \sqrt[n]{\prod_{j=1}^n a_{kj}}}$
- **Arithmetic mean:** $w_i = \frac{\frac{1}{n}\sum_{j=1}^n \frac{a_{ij}}{\sum_{k=1}^n a_{kj}}}{\sum_{l=1}^n \frac{1}{n}\sum_{j=1}^n \frac{a_{lj}}{\sum_{k=1}^n a_{kj}}}$

### Consistency Analysis

**Consistency Index:**
$$CI = \frac{\lambda_{\max} - n}{n - 1}$$

**Random Index:** Expected CI for random matrices of order $n$

**Consistency Ratio:**
$$CR = \frac{CI}{RI}$$

Acceptable consistency requires $CR \leq 0.1$.

### Hierarchical Composition

For [[three-level hierarchy]], the [[global weights]] are:

$$w_i^{\text{global}} = \sum_{j=1}^m w_j^{\text{criteria}} \cdot w_{ij}^{\text{local}}$$

where $w_j^{\text{criteria}}$ are criteria weights and $w_{ij}^{\text{local}}$ are local alternative weights under criterion $j$.

## TOPSIS Method

### Positive and Negative Ideal Solutions

**Positive Ideal Solution (PIS):**
$$\mathbf{A}^+ = \{a_1^+, a_2^+, \ldots, a_n^+\}$$

where:
$$a_j^+ = \begin{cases}
\max_i x_{ij} & \text{if } j \in J^+ \text{ (benefit criteria)} \\
\min_i x_{ij} & \text{if } j \in J^- \text{ (cost criteria)}
\end{cases}$$

**Negative Ideal Solution (NIS):**
$$\mathbf{A}^- = \{a_1^-, a_2^-, \ldots, a_n^-\}$$

where:
$$a_j^- = \begin{cases}
\min_i x_{ij} & \text{if } j \in J^+ \\
\max_i x_{ij} & \text{if } j \in J^-
\end{cases}$$

### Distance Calculations

**Euclidean distance to PIS:**
$$d_i^+ = \sqrt{\sum_{j=1}^n w_j (x_{ij} - a_j^+)^2}$$

**Euclidean distance to NIS:**
$$d_i^- = \sqrt{\sum_{j=1}^n w_j (x_{ij} - a_j^-)^2}$$

### Relative Closeness

The [[relative closeness coefficient]]:

$$RC_i = \frac{d_i^-}{d_i^+ + d_i^-}$$

Alternatives are ranked in descending order of $RC_i$.

### TOPSIS Variants

**Weighted TOPSIS:** Incorporates criterion weights directly in normalization

**Fuzzy TOPSIS:** Uses [[fuzzy numbers]] for uncertain evaluations

**Group TOPSIS:** Aggregates multiple decision makers' assessments

## ELECTRE Methods

### Outranking Relations

ELECTRE constructs [[outranking relations]] $aSb$ meaning "alternative $a$ is at least as good as alternative $b$."

### ELECTRE I

**Concordance Index:**
$$C(a,b) = \frac{\sum_{j \in J^+(a,b)} w_j + \sum_{j \in J^=(a,b)} w_j}{\sum_{j=1}^n w_j}$$

where:
- $J^+(a,b) = \{j : x_{aj} > x_{bj}\}$
- $J^=(a,b) = \{j : x_{aj} = x_{bj}\}$
- $J^-(a,b) = \{j : x_{aj} < x_{bj}\}$

**Discordance Index:**
$$D_j(a,b) = \frac{|x_{bj} - x_{aj}|}{\max_k x_{kj} - \min_k x_{kj}} \quad \forall j \in J^-(a,b)$$

**Outranking Conditions:**
1. $C(a,b) \geq c$ (concordance threshold)
2. $D_j(a,b) \leq d \quad \forall j \in J^-(a,b)$ (non-discordance condition)

### ELECTRE II

Introduces [[strong]] and [[weak outranking relations]] with multiple thresholds.

**Strong outranking:** $c_1$ and $d_1$ thresholds
**Weak outranking:** $c_2$ and $d_2$ thresholds where $c_1 > c_2$ and $d_1 < d_2$

### ELECTRE III

Uses [[pseudo-criteria]] with [[indifference]] and [[preference thresholds]]:

**Pseudo-criterion:** Criterion $j$ with:
- Indifference threshold: $q_j$
- Preference threshold: $p_j$ (where $p_j \geq q_j$)

**Concordance per criterion:**
$$c_j(a,b) = \begin{cases}
1 & \text{if } x_{aj} + q_j \geq x_{bj} \\
0 & \text{if } x_{aj} + p_j \leq x_{bj} \\
\frac{x_{aj} - x_{bj} + p_j}{p_j - q_j} & \text{otherwise}
\end{cases}$$

### ELECTRE IV

Operates without [[criterion weights]], using only thresholds for [[ordinal ranking]].

## PROMETHEE Methods

### Preference Functions

PROMETHEE uses [[preference functions]] $P_j(a,b)$ measuring preference intensity:

$$P_j(a,b) = F_j[d_j(a,b)]$$

where $d_j(a,b) = x_{aj} - x_{bj}$ for [[benefit criteria]].

**Six basic preference function types:**

1. **Usual:** $P(d) = \begin{cases} 0 & \text{if } d \leq 0 \\ 1 & \text{if } d > 0 \end{cases}$

2. **U-shape:** $P(d) = \begin{cases} 0 & \text{if } |d| \leq q \\ 1 & \text{if } |d| > q \end{cases}$

3. **V-shape:** $P(d) = \begin{cases} 0 & \text{if } d \leq 0 \\ \frac{d}{p} & \text{if } 0 < d \leq p \\ 1 & \text{if } d > p \end{cases}$

4. **Level:** Combines U-shape and V-shape

5. **Linear:** $P(d) = \begin{cases} 0 & \text{if } d \leq q \\ \frac{d-q}{p-q} & \text{if } q < d \leq p \\ 1 & \text{if } d > p \end{cases}$

6. **Gaussian:** $P(d) = 1 - \exp\left(-\frac{d^2}{2\sigma^2}\right)$

### Aggregated Preference

The [[aggregated preference index]]:

$$\pi(a,b) = \sum_{j=1}^n w_j P_j(a,b)$$

### PROMETHEE I (Partial Ranking)

**Positive flow:**
$$\phi^+(a) = \frac{1}{m-1} \sum_{b \in \mathcal{A}} \pi(a,b)$$

**Negative flow:**
$$\phi^-(a) = \frac{1}{m-1} \sum_{b \in \mathcal{A}} \pi(b,a)$$

**Partial preorder:**
- $a \succ b$ if $\phi^+(a) \geq \phi^+(b)$ and $\phi^-(a) \leq \phi^-(b)$ with at least one strict inequality
- $a \sim b$ if $\phi^+(a) = \phi^+(b)$ and $\phi^-(a) = \phi^-(b)$
- $a$ and $b$ are incomparable otherwise

### PROMETHEE II (Complete Ranking)

**Net flow:**
$$\phi(a) = \phi^+(a) - \phi^-(a)$$

Complete ranking by descending order of $\phi(a)$.

## Weight Determination Methods

### Direct Rating

Decision makers assign weights directly:
$$w_j = \frac{r_j}{\sum_{k=1}^n r_k}$$

where $r_j$ are [[raw ratings]].

### Rank Order Centroid (ROC)

For criteria ranked in order of importance:
$$w_j = \frac{1}{n} \sum_{k=j}^n \frac{1}{k}$$

### SWING Weighting

1. Rank criteria by [[swing importance]]
2. Assign 100 points to most important
3. Rate others relative to most important
4. Normalize to sum to 1

### Entropy Method

**Objective weight** based on [[information entropy]]:

$$e_j = -\frac{1}{\ln m} \sum_{i=1}^m p_{ij} \ln p_{ij}$$

where $p_{ij} = \frac{x_{ij}}{\sum_{i=1}^m x_{ij}}$

**Entropy weight:**
$$w_j = \frac{1 - e_j}{\sum_{k=1}^n (1 - e_k)}$$

### CRITIC Method

**Criteria Importance Through Inter-criteria Correlation:**

$$w_j = \frac{\sigma_j \sum_{k=1}^n (1 - r_{jk})}{\sum_{l=1}^n \sigma_l \sum_{k=1}^n (1 - r_{lk})}$$

where $\sigma_j$ is the [[standard deviation]] of criterion $j$ and $r_{jk}$ is the [[correlation coefficient]] between criteria $j$ and $k$.

### Best-Worst Method (BWM)

1. Identify [[best]] and [[worst]] criteria
2. Compare best criterion with all others: $\mathbf{A}_B = (a_{B1}, a_{B2}, \ldots, a_{Bn})$
3. Compare all criteria with worst: $\mathbf{A}_W = (a_{1W}, a_{2W}, \ldots, a_{nW})^T$

**Optimization model:**
$$\min \xi$$
subject to:
$$\left|\frac{w_B}{w_j} - a_{Bj}\right| \leq \xi \quad \forall j$$
$$\left|\frac{w_j}{w_W} - a_{jW}\right| \leq \xi \quad \forall j$$
$$\sum_{j=1}^n w_j = 1$$
$$w_j \geq 0 \quad \forall j$$

## Normalization Techniques

### Linear Normalization

**Benefit criteria:**
$$r_{ij} = \frac{x_{ij}}{\max_k x_{kj}}$$

**Cost criteria:**
$$r_{ij} = \frac{\min_k x_{kj}}{x_{ij}}$$

### Vector Normalization

$$r_{ij} = \frac{x_{ij}}{\sqrt{\sum_{k=1}^m x_{kj}^2}}$$

### Min-Max Normalization

**Benefit criteria:**
$$r_{ij} = \frac{x_{ij} - \min_k x_{kj}}{\max_k x_{kj} - \min_k x_{kj}}$$

**Cost criteria:**
$$r_{ij} = \frac{\max_k x_{kj} - x_{ij}}{\max_k x_{kj} - \min_k x_{kj}}$$

### Z-Score Normalization

$$r_{ij} = \frac{x_{ij} - \mu_j}{\sigma_j}$$

where $\mu_j$ and $\sigma_j$ are the [[mean]] and [[standard deviation]] of criterion $j$.

## Fuzzy MCDA

### Fuzzy Numbers

A [[triangular fuzzy number]] $\tilde{A} = (a, b, c)$ with membership function:

$$\mu_{\tilde{A}}(x) = \begin{cases}
0 & \text{if } x < a \text{ or } x > c \\
\frac{x-a}{b-a} & \text{if } a \leq x \leq b \\
\frac{c-x}{c-b} & \text{if } b \leq x \leq c
\end{cases}$$

### Fuzzy Arithmetic

**Addition:** $\tilde{A} \oplus \tilde{B} = (a_1 + b_1, a_2 + b_2, a_3 + b_3)$

**Multiplication:** $\tilde{A} \otimes \tilde{B} = (a_1 \cdot b_1, a_2 \cdot b_2, a_3 \cdot b_3)$ (for positive numbers)

**Division:** $\tilde{A} \oslash \tilde{B} = (a_1/b_3, a_2/b_2, a_3/b_1)$

### Fuzzy AHP

**Fuzzy pairwise comparison matrix:**
$$\tilde{\mathbf{A}} = [\tilde{a}_{ij}]$$

where $\tilde{a}_{ij} = (l_{ij}, m_{ij}, u_{ij})$

**Fuzzy weight calculation using [[extent analysis]]:**
$$S_i = \sum_{j=1}^n \tilde{a}_{ij} \otimes \left[\sum_{i=1}^n \sum_{j=1}^n \tilde{a}_{ij}\right]^{-1}$$

### Fuzzy TOPSIS

**Fuzzy positive ideal solution:**
$$\tilde{A}^+ = \{\tilde{v}_1^+, \tilde{v}_2^+, \ldots, \tilde{v}_n^+\}$$

**Fuzzy distance:**
$$\tilde{d}_i^+ = \sqrt{\sum_{j=1}^n d(\tilde{v}_{ij}, \tilde{v}_j^+)^2}$$

where $d(\tilde{A}, \tilde{B})$ is the [[distance between fuzzy numbers]].

## Group Decision Making

### Aggregation of Individual Judgments (AIJ)

Combine individual decision matrices before applying MCDA:

$$x_{ij}^{\text{group}} = \text{aggregation}(x_{ij}^{(1)}, x_{ij}^{(2)}, \ldots, x_{ij}^{(k)})$$

**Geometric mean aggregation:**
$$x_{ij}^{\text{group}} = \sqrt[k]{\prod_{l=1}^k x_{ij}^{(l)}}$$

### Aggregation of Individual Priorities (AIP)

Apply MCDA to each individual's judgments, then aggregate results:

$$P_i^{\text{group}} = \text{aggregation}(P_i^{(1)}, P_i^{(2)}, \ldots, P_i^{(k)})$$

### Consensus Measurement

**Consensus index:**
$$CI = 1 - \frac{1}{n(n-1)} \sum_{i=1}^n \sum_{j=1}^n |r_i - r_j|$$

where $r_i$ is the rank of alternative $i$.

### Social Choice Integration

**Borda count with MCDA scores:**
$$\text{Borda}(a) = \sum_{k=1}^m (n - \text{rank}_k(a)) \cdot w_k$$

where $w_k$ is the weight of decision maker $k$.

## Sensitivity Analysis

### Weight Sensitivity

**Weight stability intervals:** Range of weight values that preserve ranking

For [[additive model]], alternative $a$ dominates $b$ if:
$$\sum_{j=1}^n w_j (v_j(a) - v_j(b)) > 0$$

### Rank Reversal Analysis

**Threshold analysis:** Minimum change in weights to alter ranking

**Monte Carlo sensitivity:** Sample weights from distributions and analyze ranking stability

### Performance Sensitivity

**Tornado diagram:** Shows impact of Â±10% changes in each criterion

**Spider diagram:** Sensitivity to simultaneous changes in multiple criteria

### Robust Ranking

**Stochastic dominance:** Alternative $a$ [[first-order stochastically dominates]] $b$ if:
$$F_a(x) \leq F_b(x) \quad \forall x$$

where $F_a$ and $F_b$ are [[cumulative distribution functions]] of scores.

## Advanced MCDA Methods

### VIKOR

**Compromise ranking** based on [[closeness to ideal solution]]:

$$S_i = \sum_{j=1}^n w_j \frac{f_j^* - f_{ij}}{f_j^* - f_j^-}$$

$$R_i = \max_j \left[w_j \frac{f_j^* - f_{ij}}{f_j^* - f_j^-}\right]$$

**VIKOR index:**
$$Q_i = \nu \frac{S_i - S^*}{S^- - S^*} + (1-\nu) \frac{R_i - R^*}{R^- - R^*}$$

### MOORA

**Multi-Objective Optimization by Ratio Analysis:**

**Ratio system:**
$$y_i^* = \sum_{j=1}^g x_{ij}^* - \sum_{j=g+1}^n x_{ij}^*$$

where $g$ is the number of [[benefit criteria]].

**Reference point approach:**
$$\min_i \max_j |r_j - x_{ij}^*|$$

### COPRAS

**Complex Proportional Assessment:**

$$P_i = S_{+i} + \frac{S_{-\min} \sum_{i=1}^m S_{-i}}{S_{-i} \sum_{i=1}^m \frac{S_{-\min}}{S_{-i}}}$$

where $S_{+i}$ and $S_{-i}$ are weighted sums of [[normalized beneficial]] and [[cost criteria]].

### DEMATEL

**Decision Making Trial and Evaluation Laboratory:**

**Total-relation matrix:**
$$\mathbf{T} = \mathbf{D}(\mathbf{I} - \mathbf{D})^{-1}$$

where $\mathbf{D}$ is the [[normalized direct-relation matrix]].

**Prominence and relation:**
$$\text{Prominence}_i = \sum_{j=1}^n t_{ij} + \sum_{j=1}^n t_{ji}$$
$$\text{Relation}_i = \sum_{j=1}^n t_{ij} - \sum_{j=1}^n t_{ji}$$

## Computational Aspects

### Algorithmic Complexity

| Method | Time Complexity | Space Complexity |
|--------|----------------|------------------|
| AHP | $O(n^3)$ | $O(n^2)$ |
| TOPSIS | $O(mn)$ | $O(mn)$ |
| ELECTRE | $O(m^2n)$ | $O(m^2)$ |
| PROMETHEE | $O(m^2n)$ | $O(m^2)$ |

### Parallel Computing

**Parallel AHP:**
```python
from mpi4py import MPI
import numpy as np

def parallel_ahp_consistency(matrix_chunks):
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()
    
    # Compute eigenvalues for local chunk
    local_eigenvals = np.linalg.eigvals(matrix_chunks[rank])
    
    # Gather all eigenvalues
    all_eigenvals = comm.gather(local_eigenvals, root=0)
    
    if rank == 0:
        lambda_max = max([max(evals.real) for evals in all_eigenvals])
        return lambda_max
```

### GPU Acceleration

**CUDA implementation for distance calculations:**
```cpp
__global__ void topsis_distances(float* matrix, float* pis, float* nis, 
                                float* distances_pos, float* distances_neg,
                                int m, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < m) {
        float sum_pos = 0.0f, sum_neg = 0.0f;
        for (int j = 0; j < n; j++) {
            float diff_pos = matrix[idx * n + j] - pis[j];
            float diff_neg = matrix[idx * n + j] - nis[j];
            sum_pos += diff_pos * diff_pos;
            sum_neg += diff_neg * diff_neg;
        }
        distances_pos[idx] = sqrtf(sum_pos);
        distances_neg[idx] = sqrtf(sum_neg);
    }
}
```

### Machine Learning Integration

**Neural MCDA:**
```python
import torch
import torch.nn as nn

class MCDANet(nn.Module):
    def __init__(self, n_criteria, n_alternatives, hidden_dim=64):
        super().__init__()
        self.weight_net = nn.Sequential(
            nn.Linear(n_criteria, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, n_criteria),
            nn.Softmax(dim=-1)
        )
        self.scoring_net = nn.Sequential(
            nn.Linear(n_criteria + n_criteria, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
    
    def forward(self, decision_matrix):
        weights = self.weight_net(decision_matrix.mean(dim=0))
        weighted_matrix = decision_matrix * weights.unsqueeze(0)
        
        scores = []
        for i in range(decision_matrix.size(0)):
            input_features = torch.cat([decision_matrix[i], weights])
            score = self.scoring_net(input_features)
            scores.append(score)
        
        return torch.stack(scores), weights
```

## Software Tools

### Commercial Software

**Expert Choice:** AHP-based decision support
- Hierarchical modeling
- Sensitivity analysis
- Group decision support

**MakeItRational:** Web-based MCDA platform
- Multiple MCDA methods
- Collaborative features
- Real-time analysis

**DecisionTools Suite:** Comprehensive decision analysis
- @RISK for uncertainty
- PrecisionTree for decision trees
- TopRank for sensitivity

### Open Source Libraries

**Python:**
```python
# PyTOPSIS
from topsis import topsis
import numpy as np

# Decision matrix
matrix = np.array([[4, 5, 10], [3, 4, 6], [5, 3, 7]])
weights = np.array([0.2, 0.5, 0.3])
impacts = ['+', '+', '-']  # benefit/cost indicators

result = topsis(matrix, weights, impacts)
```

**R:**
```r
# MCDA package
library(MCDA)

# AHP example
pairwiseComparisonMatrix <- matrix(c(1, 2, 3, 1/2, 1, 2, 1/3, 1/2, 1), 
                                  nrow = 3, ncol = 3, byrow = TRUE)
weights <- calculateAHPWeights(pairwiseComparisonMatrix)

# ELECTRE III
performanceMatrix <- matrix(runif(30), nrow = 6, ncol = 5)
electre3 <- ELECTRE3(performanceMatrix, criteriaWeights, 
                     criteriaMinMax, indifferenceThresholds, 
                     preferenceThresholds, vetoThresholds)
```

**MATLAB:**
```matlab
% Fuzzy AHP
fuzzy_matrix = [1 1 1; 2 3 4; 1/4 1/3 1/2; ...
                1/4 1/3 1/2; 1 1 1; 1/5 1/4 1/3; ...
                2 3 4; 3 4 5; 1 1 1];

weights = fuzzy_ahp_weights(fuzzy_matrix);
consistency_ratio = ahp_consistency(fuzzy_matrix);
```

## Applications

### Healthcare Decision Making

**Hospital location selection:**
- Criteria: Cost, accessibility, population served, medical facilities
- Methods: AHP for weight elicitation, TOPSIS for ranking

**Treatment protocol selection:**
- Criteria: Efficacy, side effects, cost, patient compliance
- Methods: PROMETHEE with medical expert preferences

**Medical equipment procurement:**
- Criteria: Performance, reliability, cost, maintenance
- Methods: Fuzzy TOPSIS for uncertain evaluations

### Business and Management

**Supplier selection:**
$$\text{Score}_i = w_1 \cdot \text{Quality}_i + w_2 \cdot \text{Cost}_i + w_3 \cdot \text{Delivery}_i + w_4 \cdot \text{Service}_i$$

**Strategic planning:**
- Portfolio selection using ELECTRE
- Market entry decisions with AHP
- Investment prioritization via PROMETHEE

**Human resource management:**
- Employee performance evaluation
- Training program selection
- Recruitment candidate ranking

### Environmental Management

**Site selection for waste facilities:**
- Environmental impact assessment
- Social acceptance analysis
- Economic feasibility evaluation

**Renewable energy planning:**
- Technology selection (solar, wind, hydro)
- Location optimization
- Investment timing decisions

**Environmental impact assessment:**
$$\text{EIA Score} = \sum_{i=1}^n w_i \cdot \text{Impact}_i \cdot \text{Severity}_i \cdot \text{Probability}_i$$

### Urban Planning

**Transportation planning:**
- Route selection using multi-criteria GIS
- Public transport investment priorities
- Traffic management strategies

**Land use planning:**
- Zoning decisions with stakeholder involvement
- Urban development prioritization
- Green space allocation

### Financial Decision Making

**Investment portfolio optimization:**
$$\max \sum_{i=1}^n w_i r_i \quad \text{subject to} \quad \sum_{i=1}^n w_i \sigma_i \leq \sigma_{\max}$$

**Credit risk assessment:**
- Customer scoring models
- Loan approval decisions
- Risk category classification

**Insurance product evaluation:**
- Product comparison across multiple dimensions
- Market positioning analysis
- Pricing strategy development

## Validation and Verification

### Construct Validity

**Convergent validity:** Correlation between different MCDA methods
$$\rho = \text{corr}(\text{Ranking}_{\text{Method 1}}, \text{Ranking}_{\text{Method 2}})$$

**Discriminant validity:** Methods should distinguish between alternatives

### Rank Reversal Test

**Original ranking:** $a_1 \succ a_2 \succ a_3$

**After adding irrelevant alternative:** Check if $a_1 \succ a_2$ is preserved

### Simulation Studies

**Monte Carlo validation:**
```python
def mcda_simulation(n_runs=1000):
    results = {'AHP': [], 'TOPSIS': [], 'PROMETHEE': []}
    
    for run in range(n_runs):
        # Generate random decision matrix
        matrix = np.random.rand(5, 4)
        weights = np.random.rand(4)
        weights /= weights.sum()
        
        # Apply different methods
        ahp_ranking = apply_ahp(matrix, weights)
        topsis_ranking = apply_topsis(matrix, weights)
        promethee_ranking = apply_promethee(matrix, weights)
        
        results['AHP'].append(ahp_ranking)
        results['TOPSIS'].append(topsis_ranking)
        results['PROMETHEE'].append(promethee_ranking)
    
    return analyze_consistency(results)
```

### Cross-Validation

**Leave-one-out validation:**
Remove one alternative and check ranking stability of remaining alternatives.

**Bootstrap validation:**
Resample decision makers or criteria to assess robustness.

## Limitations and Challenges

### Rank Reversal Problem

Adding or removing irrelevant alternatives can change relative rankings in some MCDA methods.

**Mitigation strategies:**
- Use methods robust to rank reversal (e.g., ELECTRE)
- Apply normalization that preserves relative distances
- Validate results with multiple methods

### Weight Elicitation Challenges

**Cognitive burden:** Increasing exponentially with number of criteria
$$\text{Comparisons} = \binom{n}{2} = \frac{n(n-1)}{2}$$

**Inconsistency accumulation:** Human judgments become less reliable with complexity

**Strategic bias:** Decision makers may manipulate weights to favor preferred alternatives

### Scale Dependence

Different measurement scales can bias results:
- **Linear transformation:** $x' = ax + b$
- **Logarithmic transformation:** $x' = \log(x)$
- **Power transformation:** $x' = x^{\alpha}$

### Compensatory Assumptions

Most MCDA methods assume [[perfect compensation]]:
$$\text{Poor performance on one criterion} \leftrightarrow \text{Excellent performance on another}$$

**Non-compensatory alternatives:**
- Lexicographic ordering
- Satisficing approaches
- Elimination by aspects

### Uncertainty Propagation

**Epistemic uncertainty:** Model structure and parameter uncertainty

**Aleatory uncertainty:** Natural variability in data

**Combined uncertainty propagation:**
$$\sigma_{Y}^2 = \sum_{i=1}^n \left(\frac{\partial f}{\partial x_i}\right)^2 \sigma_{x_i}^2 + 2\sum_{i<j} \frac{\partial f}{\partial x_i} \frac{\partial f}{\partial x_j} \text{Cov}(x_i, x_j)$$

## Future Directions

### Integration with AI/ML

**Automated weight learning:**
```python
class WeightLearner:
    def __init__(self, n_criteria):
        self.model = nn.Sequential(
            nn.Linear(n_criteria, 64),
            nn.ReLU(),
            nn.Linear(64, n_criteria),
            nn.Softmax(dim=-1)
        )
    
    def learn_from_decisions(self, decisions, outcomes):
        # Learn optimal weights from historical decisions
        optimizer = torch.optim.Adam(self.model.parameters())
        
        for decision, outcome in zip(decisions, outcomes):
            weights = self.model(decision)
            predicted_value = torch.sum(weights * decision)
            loss = F.mse_loss(predicted_value, outcome)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
```

### Blockchain Integration

**Immutable decision records:** Store MCDA processes on blockchain for transparency

**Smart contracts for group decisions:** Automated aggregation and consensus measurement

### Real-time MCDA

**Streaming data processing:** Update rankings as new data arrives

**Dynamic weight adaptation:** Adjust criteria importance based on changing conditions

### Explainable MCDA

**Interpretation methods:**
- Feature importance analysis
- Counterfactual explanations
- Sensitivity visualization

## Related Concepts

- [[Decision Theory]]
- [[Formal Decision Tools]]
- [[Utility Theory]]
- [[Game Theory]]
- [[Optimization Theory]]
- [[Fuzzy Set Theory]]
- [[Social Choice Theory]]
- [[Operations Research]]
- [[Behavioral Decision Theory]]
- [[Risk Analysis]]
- [[Sensitivity Analysis]]
- [[Group Decision Making]]
- [[Preference Modeling]]
- [[Aggregation Functions]]
- [[Normalization Methods]]
- [[Consistency Analysis]]


---

preceding: [[formal decision tools]]  


following: [[satisficing]]

See also: [[side effects]]


See also: [[decision science]]


See also: [[multi-criteria decision analysis (mcda)]]


See also: [[decision analysis]]


See also: [[utility theory]]


See also: [[deliberative process]]