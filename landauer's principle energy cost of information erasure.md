---
date: 1728792778.53238
tags:
- autogenerated
- source__oai
- conversation_id__670b48c9-d8a8-8008-98d5-b1491aa87da8
- msg_aaa23684-dfcd-4725-b1fa-3ece5f6c5ab2
- msg_3f5d5039-8e0e-469f-ae18-3c2624e09f88
- colorclass/information-theory
title: landauer's principle energy cost of information erasure
---

**USER**

Landauer's principle


**ASSISTANT**

### Landauer's Principle: Energy Cost of Information Erasure

**Landauer's principle** is a foundational result in the thermodynamics of computation, introduced by physicist [[Rolf Landauer]]. The principle asserts that there is a minimum possible amount of energy required to erase one bit of information in any physical system. Specifically, Landauer's principle states that erasing one bit of information dissipates at least an energy of $k_B T \ln 2$ as heat, where:

- $k_B$ is the [[Boltzmann constant]] ($1.380649 \times 10^{-23} \, \text{J/K}$),
- $T$ is the absolute temperature of the system's thermal reservoir (in Kelvin).

This principle ties together information theory and thermodynamics, particularly the second law of thermodynamics, which prohibits processes that decrease the entropy of a closed system. When we erase information, we are effectively reducing the uncertainty (or entropy) about the system's state. This erasure necessarily increases the entropy elsewhere, in this case through the dissipation of energy as heat.

### Formalization of the Energy Bound

Let’s assume that a system holds a single bit of information, which can be in one of two states: $0$ or $1$. To erase the bit means forcing it into a definite state (usually $0$), regardless of its current state. This process eliminates the uncertainty or entropy associated with the bit, which, from an information-theoretic perspective, is given by the Shannon entropy of a binary system:

$$
H = - \sum_{i=0}^1 p_i \log_2 p_i
$$

For a maximally uncertain bit (where $p_0 = p_1 = \frac{1}{2}$), the entropy is $H = 1$ bit.

The **thermodynamic entropy** change associated with this process is connected to the Shannon entropy by a factor of $\ln 2$ due to the use of logarithms to base 2 in information theory, while physical entropy measures typically use natural logarithms (base $e$):

$$
\Delta S \geq k_B \ln 2
$$

By the second law of thermodynamics, this reduction in entropy must be compensated for by an increase in the entropy of the surrounding environment. In thermodynamic systems, heat dissipation $Q$ is related to the change in entropy $\Delta S$ by:

$$
\Delta S = \frac{Q}{T}
$$

Thus, combining this with the minimum change in entropy $\Delta S = k_B \ln 2$ gives the **Landauer bound**:

$$
Q \geq k_B T \ln 2
$$

This is the minimum amount of energy that must be dissipated as heat to erase one bit of information.

### Implications of Landauer’s Principle

1. **Thermodynamics of Computation**: Landauer's principle highlights that computation has fundamental thermodynamic limits. In particular, while the actual manipulation and processing of information (e.g., logical operations) can in principle be done in a thermodynamically reversible way (incurring no heat dissipation), erasure is an inherently irreversible process that dissipates energy.
   
2. **Maxwell’s Demon**: Landauer's principle provides a resolution to the paradox posed by [[Maxwell's Demon]], a thought experiment where a demon seemingly violates the second law of thermodynamics by selectively allowing particles to pass between two chambers based on their speed, thereby decreasing entropy. Landauer’s principle implies that the demon, in the act of erasing the information it gathers about particle speeds, must dissipate energy, thus preserving the second law.

3. **Technological Relevance**: As we approach the physical limits of miniaturization in computing hardware, Landauer's limit becomes more relevant for understanding the thermodynamic cost of data processing. Modern computing devices dissipate energy orders of magnitude above the Landauer limit, but future technologies might approach this bound, making energy efficiency in computation increasingly important.

### Connection to Statistical Mechanics

Landauer's principle is deeply rooted in the statistical mechanical interpretation of entropy. The information associated with the state of a system has a direct link to the number of microscopic configurations (microstates) that are consistent with a given macroscopic state. When information is erased, the number of accessible microstates is reduced, corresponding to a decrease in information-theoretic entropy. To maintain the total entropy of a closed system, this decrease must be accompanied by an increase in the entropy of the environment, realized as heat.

### Summary

Landauer's principle establishes a lower bound on the energy cost of erasing information in physical systems, directly linking information theory to the second law of thermodynamics. The minimum energy dissipation required to erase one bit of information is given by:

$$
E_{\text{erase}} \geq k_B T \ln 2
$$

This relationship formalizes the concept that there is no "free" erasure of information, as each such operation is accompanied by unavoidable heat dissipation. This principle not only underpins the thermodynamics of computation but also provides insights into fundamental physical processes like the behavior of [[Maxwell's Demon]].


---


following: [[thermodynamics of computation]]

See also: [[energy dissipation]]


See also: [[information theory]]