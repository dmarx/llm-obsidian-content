---
date: '2025-01-28T21:12:02.565940Z'
tags:
- autogenerated
- source__claude
- conversation_id__b01d1f56-b956-4961-9c10-4f930adda320
- msg_47fd3d26-007c-4cb1-9638-1047906e4487
- msg_4692e78a-4397-40b5-a0ed-6a50e7867f07
- colorclass/information-theory
title: modeling as notational compression
---

**USER**

"modeling"(qua predictive, generative, etc.) as the "art" or "craft" of formalizing processes in the form of notation, which is functionally equivalent to distilling systems into what is effectively their most compact (kolmogorov complexity) representation


**ASSISTANT**

# Modeling as Notational Compression

[[Modeling]] can be understood as the systematic process of distilling complex systems into their most efficient symbolic representations, fundamentally aligned with principles of [[Kolmogorov complexity]] and [[information theory]]. This perspective frames modeling as an art of compression - capturing the essential dynamics and relationships of a system using minimal descriptive resources.

## Formal Definition

Let $\mathcal{S}$ be a system with observable behaviors $B = \{b_1, ..., b_n\}$ and let $\mathcal{M}$ be a model of $\mathcal{S}$ expressed in some [[formal language]] $L$. The [[descriptive complexity]] of $\mathcal{M}$ relative to $L$ is:

$K_L(\mathcal{M}) = \min\{|p| : U(p) = \mathcal{M}\}$

where $U$ is a universal computer implementing $L$ and $|p|$ is the length of program $p$.

## Optimization Objective

The art of modeling can be expressed as finding $\mathcal{M}^*$ that minimizes:

$\mathcal{M}^* = \arg\min_{\mathcal{M}} \{K_L(\mathcal{M}) + \lambda D(\mathcal{S}, \mathcal{M})\}$

where:
- $D(\mathcal{S}, \mathcal{M})$ is a [[divergence measure]] between the system and model behaviors
- $\lambda$ is a trade-off parameter between complexity and fidelity

## Key Properties

1. **[[Parsimony Principle]]**: Good models achieve high predictive power with minimal symbolic complexity

2. **[[Universal Computation]]**: Any sufficiently expressive notation system can represent any computable process

3. **[[Trade-off Optimization]]**: Modeling involves balancing:
   - Descriptive accuracy
   - Computational tractability 
   - Human interpretability
   - Generalization capacity

## Connection to Scientific Understanding

This framing suggests that scientific understanding itself can be measured by the compression ratio achieved in modeling:

$C_R = \frac{\text{bits needed to describe raw observations}}{\text{bits needed to describe predictive model}}$

Higher compression ratios indicate deeper understanding through more efficient abstract representations.

## Limitations and Philosophical Implications

The view of modeling as compression highlights fundamental limits:
- [[No Free Lunch Theorem]] implies no universally optimal notation
- [[Incompleteness Theorem]] suggests inherent limitations in formal systems
- Trade-off between [[model complexity]] and [[generalization error]]

This perspective connects modeling to broader questions in:
- [[Philosophy of Mathematics]]
- [[Cognitive Science]] 
- [[Information Theory]]
- [[Complexity Theory]]

Understanding modeling as notational compression provides a rigorous framework for evaluating and comparing different formal representations while acknowledging fundamental limitations and trade-offs inherent in the enterprise.


---


following: [[related reading paths]]

See also: [[kolmogorov complexity]]


See also: [[compression]]