---
date: '2025-04-06T04:27:01.874669Z'
tags:
- autogenerated
- source__claude
- conversation_id__313d5a59-f9d4-489a-9551-c32b78a7adaf
- msg_0d72dec5-03ae-46d9-ab27-45fb61e517bb
- msg_7533b82e-c129-4af6-b54c-c1d92546b9d5
- colorclass/information-theory
title: sample complexity
---

**USER**

Sample Complexity


**ASSISTANT**

# Sample Complexity

Sample complexity is a fundamental concept in [[statistical learning theory]] that quantifies the number of training examples required for a learning algorithm to achieve a specified level of performance with high probability. It establishes theoretical bounds on how much data is needed to learn an effective model while providing formal guarantees about generalization.

## Mathematical Formalization

### Basic Definition

The sample complexity $m(\epsilon, \delta)$ is the minimum number of samples needed to ensure that with probability at least $1-\delta$, a learning algorithm $\mathcal{A}$ outputs a hypothesis $h$ with error at most $\epsilon$:

$$m(\epsilon, \delta) = \min \left\{ m : P_{S \sim D^m}[\text{error}(\mathcal{A}(S)) \leq \epsilon] \geq 1 - \delta \right\}$$

Where:
- $D$ is the underlying data distribution
- $S$ is a training set of $m$ examples drawn from $D$
- $\text{error}(h) = P_{x \sim D}[h(x) \neq f(x)]$ for target function $f$

### PAC Learning Framework

Within the [[Probably Approximately Correct (PAC)]] learning framework, sample complexity is tied to the concept of PAC-learnability:

A hypothesis class $\mathcal{H}$ is PAC-learnable if there exists an algorithm $\mathcal{A}$ and a polynomial function $\text{poly}(\cdot,\cdot,\cdot,\cdot)$ such that for any $\epsilon, \delta \in (0,1)$, distribution $D$, and target concept $c$:

$$m(\epsilon, \delta) \leq \text{poly}\left(\frac{1}{\epsilon}, \frac{1}{\delta}, n, \text{size}(c)\right)$$

Where $n$ is the input dimension and $\text{size}(c)$ is a measure of the complexity of the target concept.

## Theoretical Bounds

### 1. [[VC Dimension Bounds]]

For a hypothesis class $\mathcal{H}$ with VC dimension $d$:

$$m(\epsilon, \delta) = O\left(\frac{d + \log(1/\delta)}{\epsilon^2}\right)$$

This bound is tight in the worst case, with a matching lower bound:

$$m(\epsilon, \delta) = \Omega\left(\frac{d + \log(1/\delta)}{\epsilon^2}\right)$$

### 2. [[Rademacher Complexity Bounds]]

Using the empirical Rademacher complexity $\hat{\mathcal{R}}_S(\mathcal{H})$:

$$m(\epsilon, \delta) = O\left(\frac{\mathbb{E}[\hat{\mathcal{R}}_S(\mathcal{H})]^2 + \log(1/\delta)}{\epsilon^2}\right)$$

### 3. [[Covering Number Bounds]]

Using the covering number $\mathcal{N}(\mathcal{H}, \epsilon, \| \cdot \|)$:

$$m(\epsilon, \delta) = O\left(\frac{\log \mathcal{N}(\mathcal{H}, \epsilon/4, \| \cdot \|_\infty) + \log(1/\delta)}{\epsilon^2}\right)$$

## Problem-Specific Sample Complexity

### 1. [[Realizable vs. Agnostic Learning]]

- **Realizable setting** (target function in hypothesis class):
  $$m(\epsilon, \delta) = O\left(\frac{d \log(1/\epsilon) + \log(1/\delta)}{\epsilon}\right)$$

- **Agnostic setting** (target function may not be in hypothesis class):
  $$m(\epsilon, \delta) = O\left(\frac{d + \log(1/\delta)}{\epsilon^2}\right)$$

### 2. [[Active Learning]]

When the learner can select which examples to label:

$$m_{\text{active}}(\epsilon, \delta) = O\left(\theta \cdot \log^2\left(\frac{1}{\epsilon}\right) \log\left(\frac{\log(1/\epsilon)}{\delta}\right)\right)$$

Where $\theta$ is a problem-dependent disagreement coefficient.

### 3. [[Online Learning]]

In the online learning setting with regret $R_T$:

$$m_{\text{online}}(\epsilon, \delta) = O\left(\frac{R_T^2}{\epsilon^2} + \frac{\log(1/\delta)}{\epsilon^2}\right)$$

## Advanced Complexity Measures

### 1. [[Fat-Shattering Dimension]]

For real-valued function classes, the fat-shattering dimension $\text{fat}_\gamma(\mathcal{F})$ at scale $\gamma$:

$$m(\epsilon, \delta) = O\left(\frac{\text{fat}_{\epsilon/2}(\mathcal{F}) \cdot \log^2(1/\epsilon) + \log(1/\delta)}{\epsilon^2}\right)$$

### 2. [[Algorithmic Stability]]

For algorithms with stability parameter $\beta$:

$$m(\epsilon, \delta) = O\left(\frac{\beta + \log(1/\delta)}{\epsilon^2}\right)$$

### 3. [[Compression Schemes]]

If a learning algorithm can be represented as a compression scheme of size $k$:

$$m(\epsilon, \delta) = O\left(\frac{k \log(1/\epsilon) + \log(1/\delta)}{\epsilon}\right)$$

## Applications to Machine Learning

### 1. [[Linear Classifiers]]

For learning a linear separator in $n$ dimensions:

$$m(\epsilon, \delta) = O\left(\frac{n + \log(1/\delta)}{\epsilon^2}\right)$$

### 2. [[Decision Trees]]

For learning a decision tree of depth $d$:

$$m(\epsilon, \delta) = O\left(\frac{2^d \log(1/\epsilon) + \log(1/\delta)}{\epsilon}\right)$$

### 3. [[Neural Networks]]

For a neural network with $W$ weights and activation functions satisfying certain conditions:

$$m(\epsilon, \delta) = O\left(\frac{W \log W + \log(1/\delta)}{\epsilon^2}\right)$$

## Sample Complexity Reduction Techniques

### 1. [[Structural Risk Minimization]]

Balancing hypothesis class complexity with empirical risk:

$$m_{\text{SRM}}(\epsilon, \delta) \approx \min_k \left\{ m_k(\epsilon/2, \delta/2) : \text{empirical error on } m_k \text{ samples } \leq \epsilon/2 \right\}$$

### 2. [[Transfer Learning]]

Leveraging knowledge from related tasks:

$$m_{\text{transfer}}(\epsilon, \delta) = O\left(\frac{d_{\text{target}} + d_{\text{divergence}} + \log(1/\delta)}{\epsilon^2}\right)$$

Where $d_{\text{divergence}}$ measures distribution shift between tasks.

### 3. [[Semi-Supervised Learning]]

Using unlabeled data to reduce labeled sample requirements:

$$m_{\text{semi}}(\epsilon, \delta) = O\left(\frac{d_{\text{compatible}} + \log(1/\delta)}{\epsilon^2}\right)$$

Where $d_{\text{compatible}}$ is a compatibility-based complexity measure.

## Practical Implications

### 1. [[Learning Curves]]

The relationship between sample size and expected error:

$$\text{Expected Error}(m) \approx a + \frac{b}{m^c}$$

Where $a$, $b$, and $c$ are problem-dependent constants.

### 2. [[Diminishing Returns]]

The phenomenon where doubling sample size provides less than double improvement:

$$\Delta \text{Error}(m \to 2m) \approx \frac{b}{m^c} - \frac{b}{(2m)^c} = b \cdot m^{-c} \cdot (1 - 2^{-c})$$

### 3. [[Curriculum Design]]

Implications for how to structure learning experiences:

$$m_{\text{curriculum}}(\epsilon, \delta) \leq m_{\text{standard}}(\epsilon, \delta)$$

Under appropriate assumptions about task structure.

## Connections to Other Frameworks

### 1. [[Computational Complexity]]

The relationship between sample and computational complexity:

$$\text{Time Complexity} = f(m(\epsilon, \delta), n, \epsilon, \delta)$$

### 2. [[Communication Complexity]]

In distributed learning settings:

$$\text{Communication} = g(m(\epsilon, \delta), \text{parties}, \epsilon, \delta)$$

### 3. [[Privacy Complexity]]

Additional samples needed for privacy guarantees:

$$m_{\text{private}}(\epsilon, \delta, \rho) = \Omega\left(m(\epsilon, \delta) \cdot \sqrt{\frac{d}{\rho}}\right)$$

Where $\rho$ parameterizes the privacy level.

## Research Frontiers

Current research directions include:

### 1. [[Instance-Optimal Sample Complexity]]

Bounds that adapt to the specific learning problem instance:

$$m_{\text{instance}}(\epsilon, \delta) = h(\text{instance-specific parameters}, \epsilon, \delta)$$

### 2. [[Multi-Task Sample Complexity]]

Sample requirements when learning multiple related tasks:

$$m_{\text{multi}}(\epsilon, \delta, T) = O\left(\frac{d + T\bar{d} + \log(1/\delta)}{\epsilon^2}\right)$$

Where $T$ is the number of tasks and $\bar{d}$ is a measure of task relatedness.

### 3. [[Adaptive Sample Complexity]]

Algorithms that automatically determine how many samples to collect:

$$m_{\text{adaptive}}(\epsilon, \delta) \leq m_{\text{fixed}}(\epsilon, \delta)$$

With equality only in worst-case scenarios.

Sample complexity remains a fundamental concept in machine learning theory, providing theoretical guidance for data collection and algorithm design while establishing formal guarantees about learning performance across diverse settings.


---

preceding: [[regret analysis]]  


following: [[rademacher complexity bounds]]

See also: [[hypothesis class]]


See also: [[computational epistemology]]


See also: [[levels of solution in stochastic games]]


See also: [[information dimension]]


See also: [[probably approximately correct]]