---
date: 1718160703.257135
tags:
- autogenerated
- source__oai
- conversation_id__18aef735-d044-4209-927f-ec249ab3595f
- msg_aaa27515-d269-470a-853f-a47c3e214063
- msg_9fecb4fc-fe2b-4b0c-9b04-4cd38dc70279
- colorclass/system-dynamics
title: control law design
---

**USER**

Control Law Design


**ASSISTANT**

### Control Law Design

Control law design involves creating a control strategy that achieves the desired behavior of a dynamic system. This can involve various approaches, including classical methods like PID control, modern techniques such as [[state feedback control]], and advanced methods like [[adaptive control]] and optimal control. Here, we focus on control law design within the context of [[adaptive control]], particularly for Self-Tuning Regulators (STR) and Model Reference Adaptive Control (MRAC).

### Control Law Design in Self-Tuning Regulators (STR)

In STR, the control law is designed based on the real-time estimated parameters of the system. The control objective is to regulate the system output to track a desired reference signal or maintain stability.

#### Steps in Control Law Design for STR

1. **System Identification**:
   - Estimate the parameters of the system model in real-time using methods like Recursive Least Squares (RLS).

2. **Model Representation**:
   - Represent the system dynamics using the estimated parameters.

3. **Control Objective**:
   - Define the control objective, such as setpoint tracking or disturbance rejection.

4. **Control Law Formulation**:
   - Design the control law based on the estimated system model. Common approaches include [[pole placement]] and Linear Quadratic Regulator (LQR) design.

### Example: Pole Placement Control

Consider a discrete-time system:
$$
y(k+1) = a y(k) + b u(k) + \epsilon(k),
$$
where \(a\) and \(b\) are the parameters to be estimated.

1. **Parameter Estimation**:
   - Estimate \(a\) and \(b\) using RLS or another estimation method.

2. **Control Law**:
   - Design the control law to place the closed-loop poles at desired locations for stability and performance. For example:
     $$ u(k) = -\frac{1}{b} (a y(k) + k_c (r(k) - y(k))), $$
     where \(k_c\) is the feedback gain chosen to achieve desired [[pole placement]].

### Control Law Design in Model Reference Adaptive Control (MRAC)

In MRAC, the control law is designed to make the system output follow the output of a reference model. The reference model specifies the desired dynamics, and the [[adaptive control]] law adjusts the parameters to minimize the tracking error.

#### Steps in Control Law Design for MRAC

1. **Reference Model Specification**:
   - Define the desired dynamics using a reference model:
     $$ \dot{x}_m(t) = A_m x_m(t) + B_m r(t), $$
     where \(x_m(t)\) is the reference model state and \(r(t)\) is the reference input.

2. **Control Law Formulation**:
   - Design the control law with adjustable parameters to achieve the desired tracking. For example, the control input \(u(t)\) can be:
     $$ u(t) = \theta^T(t) \phi(t), $$
     where \(\theta(t)\) is the adaptive parameter vector and \(\phi(t)\) is the regressor vector.

3. **Adaptation Law**:
   - Develop an adaptation law to update the control parameters in real-time to minimize the tracking error \(e(t) = x(t) - x_m(t)\).

### Example: MRAC for a First-Order System

Consider a first-order system:
$$
\dot{x}(t) = -a x(t) + b u(t),
$$
where \(a\) and \(b\) are unknown parameters.

1. **Reference Model**:
   - Define the reference model:
     $$ \dot{x}_m(t) = -a_m x_m(t) + b_m r(t), $$
     where \(a_m\) and \(b_m\) are chosen to represent the desired dynamics.

2. **Control Law**:
   - The control input is:
     $$ u(t) = \theta_1(t) r(t) + \theta_2(t) x(t), $$
     where \(\theta_1(t)\) and \(\theta_2(t)\) are adaptive parameters.

3. **Adaptation Law**:
   - Use the gradient method to update the parameters:
     $$ \begin{aligned}
     \dot{\theta}_1(t) &= \gamma r(t) e(t), \\
     \dot{\theta}_2(t) &= \gamma x(t) e(t),
     \end{aligned} $$
     where \(e(t) = x(t) - x_m(t)\) is the tracking error and \(\gamma\) is the adaptation gain.

### Advanced Control Law Design Techniques

#### 1. Linear Quadratic Regulator (LQR)

LQR is an optimal control strategy that minimizes a quadratic cost function. For a system described by:
$$ \dot{x} = A x + B u, $$
the LQR problem involves finding the control input \(u\) that minimizes the cost:
$$ J = \int_0^\infty (x^T Q x + u^T R u) \, dt, $$
where \(Q\) and \(R\) are positive definite matrices. The optimal control law is:
$$ u = -K x, $$
where \(K\) is the feedback gain matrix obtained by solving the Riccati equation.

#### 2. Robust Control

Robust control techniques, such as \(H_\infty\) control, are designed to handle model uncertainties and disturbances. The objective is to design a control law that minimizes the worst-case effect of disturbances on the system.

### Conclusion

Control law design in [[adaptive control]] systems like STR and MRAC involves real-time parameter estimation and dynamic adjustment of the controller parameters to achieve desired performance. Techniques such as [[pole placement]], LQR, and robust control provide frameworks for designing effective control laws. For further exploration, consider topics such as [[Adaptive Control]], [[Optimal Control]], and [[Robust Control]].


---

preceding: [[self-tuning regulators (str)]]  


following: [[adaptation mechanisms in [[adaptive control]]]]

See also: [[gain matrix]]


See also: [[system dynamics]]