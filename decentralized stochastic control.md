---
date: 1717810416.475404
tags:
- autogenerated
- source__oai
- conversation_id__77e70e10-f02a-4f98-bd5c-6217b10122cf
- msg_aaa2f1e8-e27e-4c92-ae76-654dbef4504b
- msg_77014754-8f8d-405a-bdf7-0a058ff1bb2f
- colorclass/system-dynamics
title: decentralized stochastic control
---

**USER**

decentralized stochastic control


**ASSISTANT**

Decentralized stochastic control is a branch of control theory that deals with systems composed of multiple interacting subsystems, each with its own control inputs, which operate under uncertainty. In these systems, each subsystem, or agent, makes decisions based on its local information and possibly some shared information. This framework is crucial for applications in multi-agent systems, networked control systems, and distributed sensor networks.

### Problem Setup

In decentralized stochastic control, we consider a system of \(N\) agents, each with its own state and control input. The overall system dynamics can be influenced by the control inputs from multiple agents and are subject to stochastic disturbances.

#### System Dynamics

The state dynamics of agent \(i\) can be modeled as a stochastic differential equation (SDE):
\[ d\mathbf{x}_i(t) = \mathbf{f}_i(\mathbf{x}_i(t), \mathbf{u}_i(t), t) dt + \mathbf{G}_i(\mathbf{x}_i(t), t) d\mathbf{w}_i(t), \]
where:
- \( \mathbf{x}_i(t) \in \mathbb{R}^{n_i} \) is the state vector of agent \(i\),
- \( \mathbf{u}_i(t) \in \mathbb{R}^{m_i} \) is the control input vector of agent \(i\),
- \( \mathbf{f}_i \) represents the deterministic part of the dynamics for agent \(i\),
- \( \mathbf{G}_i \) represents the diffusion matrix for agent \(i\),
- \( \mathbf{w}_i(t) \) is a standard Wiener process representing stochastic disturbances for agent \(i\).

The overall system state is \(\mathbf{x}(t) = [\mathbf{x}_1(t)^T, \mathbf{x}_2(t)^T, \ldots, \mathbf{x}_N(t)^T]^T\), and the control inputs are \(\mathbf{u}(t) = [\mathbf{u}_1(t)^T, \mathbf{u}_2(t)^T, \ldots, \mathbf{u}_N(t)^T]^T\).

### Cost Functional

The objective is to minimize a global cost functional, which is a sum of local costs for each agent:
\[ J(\mathbf{u}) = \mathbb{E} \left[ \sum_{i=1}^N \left( \phi_i(\mathbf{x}_i(T)) + \int_{0}^{T} L_i(\mathbf{x}_i(t), \mathbf{u}_i(t), t) dt \right) \right], \]
where:
- \( \phi_i(\mathbf{x}_i(T)) \) is the terminal cost for agent \(i\),
- \( L_i(\mathbf{x}_i, \mathbf{u}_i, t) \) is the running cost for agent \(i\),
- \(\mathbb{E}\) denotes the expectation operator.

### Decentralized Control Strategies

In decentralized control, each agent makes decisions based on its local information and possibly some shared information from other agents. The control strategy for each agent \(i\) is a function of its local state and available information:
\[ \mathbf{u}_i(t) = \pi_i(\mathbf{I}_i(t)), \]
where \( \pi_i \) is the control policy for agent \(i\) and \( \mathbf{I}_i(t) \) represents the information set available to agent \(i\) at time \(t\).

### Information Structures

The information structure, or pattern, defines what information is available to each agent at each time step. Common information structures include:

1. **Fully Decentralized**:
   Each agent has access only to its own state and possibly its own past control inputs.
   \[ \mathbf{I}_i(t) = \{\mathbf{x}_i(s), \mathbf{u}_i(s) \mid 0 \leq s \leq t\}. \]

2. **Partially Decentralized**:
   Each agent has access to its own state and the states or control inputs of a subset of other agents.
   \[ \mathbf{I}_i(t) = \{\mathbf{x}_i(s), \mathbf{x}_j(s), \mathbf{u}_i(s), \mathbf{u}_j(s) \mid 0 \leq s \leq t, j \in \mathcal{N}_i\}, \]
   where \(\mathcal{N}_i\) is the set of agents whose information is available to agent \(i\).

3. **Centralized**:
   Each agent has access to the global state information.
   \[ \mathbf{I}_i(t) = \{\mathbf{x}(s), \mathbf{u}(s) \mid 0 \leq s \leq t\}. \]

### Dynamic Programming and the Hamilton-Jacobi-Bellman (HJB) Equation

In decentralized control, dynamic programming principles can be extended to handle the decentralized information structures. The value function for agent \(i\), \(V_i(\mathbf{x}_i, t)\), represents the minimum expected cost-to-go from state \(\mathbf{x}_i\) at time \(t\) given the information available to agent \(i\).

#### Coupled HJB Equations

The coupled HJB equations for decentralized stochastic control are:
\[ \frac{\partial V_i}{\partial t} + \min_{\mathbf{u}_i} \left[ L_i(\mathbf{x}_i, \mathbf{u}_i, t) + \nabla V_i \cdot \mathbf{f}_i(\mathbf{x}_i, \mathbf{u}_i, t) + \frac{1}{2} \text{Tr} \left( \mathbf{G}_i^T \mathbf{H} V_i \mathbf{G}_i \right) \right] = 0, \]
with terminal condition:
\[ V_i(\mathbf{x}_i, T) = \phi_i(\mathbf{x}_i(T)). \]

Each agent solves its own HJB equation considering its local information and interactions with other agents.

### Example: Decentralized LQG Control

Consider a decentralized LQG control problem with two agents. The system dynamics for each agent \(i\) are:
\[ d\mathbf{x}_i(t) = (A_i \mathbf{x}_i(t) + B_i \mathbf{u}_i(t)) dt + \mathbf{G}_i d\mathbf{w}_i(t), \]

The cost functional for each agent \(i\) is:
\[ J_i = \mathbb{E} \left[ \mathbf{x}_i(T)^T F_i \mathbf{x}_i(T) + \int_{0}^{T} (\mathbf{x}_i(t)^T Q_i \mathbf{x}_i(t) + \mathbf{u}_i(t)^T R_i \mathbf{u}_i(t)) dt \right]. \]

#### Solution Steps:

1. **Solve the Riccati Equation**:
   Each agent solves a Riccati equation for its subsystem:
   \[ \dot{P}_i(t) = -Q_i - A_i^T P_i - P_i A_i + P_i B_i R_i^{-1} B_i^T P_i, \]
   with terminal condition \( P_i(T) = F_i \).

2. **Compute the Optimal Control**:
   The optimal control law for each agent is:
   \[ \mathbf{u}_i^*(t) = -R_i^{-1} B_i^T P_i(t) \mathbf{x}_i(t). \]

### Summary

Decentralized stochastic control deals with optimizing the performance of multi-agent systems under uncertainty. Each agent makes decisions based on its local information and possibly shared information from other agents. The dynamic programming approach and coupled HJB equations form the backbone of finding optimal decentralized control policies. This framework is vital for applications in networked systems, multi-robot systems, and large-scale distributed systems.


---

preceding: [[stochastic [[optimal control theory]]]]  


following: [[witsenhausen's counterexample]]

See also: [[control theory]]


See also: [[dynamic programming]]


See also: [[system dynamics]]