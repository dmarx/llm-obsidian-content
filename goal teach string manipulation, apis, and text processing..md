---
date: 1726437555.750692
tags:
- autogenerated
- source__oai
- conversation_id__66e757d1-0534-8008-bb6a-afa8342b5ee2
- msg_aaa27210-7a73-40b2-b50c-ec106992a567
- msg_3ebadb63-11bc-4c29-b137-1e8cf35c3bb6
- colorclass/edge-case
title: goal teach string manipulation, apis, and text processing.
---

**USER**

> Goal: Teach string manipulation, APIs, and text processing.
I was actually thinking of front-loading this. The "hello world" assignment needs to be sending a prompt to an api-hosted model. students learn skills incrementally, specifically in the context of prompt engineering and agent engineering. string manipulation should be prioritized over control structures. jinja templating prioritized over regex.


**ASSISTANT**

That’s a great idea—front-loading the course with LLM interactions, while emphasizing string manipulation, API interactions, and prompt engineering, sets a modern and practical tone from the start. This approach can help students see immediate results and understand how foundational skills like string manipulation and templating play crucial roles in LLM-driven applications.

Here's how you could structure a “Hello World” assignment that sends prompts to an API-hosted model, while introducing key concepts like string manipulation and templating early on. This plan includes incremental learning steps focused on prompt engineering and agent interaction.

## Revised Outline for “Hello World” Assignment

### 1. **First Assignment: Simple API Interaction**
   *Goal*: Introduce students to making API requests and working with strings in the context of LLM-driven prompt engineering.

   - **Concepts**:
     - Sending a request to a hosted LLM (e.g., GPT-3 or GPT-4).
     - Processing the response (basic string handling).
     - Formulating effective prompts.
   - **Python Skills**:
     - Using `requests` library for HTTP requests.
     - Basic string concatenation and manipulation.
     - Minimal error handling to handle common API failures (e.g., invalid API keys, rate limits).

   **Example Code**:
   ```python
   import requests

   def query_gpt(prompt, api_key):
       api_url = "https://api.openai.com/v1/completions"
       headers = {
           "Authorization": f"Bearer {api_key}",
           "Content-Type": "application/json"
       }
       data = {
           "model": "text-davinci-003",
           "prompt": prompt,
           "max_tokens": 100
       }
       response = requests.post(api_url, headers=headers, json=data)
       return response.json().get('choices', [{}])[0].get('text', '')

   api_key = "your_openai_api_key"
   prompt = "Hello, world!"
   response_text = query_gpt(prompt, api_key)
   print("AI Response:", response_text)
   ```

   **Learning Outcomes**:
   - Students will learn how to format and send HTTP requests.
   - Basic string concatenation to form API headers and payloads.
   - Inspecting the structure of JSON responses and extracting relevant information.

   ### Discussion on Prompt Engineering:
   After this simple interaction, introduce prompt engineering as an iterative process. Students can start modifying their "Hello World" prompt to explore variations:
   - How does the response change with small tweaks in wording?
   - Introduce token limits and explain how prompt length impacts results.

### 2. **Focus on String Manipulation and Prompt Construction**
   Now that students understand how to interact with an LLM API, shift to refining their inputs via **string manipulation**. At this stage, they need to understand how even subtle changes in prompt formulation can affect the output.

   - **Key Skills**:
     - String concatenation and substitution: `"The result is " + result`.
     - **F-strings**: `"The result is {result}"`, Python’s preferred formatting method.
     - Introduce **multi-line strings** to craft more complex prompts (`"""This is a multi-line prompt."""`).

   **Example Task**:
   - Ask students to craft a prompt that outputs a polite response using string concatenation or f-strings:
     ```python
     user_name = "Alice"
     prompt = f"Hello, {user_name}! How can I assist you today?"
     response_text = query_gpt(prompt, api_key)
     print("AI Response:", response_text)
     ```

   - Ask them to explore edge cases like empty strings or special characters.

### 3. **Introduce Jinja2 for Templating Prompts**
   After mastering simple string manipulation, introduce [[Jinja2]] for **prompt templating**, which allows for more dynamic and reusable prompt structures. This is particularly important in agent engineering, where prompts are generated programmatically depending on context.

   - **Concepts**:
     - **Template rendering** with `Jinja2`: Teach students how to use templates to construct prompts dynamically based on input variables, making their prompts more flexible and powerful.
     - Comparison with traditional string formatting, showing the advantages of templating when dealing with complex structures or multiple fields.
     - **Prompt modularity**: Break a single complex prompt into reusable parts that can be combined via templates.

   **Example Code with Jinja2**:
   ```python
   from jinja2 import Template

   def generate_prompt(user_name, task):
       template_str = """
       Hello, {{ user_name }}!
       I see that you'd like help with {{ task }}.
       Let me provide some guidance:
       """
       template = Template(template_str)
       return template.render(user_name=user_name, task=task)

   user_name = "Alice"
   task = "learning Python"
   prompt = generate_prompt(user_name, task)
   response_text = query_gpt(prompt, api_key)
   print("AI Response:", response_text)
   ```

   **Learning Outcomes**:
   - Understanding the benefits of templating over direct string manipulation, especially in scenarios with multiple variables or varying inputs.
   - How to create reusable, parameterized prompt templates that can adapt to different contexts dynamically.
   - The importance of prompt modularity in LLM interactions, particularly when building larger applications or complex agents.

### 4. **Agent Engineering: Combining APIs with Logic**
   Now that students understand prompt construction and API interactions, begin layering in more complex **agent engineering** concepts. This stage doesn’t yet require complex control structures (like `for` loops or conditionals), but it can introduce the basic idea of **agent autonomy**—where the prompt itself provides logic or rules for the AI to follow.

   - **Goal**: Build simple agents that interact with the model autonomously based on user input.
   
   - **Task**: Create a small helper agent that guides users through a basic process (e.g., calculating a sum, solving a math problem) with limited back-and-forth prompts.

   **Example Task**:
   - The agent asks a user for two numbers and returns their sum:
     ```python
     def generate_math_prompt(num1, num2):
         template_str = """
         You are a math tutor. Please add {{ num1 }} and {{ num2 }}.
         """
         template = Template(template_str)
         return template.render(num1=num1, num2=num2)

     num1, num2 = 12, 8
     prompt = generate_math_prompt(num1, num2)
     response_text = query_gpt(prompt, api_key)
     print("AI Response:", response_text)
     ```

   **Learning Outcomes**:
   - Demonstrating how prompt templates can encapsulate basic agent behavior (guiding the AI on how to respond to user queries).
   - Understanding how the agent can be tweaked or extended based on more complex logic or conversational state management.

### 5. **Real-Time User Interaction and Dynamic Prompting**
   Once students grasp agent fundamentals, introduce real-time user input to dynamically generate and modify prompts based on user input. This could serve as the foundation for an interactive chatbot or assistant project.

   **Example**:
   - Build a simple loop where the user provides input, and the agent crafts a prompt and gets a response:
     ```python
     while True:
         task = input("What would you like help with today? ")
         if task.lower() in ['exit', 'quit']:
             break
         prompt = generate_prompt("Alice", task)
         response_text = query_gpt(prompt, api_key)
         print("AI Response:", response_text)
     ```

   **Learning Outcomes**:
   - Learning how to manage user interactions and dynamically construct prompts in real-time.
   - Combining string manipulation, templating, and basic I/O to create interactive applications.
   - Handling edge cases when user input may lead to undesired or unexpected model behavior (e.g., empty inputs or inappropriate tasks).

---

## Summary
By front-loading API interactions, string manipulation, and prompt engineering, students can start building useful applications immediately, which keeps them engaged and grounded in modern AI workflows. Introducing skills incrementally in this context builds a solid foundation for agent development without overwhelming them with control structures early on.

### Key Priorities in this Approach:
1. **API-first mindset**: Make interacting with LLMs the immediate focus.
2. **String manipulation**: Prioritize basic string operations and formatting.
3. **Templating**: Use [[Jinja2]] for reusable and dynamic prompt creation, which mirrors real-world use cases.
4. **Agent engineering**: Gradually build up to creating autonomous agents, focusing on prompt-driven logic rather than heavy control flow.

This strategy will help students learn Python in the context of building LLM-powered applications, preparing them for the growing relevance of LLMs in modern software systems.


---

preceding: [[teaching python through llm-driven applicationsuse-cases]]  


following: [[start simple and practical. this is a hello world assignment, we're not asking them to re-invent the wheel. `import openai` and get config arguments via `os.environ.get`]]

See also: [[edge case]]