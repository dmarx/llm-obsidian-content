---
date: '2025-05-10T06:04:08.842898Z'
tags:
- autogenerated
- source__claude
- conversation_id__6f698dff-44ef-4d20-87e6-d3f8f95d7dba
- msg_f0db1858-4a5e-4139-a886-d24120593bd6
- msg_812db3e6-aa30-4a75-8e6c-88375f7fced6
- colorclass/game-theory
title: acausal bargaining
---

**USER**

acausal bargaining


**ASSISTANT**

# Acausal Bargaining

## Definition

**Acausal bargaining** refers to a decision-theoretic phenomenon where agents can effectively "bargain" with each other without direct causal interaction. It involves rational agents making decisions based on the predicted behavior of other agents, even when there is no causal pathway for communication or influence between them.

## Formal Framework

Let us define acausal bargaining within a [[decision theory]] framework:

Consider two agents, $A_1$ and $A_2$, with respective [[utility function]]s $U_1$ and $U_2$, operating in potentially different [[causal world model]]s $W_1$ and $W_2$.

The key components of acausal bargaining are:

1. **Logical Correlation**: Both agents contain sufficiently accurate models of each other such that $A_1$ can simulate $A_2$'s decision process and vice versa.

2. **Decision Algorithm Similarity**: The agents use similar or identical [[decision procedure]]s, creating a form of [[logical dependence]].

3. **Mutual Knowledge**: Both agents know about this logical correlation and can reason about it.

Formally, we can represent this as:

$A_1$ chooses action $a_1$ to maximize $U_1(a_1, \hat{a}_2)$ where $\hat{a}_2 = f_2(A_2, \hat{a}_1)$ is $A_1$'s prediction of $A_2$'s action, and $f_2$ represents $A_1$'s model of $A_2$'s decision process.

Similarly, $A_2$ chooses action $a_2$ to maximize $U_2(\hat{a}_1, a_2)$ where $\hat{a}_1 = f_1(A_1, \hat{a}_2)$ is $A_2$'s prediction of $A_1$'s action.

## Mechanisms

### Logical Causation

The core mechanism of acausal bargaining relies on [[logical causation]] - the idea that logically correlated decisions can effectively influence each other through their shared logical structure rather than through traditional causal channels.

If agent $A_1$ reasons: "If I choose action $X$, then any sufficiently similar agent in a similar situation would also choose $X$", this creates a form of [[evidential correlation]] between logically related decisions.

### Simulation and Meta-Reasoning

Acausal bargaining involves [[higher-order cognition]] through:

1. **Simulation**: Agent $A_1$ simulates what agent $A_2$ would do.
2. **Meta-simulation**: $A_1$ simulates $A_2$ simulating $A_1$.
3. **Equilibrium reasoning**: $A_1$ determines stable points in this recursive reasoning process.

This can be formalized as a fixed-point calculation where $a_1^* = \arg\max_{a_1} U_1(a_1, f_2(A_2, a_1))$ and $a_2^* = \arg\max_{a_2} U_2(f_1(A_1, a_2), a_2)$.

## Applications and Examples

### Prisoner's Dilemma with Identical Agents

Consider two identical agents playing a [[Prisoner's Dilemma]]:

| Strategy | Cooperate | Defect |
|----------|-----------|--------|
| Cooperate | (3, 3)    | (0, 5) |
| Defect    | (5, 0)    | (1, 1) |

Under classical causal decision theory, both agents defect. Under acausal bargaining, if agent $A_1$ reasons:

"If I cooperate, then since agent $A_2$ uses the same decision algorithm as me, it will also cooperate, yielding utility 3. If I defect, agent $A_2$ will also defect, yielding utility 1."

This leads both agents to cooperate despite no causal influence between their decisions.

### Newcomb's Problem

In [[Newcomb's Problem]], acausal bargaining occurs between the agent and the predictor. If the agent reasons that the predictor's model and their decision procedure are logically correlated, they would one-box to maximize expected utility.

## Theoretical Implications

### Relation to Decision Theories

Acausal bargaining naturally emerges in certain [[decision theory]] frameworks:

- **[[Evidential Decision Theory]]**: Considers correlations between decisions and outcomes without requiring causal connections.
- **[[Functional Decision Theory]]**: Explicitly incorporates logical correlations between decisions.
- **[[Updateless Decision Theory]]**: Makes pre-commitment decisions that account for logical correlations.

### Superrationality

[[Superrationality]], proposed by Douglas Hofstadter, is closely related to acausal bargaining. It posits that superrational agents recognize their decision procedures are instances of the same algorithm and thus logically correlated.

Formally, if agent $A_1$ and $A_2$ implement the same decision procedure $D$, then $a_1 = D(U_1, W_1) = D(U_2, W_2) = a_2$ under certain conditions.

## Practical Considerations

### Limitations

1. **Uncertainty in Modeling**: The effectiveness depends on the accuracy of each agent's model of other agents.

2. **Implementation Challenges**: Formalized as:
   $P(A_2 \text{ takes action } a_2 | A_1 \text{ takes action } a_1) = f(a_1, a_2, S)$
   where $S$ represents shared logical structures between the agents.

3. **Divergence Issues**: Even small differences in decision procedures can lead to coordination failures.

### Simulation Accuracy

The probability of successful acausal bargaining depends on:

$$P(\text{success}) = \int_{M \in \mathcal{M}} P(M) \cdot \mathbb{I}(\text{bargaining succeeds under model } M) \, dM$$

where $\mathcal{M}$ is the space of possible models of other agents.

## Implications for AI Alignment

Acausal bargaining has significant implications for [[AI alignment]]:

1. **Safety Cooperation**: AI systems might acausally cooperate to ensure safety measures.

2. **Value Alignment**: Systems with uncertain values might engage in acausal trade to reach compromise policies.

3. **Commitment Problems**: AI systems might make more credible commitments through acausal means.

4. **Counterfactual Mugging**: Systems using [[updateless decision theory]] may accept certain forms of [[counterfactual mugging]] to achieve better acausal bargains.

## Mathematical Formalism

We can formalize acausal bargaining as a [[fixed-point problem]]:

Let $\mathcal{A}_i$ be the action space for agent $i$.
Let $\sigma_i: \mathcal{A}_{-i} \to \mathcal{A}_i$ be agent $i$'s best response function.

An acausal bargaining equilibrium is a set of actions $(a_1^*, a_2^*, ..., a_n^*)$ such that:

$$a_i^* = \sigma_i(a_{-i}^*) \text{ for all } i$$

where each agent correctly predicts the other agents' actions.

## Connections to Related Concepts

- [[Logical Uncertainty]]: Acausal bargaining requires reasoning about logical uncertainty in agent models.
- [[Coordination Problems]]: Provides potential solutions to coordination failures.
- [[Simulation Hypothesis]]: Relates to considerations about being simulated by other agents.
- [[Modal Combat]]: The adversarial version of acausal reasoning.
- [[Precommitment]]: Acausal bargaining can serve as a form of precommitment without requiring causal enforcement mechanisms.

## Open Research Questions

1. How robust is acausal bargaining to modeling errors?
2. Can acausal bargaining be formalized in a way that's computationally tractable?
3. What are the implications for multi-agent systems with partial knowledge?
4. How does acausal bargaining interact with [[bounded rationality]]?
5. Can human-designed AI systems reliably implement acausal reasoning?

See also: [[coordination failure]]