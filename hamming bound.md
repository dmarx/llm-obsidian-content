---
date: 1719333875.455623
tags:
- autogenerated
- source__oai
- conversation_id__b7c336c1-f2dc-4e0a-b2e0-bbe32516848b
- msg_aaa2305d-1b55-4451-a89e-82f5c6a40e62
- msg_1b3e4cb2-7adb-487a-b500-3c6f20fd2ec4
- colorclass/vector-space
title: hamming bound
---

**USER**

Hamming Bound


**ASSISTANT**

### Hamming Bound

The Hamming Bound, also known as the sphere-packing bound, is a fundamental limit in [[coding theory]] that gives an upper bound on the number of codewords in a block code for a given block length, code size, and minimum distance. It ensures that the codewords are sufficiently spaced apart to allow for error detection and correction.

#### Definition

For a block code of length \(n\), size \(M\), and minimum distance \(d\) over an alphabet with \(q\) symbols, the Hamming Bound is given by:
$$ M \leq \frac{q^n}{\sum_{i=0}^t \binom{n}{i} (q-1)^i}, $$
where:
- \(t = \left\lfloor \frac{d-1}{2} \right\rfloor\) is the maximum number of errors that can be corrected.
- \(\binom{n}{i}\) is a binomial coefficient representing the number of ways to choose \(i\) positions out of \(n\).
- \((q-1)^i\) is the number of ways to change \(i\) symbols in a codeword, since each symbol can be changed to \(q-1\) other symbols.

#### Derivation

The Hamming Bound is derived from the idea of packing spheres in the \(n\)-dimensional Hamming space, where each sphere represents the set of all possible received words that can be decoded to a given codeword.

1. **Hamming Distance**
   - The Hamming distance \(d_H(x, y)\) between two codewords \(x\) and \(y\) is the number of positions in which they differ. For example, if \(x = (x_1, x_2, \ldots, x_n)\) and \(y = (y_1, y_2, \ldots, y_n)\), then:
     $$ d_H(x, y) = \sum_{i=1}^n \delta(x_i, y_i), $$
     where \(\delta(x_i, y_i) = 1\) if \(x_i \neq y_i\) and \(0\) otherwise.

2. **Error Correction Capability**
   - A code with minimum distance \(d\) can correct up to \(t = \left\lfloor \frac{d-1}{2} \right\rfloor\) errors. This means that if the received word is within a Hamming distance of \(t\) from the original codeword, it can be correctly decoded.

3. **Sphere Packing**
   - The set of all words within a Hamming distance of \(t\) from a given codeword forms a Hamming sphere of radius \(t\). The number of words in such a sphere is:
     $$ V(n, t) = \sum_{i=0}^t \binom{n}{i} (q-1)^i. $$
   - The total number of distinct \(n\)-length sequences over a \(q\)-ary alphabet is \(q^n\).

4. **Packing Condition**
   - For the code to correct \(t\) errors, the Hamming spheres of radius \(t\) centered at each codeword must not overlap. Therefore, the number of codewords \(M\) times the volume of each sphere must be less than or equal to the total number of sequences:
     $$ M \cdot V(n, t) \leq q^n. $$

By rearranging, we get the Hamming Bound:
$$ M \leq \frac{q^n}{V(n, t)} = \frac{q^n}{\sum_{i=0}^t \binom{n}{i} (q-1)^i}. $$

#### Implications

1. **Code Design**
   - The Hamming Bound helps in designing codes by providing an upper limit on the number of codewords for a given code length and error-correcting capability. It ensures that the codewords are sufficiently separated to allow for reliable error correction.

2. **Optimal Codes**
   - Codes that achieve the Hamming Bound with equality are called perfect codes. These codes have the maximum possible number of codewords for a given minimum distance and are highly efficient in terms of error correction. Examples include Hamming codes and certain BCH codes.

3. **Error Detection and Correction**
   - The Hamming Bound highlights the trade-off between the code rate (number of information symbols relative to the total number of symbols) and the error-correcting capability. Increasing the error-correcting capability \(t\) generally requires reducing the code rate.

4. **Sphere-Packing Efficiency**
   - The bound provides insights into the efficiency of sphere packing in high-dimensional spaces, which is a central concept in both [[coding theory]] and other areas such as lattice theory and digital communications.

In summary, the Hamming Bound is a crucial tool in [[coding theory]] for understanding the limits of error-correcting codes. It guides the design and evaluation of codes, ensuring that they are capable of correcting a specified number of errors while maintaining efficient use of the coding space.


---

preceding: [[channel capacity]]  


following: [[singleton bound]]

See also: [[lattice theory]]