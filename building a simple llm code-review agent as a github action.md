---
date: 1726448421.353535
tags:
- autogenerated
- source__oai
- conversation_id__66e757d1-0534-8008-bb6a-afa8342b5ee2
- msg_01708218-b60f-499a-ace6-d238b27e3b0b
- msg_6939e2b9-ec6e-404a-9720-d853c8f02bac
- msg_aaa2916f-f2c6-4901-b84a-d7a79a38ad70
- colorclass/decision-making-processes
title: building a simple llm code-review agent as a github action
---

**ASSISTANT**

### **Building a Simple LLM Code-Review Agent as a GitHub Action**

In this assignment, we will build a **code-review agent** that integrates an **LLM (Large Language Model)** into a **GitHub Action**. This agent will analyze code changes in pull requests (PRs) and provide feedback based on criteria like readability, adherence to best practices, and potential bugs.

By using GitHub Actions, we can automate this process, allowing the LLM to comment on PRs in real-time as part of a CI/CD pipeline.

---

### **Overview of GitHub Actions**

**GitHub Actions** is a platform for automating tasks directly in GitHub repositories. It allows you to create workflows that automatically run when certain events (like a pull request or push) occur. In our case, the event will be triggered whenever a pull request is opened or updated.

The main components of a GitHub Action workflow are:
- **Triggers**: Define the event that will trigger the workflow, such as `pull_request` or `push`.
- **Jobs**: Define tasks or scripts to be executed when the workflow runs.
- **Steps**: Individual commands that make up a job, such as running tests, linting, or, in this case, calling an LLM to perform a code review.

---

### **Steps to Implement the LLM Code-Review Agent GitHub Action**

#### **Step 1: Create a GitHub Action Workflow**

We start by creating a new workflow in the GitHub repository. This workflow will run every time a **pull request** is opened or updated. The workflow will fetch the modified code and pass it to an LLM for review.

1. Inside your repository, create the following directory structure:
   ```bash
   .github/
       workflows/
           code-review.yml
   ```

2. Create a new file called `code-review.yml` in the `.github/workflows/` directory.

#### **Step 2: Define the Workflow Trigger and Jobs**

In `code-review.yml`, define the workflow to trigger on pull requests and execute the job to call the LLM code-review agent.

```yaml
name: Code Review with LLM

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  code-review:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Run LLM code review
        run: |
          python3 review_code.py
```

Here, the workflow:
- Triggers on `pull_request` events when a PR is opened or updated (`synchronize`).
- Checks out the code changes.
- Calls a Python script (`review_code.py`) that will interact with the LLM.

---

#### **Step 3: Interacting with the LLM**

We will now create the `review_code.py` script that sends the code diff to an LLM API (e.g., OpenAI's GPT model) and processes the review feedback.

1. Create the `review_code.py` script at the root of your repository.

```python
import os
import openai
from git import Repo

# Load the OpenAI API key from environment variables
openai.api_key = os.getenv("OPENAI_API_KEY")

# Function to retrieve the diff of the pull request
def get_pull_request_diff():
    repo = Repo('.')
    diff = repo.git.diff('origin/main...HEAD', '--unified=0')
    return diff

# Function to call OpenAI's GPT API for code review
def review_code_with_llm(code_diff):
    prompt = f"Review the following code diff and provide feedback:\n{code_diff}"

    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=prompt,
        max_tokens=500,
        temperature=0.7
    )

    return response.choices[0].text.strip()

# Main execution
if __name__ == "__main__":
    diff = get_pull_request_diff()
    if diff:
        review_feedback = review_code_with_llm(diff)
        print(f"LLM Code Review Feedback:\n{review_feedback}")
    else:
        print("No code changes found.")
```

#### **Explanation**:
- **`get_pull_request_diff()`**: Uses the `gitpython` library to get the code differences (diff) between the pull request branch and the `main` branch.
- **`review_code_with_llm()`**: Sends the code diff to an LLM (OpenAI GPT-3 in this case) using the OpenAI API and gets feedback.
- **OpenAI API**: Make sure your OpenAI API key is available in your GitHub secrets (we'll set this up in the next step).

---

#### **Step 4: Add the OpenAI API Key to GitHub Secrets**

To securely store the **OpenAI API key** needed for making requests, weâ€™ll use **GitHub Secrets**:

1. In your GitHub repository, go to **Settings** > **Secrets and variables** > **Actions**.
2. Click **New repository secret**.
3. Name the secret `OPENAI_API_KEY` and paste your OpenAI API key as the value.

Now the workflow will have access to the API key.

---

#### **Step 5: Posting Feedback to the Pull Request**

Next, we will modify the workflow to post the LLM's review feedback directly to the pull request as a comment. This requires using GitHub's API.

Update the `review_code.py` script to use GitHub's REST API to comment on the pull request.

```python
import os
import openai
import requests
from git import Repo

# Load environment variables
openai.api_key = os.getenv("OPENAI_API_KEY")
github_token = os.getenv("GITHUB_TOKEN")
repo_name = os.getenv("GITHUB_REPOSITORY")
pr_number = os.getenv("GITHUB_PULL_REQUEST_NUMBER")

# Function to retrieve the diff of the pull request
def get_pull_request_diff():
    repo = Repo('.')
    diff = repo.git.diff('origin/main...HEAD', '--unified=0')
    return diff

# Function to call OpenAI's GPT API for code review
def review_code_with_llm(code_diff):
    prompt = f"Review the following code diff and provide feedback:\n{code_diff}"

    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=prompt,
        max_tokens=500,
        temperature=0.7
    )

    return response.choices[0].text.strip()

# Function to post a comment to the pull request
def post_comment_to_pr(comment):
    url = f"https://api.github.com/repos/{repo_name}/issues/{pr_number}/comments"
    headers = {
        "Authorization": f"token {github_token}",
        "Content-Type": "application/json",
    }
    data = {
        "body": comment
    }
    response = requests.post(url, json=data, headers=headers)
    if response.status_code == 201:
        print("Successfully posted review comment.")
    else:
        print(f"Failed to post comment: {response.content}")

# Main execution
if __name__ == "__main__":
    diff = get_pull_request_diff()
    if diff:
        review_feedback = review_code_with_llm(diff)
        comment = f"LLM Code Review Feedback:\n{review_feedback}"
        post_comment_to_pr(comment)
    else:
        print("No code changes found.")
```

#### **Explanation**:
- **GitHub API**: We use GitHub's REST API to post a comment to the pull request, which contains the feedback from the LLM.
- **GITHUB_TOKEN**: GitHub Actions provides a default authentication token (`secrets.GITHUB_TOKEN`) to authenticate API calls. We'll make sure to pass this to the script.

---

#### **Step 6: Update the GitHub Action Workflow**

Now, update the `code-review.yml` to pass the necessary environment variables and allow the Python script to comment on the pull request.

```yaml
name: Code Review with LLM

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  code-review:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Run LLM code review
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_PULL_REQUEST_NUMBER: ${{ github.event.pull_request.number }}
        run: |
          python3 review_code.py
```

#### **Explanation**:
- **Environment Variables**: We pass the necessary GitHub and OpenAI environment variables into the script. These include the `GITHUB_TOKEN` for API authentication, and `GITHUB_PULL_REQUEST_NUMBER` for identifying which PR to comment on.

---

### **Step 7: Test the Code-Review Action**

1. Commit and push the workflow and scripts to your repository.
2. Open a new pull request or update an existing one.

Once the pull request is created or updated, the GitHub Action will automatically run, fetch the code diff, pass it to the LLM for review, and post feedback as a comment on the pull request.

#### **Example Output in Pull Request Comment**:
```markdown
LLM Code Review Feedback:
- The indentation in `main.py` could be improved for better readability.
- Consider using list comprehensions to simplify the code in `data_processing.py`.
- In `config.yaml`, avoid hardcoding values. Use environment variables instead.
```

---

### **Advantages of LLM-Based Code Review**

1. **Automated Feedback**: The LLM provides automated code review


**ASSISTANT**

feedback that can detect common issues such as coding style, readability, and potential bugs.
2. **Scalability**: This system can be easily scaled to review large numbers of PRs across different repositories.
3. **Consistency**: LLM agents provide consistent feedback across different PRs, ensuring that the same standards are applied to all contributors.

---

### **Further Enhancements**

- **Customization**: Tailor the prompt given to the LLM to focus on specific types of feedback, such as security vulnerabilities, performance optimizations, or language-specific best practices.
- **Improved Diff Handling**: Handle more complex diffs, such as binary files or large-scale code changes, by refining the diff retrieval process.
- **Multi-File Reviews**: Enhance the agent to provide per-file feedback and comment directly on specific lines of code using GitHub's API.

---

### **Summary**

In this assignment, we implemented a **simple LLM-based code-review agent** integrated as a **GitHub Action**. By leveraging the power of **LLMs** and GitHub's API, we automated the process of reviewing code in pull requests, providing real-time feedback directly in the pull request comments. This workflow provides developers with actionable insights into their code, ensuring higher code quality and efficiency in development processes.


**USER**

llm "loom" tools and branching prompts


---

preceding: [[monte carlo tree search (mcts) in the context of ai and llm agentic systems]]  


following: [[llm loom tools and branching prompts]]