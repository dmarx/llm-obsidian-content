---
date: 1716501396.963166
tags:
- autogenerated
- source__oai
- conversation_id__0e0f4346-9be9-487d-a32b-5c43038ff0fc
- msg_aaa217f6-7993-4f40-9c74-3f9172ef75a8
- msg_2a00839a-4d0c-4368-ba36-e4f7c212764f
- colorclass/information-theory
title: hierarchical bayesian estimation of the drift-diffusion model
---

**USER**

Hierarchical Bayesian Estimation of the Drift-Diffusion Model


**ASSISTANT**

Hierarchical Bayesian estimation is a powerful method for estimating the parameters of the [[Ratcliff Diffusion Model]] (RDM), especially when dealing with data from multiple subjects or conditions. This approach allows for the modeling of both individual and group-level variations in parameters, providing more nuanced and reliable estimates.

### Overview of Hierarchical Bayesian Estimation

Hierarchical Bayesian models incorporate multiple levels of random effects, capturing variability at both the individual and group levels. In the context of the RDM, this means estimating the parameters (e.g., drift rate \( v \), boundary separation \( a \), non-decision time \( T_{er} \)) for each participant while simultaneously estimating the population-level distributions of these parameters.

### Model Specification

#### Individual-Level Model

For each participant \( i \) and trial \( j \), the RDM specifies the decision time \( RT_{ij} \) and choice \( C_{ij} \) as follows:

1. **Drift Rate**: \( v_i \)
2. **Boundary Separation**: \( a_i \)
3. **Starting Point**: \( z_i \) (usually \( z_i \sim \mathcal{U}(0, a_i) \))
4. **Non-Decision Time**: \( T_{er,i} \)

The likelihood of observing a response time \( RT_{ij} \) and choice \( C_{ij} \) given these parameters can be denoted as \( P(RT_{ij}, C_{ij} \mid v_i, a_i, z_i, T_{er,i}) \).

#### Group-Level Model

At the group level, we assume that individual parameters are drawn from population-level distributions:

- Drift rate: \( v_i \sim \mathcal{N}(\mu_v, \sigma_v^2) \)
- Boundary separation: \( a_i \sim \mathcal{N}(\mu_a, \sigma_a^2) \)
- Non-decision time: \( T_{er,i} \sim \mathcal{N}(\mu_{T_{er}}, \sigma_{T_{er}}^2) \)

The group-level hyperparameters \( \mu_v, \sigma_v, \mu_a, \sigma_a, \mu_{T_{er}}, \sigma_{T_{er}} \) describe the means and variances of these distributions.

### Bayesian Inference

Bayesian inference involves updating prior beliefs about the parameters with observed data to obtain posterior distributions. The hierarchical model can be represented as:

\[ P(\theta, \eta \mid \text{data}) \propto P(\text{data} \mid \theta) P(\theta \mid \eta) P(\eta) \]

where:
- \( \theta \) represents the individual-level parameters \((v_i, a_i, T_{er,i})\)
- \( \eta \) represents the group-level hyperparameters \((\mu_v, \sigma_v, \mu_a, \sigma_a, \mu_{T_{er}}, \sigma_{T_{er}})\)

### Steps for Hierarchical Bayesian Estimation

1. **Specify Priors**: Choose appropriate prior distributions for the individual-level parameters and group-level hyperparameters. For example:
   - \( \mu_v \sim \mathcal{N}(0, 1) \)
   - \( \sigma_v \sim \text{Half-Cauchy}(0, 1) \)
   - Similar priors for \( \mu_a, \sigma_a, \mu_{T_{er}}, \sigma_{T_{er}} \)

2. **Define the Model**: Use a probabilistic programming language like Stan or JAGS to specify the hierarchical model, including the likelihood function and priors.

3. **Sample from the Posterior**: Use Markov Chain Monte Carlo (MCMC) methods to draw samples from the posterior distribution of the parameters. Tools like Stan provide efficient algorithms (e.g., Hamiltonian Monte Carlo) for this purpose.

4. **Posterior Analysis**: Analyze the posterior samples to obtain point estimates (e.g., means, medians) and credible intervals for the parameters. Assess the convergence of the MCMC chains using diagnostics like trace plots and the Gelman-Rubin statistic.

### Example Model in Stan

Here's a simplified example of how the hierarchical RDM could be implemented in Stan:

```stan
data {
  int<lower=0> N; // number of trials
  int<lower=0> J; // number of subjects
  int<lower=0, upper=1> C[N]; // choices
  real RT[N]; // response times
  int<lower=1, upper=J> subj[N]; // subject index
}

parameters {
  real<lower=0> mu_v;
  real<lower=0> sigma_v;
  real<lower=0> mu_a;
  real<lower=0> sigma_a;
  real<lower=0> mu_T_er;
  real<lower=0> sigma_T_er;

  vector[J] v;
  vector<lower=0>[J] a;
  vector<lower=0>[J] T_er;
}

model {
  // Priors
  mu_v ~ normal(0, 1);
  sigma_v ~ cauchy(0, 1);
  mu_a ~ normal(0, 1);
  sigma_a ~ cauchy(0, 1);
  mu_T_er ~ normal(0, 1);
  sigma_T_er ~ cauchy(0, 1);

  // Hierarchical structure
  v ~ normal(mu_v, sigma_v);
  a ~ normal(mu_a, sigma_a);
  T_er ~ normal(mu_T_er, sigma_T_er);

  // Likelihood
  for (n in 1:N) {
    RT[n] ~ diffusion_likelihood(v[subj[n]], a[subj[n]], T_er[subj[n]], C[n]);
  }
}

```

In this example, `diffusion_likelihood` would be a user-defined function implementing the likelihood for the RDM given the parameters.

### Conclusion

Hierarchical Bayesian estimation provides a flexible and powerful framework for estimating the parameters of the [[Ratcliff Diffusion Model]]. By capturing both individual and group-level variability, it offers more robust and interpretable insights into cognitive processes underlying decision-making. Advanced software tools like Stan facilitate the implementation of such models, making it accessible for researchers to apply hierarchical Bayesian methods in their analyses.


---

preceding: [[linear ballistic accumulator]]