---
date: '2025-01-20T23:07:15.433002Z'
tags:
- autogenerated
- source__claude
- conversation_id__34097685-a4cb-47b6-b184-9cebb982ebfa
- msg_5cdda3c4-8fda-4645-b7f2-bcfa119bec52
- msg_36242075-0b6b-4e8d-b0f2-596b4ec61cd3
- colorclass/information-theory
title: information decomposition
---

**USER**

Information Decomposition


**ASSISTANT**

# Information Decomposition

[[Information decomposition]] provides a framework for analyzing how multiple sources jointly contribute to information about a target. This theory addresses the fundamental question of how [[information]] can be shared, unique, or emergent from interactions between variables.

## Mathematical Framework

### [[Partial Information Decomposition]] (PID)

For predictor variables X₁, X₂ and target variable Y, the total [[mutual information]] decomposes as:

I(X₁,X₂;Y) = UI(X₁\X₂;Y) + UI(X₂\X₁;Y) + RI(X₁,X₂;Y) + SI(X₁,X₂;Y)

where:
- UI: [[Unique Information]]
- RI: [[Redundant Information]]
- SI: [[Synergistic Information]]

### [[Axioms of Decomposition]]

1. [[Self-Redundancy]]: I(X;Y) = UI(X\∅;Y) + RI(X;Y)
2. [[Monotonicity]]: RI(X₁,X₂;Y) ≤ min[I(X₁;Y), I(X₂;Y)]
3. [[Symmetry]]: UI(X₁\X₂;Y) = UI(X₂\X₁;Y) when X₁ and X₂ are exchangeable
4. [[Identity Property]]: RI(X,X;Y) = I(X;Y)

## Measures and Methods

### [[Minimal Information]] Approach
Defines redundancy as:

RI_min(X₁,X₂;Y) = min[I(X₁;Y), I(X₂;Y)]

### [[Common Change in Surprise]]
Measures redundancy through shared local information:

RI_∩(X₁,X₂;Y) = ∑ p(x₁,x₂,y) min[i(x₁;y), i(x₂;y)]

where i(x;y) represents [[local mutual information]].

## Applications

### [[Neural Coding]]
- [[Population Coding]] analysis
- [[Neural Redundancy]] estimation
- [[Stimulus Encoding]] patterns

### [[Gene Regulation]]
- [[Regulatory Network]] analysis
- [[Pathway Redundancy]]
- [[Combinatorial Control]]

### [[Complex Systems]]
- [[Emergent Behavior]] detection
- [[Collective Information]] processing
- [[Multi-agent Systems]] analysis

## Theoretical Extensions

### [[Multivariate Decomposition]]
Generalizes to n variables through [[lattice theory]]:
- [[Redundancy Lattice]]
- [[Synergy Lattice]]
- [[Integration Lattice]]

### [[Dynamic Information Decomposition]]
Incorporates temporal aspects:
- [[Time-delayed Mutual Information]]
- [[Transfer Entropy Decomposition]]
- [[Causal Information Decomposition]]

This framework provides essential tools for understanding [[complex interactions]], [[distributed computation]], and [[emergent phenomena]] in multivariate systems.


---

preceding: [[information dynamics]]  


following: [[lattice theory]]

See also: [[contextual emergence]]


See also: [[transfer entropy]]


See also: [[excess entropy (dual total correlation)]]


See also: [[partial information decomposition]]


See also: [[scale in the context of information]]


See also: [[transfer entropy measuring directed information flow]]