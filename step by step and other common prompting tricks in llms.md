---
date: 1726445824.019985
tags:
- autogenerated
- source__oai
- conversation_id__66e757d1-0534-8008-bb6a-afa8342b5ee2
- msg_5a3bce62-fc54-4b74-bd00-af2e30fa9166
- msg_4b61f961-ed4a-4b34-a349-9d254a5ad5a8
- msg_a91085c6-9d5d-425b-8113-e3f2e20b714c
- colorclass/target-audience
title: step by step and other common prompting tricks in llms
---

**ASSISTANT**

### **"Step by Step" and Other Common Prompting Tricks in LLMs**

In large language models (LLMs), especially those like GPT, **prompt engineering** plays a critical role in guiding the model toward generating more accurate, coherent, and useful outputs. With the right prompting techniques, you can improve the model's reasoning, creativity, or specificity for various tasks. This approach is particularly important when working with models that don’t have explicit access to structured reasoning or task decomposition.

This guide will explore **common prompting tricks** like **"step by step"**, **"let's think about this"**, and other strategies that can help you get more reliable and thoughtful responses from LLMs.

---

### **1. "Step by Step" Prompts**

The **"step by step"** prompting technique encourages the model to break down a complex task or problem into smaller, logical steps. This is especially useful in tasks involving multi-step reasoning, problem-solving, or generating long-form content.

#### **Why It Works**:
When you explicitly instruct the model to think "step by step," it reduces the likelihood of skipping important details or arriving at premature conclusions. It forces the model to focus on each intermediate step before jumping to the final output.

#### **Example Prompt**:
**Task**: Solve a math word problem.

- **Without "step by step"**: 
  - **Prompt**: "What is the total cost if 3 apples cost $2 each and 2 bananas cost $1 each?"
  - **Model Response**: "The total cost is $8."
  
  (This answer may be correct, but it doesn’t explain the reasoning process.)

- **With "step by step"**:
  - **Prompt**: "What is the total cost if 3 apples cost $2 each and 2 bananas cost $1 each? Please solve it step by step."
  - **Model Response**: "Step 1: Calculate the cost of apples: 3 apples × $2 = $6. Step 2: Calculate the cost of bananas: 2 bananas × $1 = $2. Step 3: Add the two amounts: $6 + $2 = $8. The total cost is $8."

By guiding the model to reason through each step explicitly, you ensure transparency in the reasoning process and reduce errors caused by missing steps.

---

### **2. "Let's Think" or "Let's Think Step by Step" Prompts**

Another variation of "step by step" prompting is starting with phrases like **"Let's think about this step by step"** or **"Let's think carefully"**. These signals prompt the model to engage in deeper reasoning.

#### **Why It Works**:
Models trained on large corpora of text often pick up common patterns of reasoning. By suggesting that the model "think carefully," you can tap into these patterns and prompt the model to reason in a more structured manner, as it has often seen such phrases associated with logical and careful explanations.

#### **Example Prompt**:
**Task**: Solve a logic puzzle.

- **Without prompt**: 
  - **Prompt**: "If a rooster lays an egg on the roof of a barn, which way will it roll off?"
  - **Model Response**: "It will roll down the slope."
  
  (This is incorrect because roosters don’t lay eggs.)

- **With "Let's think step by step"**:
  - **Prompt**: "If a rooster lays an egg on the roof of a barn, which way will it roll off? Let's think step by step."
  - **Model Response**: "Step 1: Roosters are male chickens. Step 2: Only hens lay eggs, not roosters. Therefore, the premise is false, and no egg will be laid."

By asking the model to think through the problem, it identifies that the premise is flawed, producing a more accurate response.

---

### **3. "Chain of Thought" Prompts**

The **"Chain of Thought (CoT)"** prompting technique is similar to "step by step," but with more emphasis on **reasoning chains** where each part of the reasoning is linked to the next. This is particularly effective for complex reasoning tasks like mathematical problems, logical deductions, or even detailed explanations of concepts.

#### **Why It Works**:
Breaking a problem into smaller, interconnected chunks allows the model to focus on reasoning sequentially rather than skipping steps. This reduces the chances of logical inconsistencies.

#### **Example Prompt**:
**Task**: Solve a riddle.

- **Prompt**: "A man is found dead in a room with 53 bicycles. How did he die? Provide a chain of thought."
  
  **Model Response**: "Step 1: The mention of 53 bicycles is unusual, as bicycles generally refer to two-wheeled vehicles. Step 2: The key here is that 'bicycles' could be referring to something else. Step 3: In card games, the 'bicycle' is a brand of playing cards. Step 4: 52 cards are standard, and the 53rd 'bicycle' could refer to a joker card. Conclusion: The man might have died in a gambling-related event, and 'bicycles' refer to cards."

The model engages in **associative reasoning**, connecting ideas to reach a plausible conclusion.

---

### **4. "Explain Like I'm 5" (ELI5)** Prompts

The **"Explain Like I'm 5" (ELI5)** prompt encourages the model to simplify complex topics, making them accessible and understandable for a broad audience. It’s particularly useful when you need simplified explanations of difficult or technical topics.

#### **Why It Works**:
By using ELI5 prompts, the model is prompted to avoid jargon, break down complex ideas into smaller parts, and communicate in clear, concise terms.

#### **Example Prompt**:
**Task**: Explain a scientific concept.

- **Prompt**: "Can you explain how nuclear fusion works, but explain it like I'm 5?"
  
  **Model Response**: "Sure! Imagine the sun is like a big oven. Inside, little things called atoms get squished together really, really tightly, and when they stick, they make a lot of energy, kind of like fireworks! That’s what gives the sun its heat and light."

By prompting the model to simplify the concept, you get a clearer and more approachable explanation, even for complex topics.

---

### **5. "Show Your Work" Prompts**

The **"show your work"** prompt is frequently used in mathematics, problem-solving, or explanation tasks. It’s similar to the **"step by step"** approach but explicitly focuses on making the model generate intermediate calculations or reasoning as part of the solution.

#### **Why It Works**:
Encouraging the model to "show its work" reduces the chances of generating an incorrect or oversimplified final answer. By going through each step, the model is less likely to make arithmetic or reasoning errors.

#### **Example Prompt**:
**Task**: Solve a math problem.

- **Prompt**: "What is the area of a triangle with base 5 and height 10? Show your work."
  
  **Model Response**: "Step 1: The formula for the area of a triangle is (1/2) × base × height. Step 2: Plug in the values: (1/2) × 5 × 10 = 25. Step 3: The area of the triangle is 25 square units."

---

### **6. "Roleplay" Prompts**

Roleplay prompting is particularly useful for dialogue systems, where you can assign a specific role or persona to the model (e.g., acting as a teacher, doctor, assistant). This trick helps guide the model to provide more tailored and domain-specific answers.

#### **Why It Works**:
LLMs are trained on large datasets that contain various contexts. By specifying a role, you are framing the context for the model, leading it to generate responses more aligned with the persona or expertise.

#### **Example Prompt**:
**Task**: Explain a medical condition.

- **Prompt**: "You are a doctor. Explain the symptoms of diabetes to a patient."
  
  **Model Response**: "As your doctor, I can explain that diabetes is a condition where your body doesn’t make enough insulin or can’t use it properly. Common symptoms include excessive thirst, frequent urination, fatigue, and blurred vision."

The model tailors its response to fit the role, offering a more authoritative and focused explanation.

---

### **7. "Teach Back" Prompts**

The **"teach back"** prompt technique involves asking the model to explain or "teach" a concept after it has provided a response. This ensures the model not only generates an answer but also confirms understanding by reiterating the key points.

#### **Why It Works**:
Asking the model to teach back or explain helps reinforce the accuracy of the initial answer and encourages the model to reflect on its reasoning process. It can be particularly useful for educational purposes or when confirming comprehension.

#### **Example Prompt**:
**Task**: Explain a historical event.

- **Prompt**: "Explain the cause of the American Revolution. Now, imagine you’re teaching a student and summarize what you just said."
  
  **Model Response**: "The American Revolution started because the American colonies were frustrated by British taxes and lack of representation. They wanted independence from British rule. In summary, the colonies rebelled because they were being taxed without having a say in the government."

By repeating and summarizing the explanation, the model strengthens its response.

---

### **8. "Provide Alternatives" Prompts**

The **"provide alternatives"** prompt encourages the model to generate multiple options, solutions, or perspectives on a given task. It’s particularly useful for creative writing, brainstorming, or decision-making tasks


**ASSISTANT**

where different possibilities need to be considered.

#### **Why It Works**:
This technique encourages the model to think beyond the first solution and present other possible answers, allowing users to compare or choose the best option.

#### **Example Prompt**:
**Task**: Write different opening lines for a novel.

- **Prompt**: "Give me three different ways to start a science fiction novel."
  
  **Model Response**: 
  - "Option 1: The first time humanity made contact with alien life, it wasn’t through a message in the stars. It was a message left on Earth."
  - "Option 2: Commander Voss watched the ship's last fuel cell flicker. They were 500 million miles from home, and the energy crisis had just begun."
  - "Option 3: On a planet where time runs backward, the future was already written, but not for Alys."

The model provides diverse options for the task, giving the user flexibility.

---

### **9. "Simulate Conversations" Prompts**

This technique involves instructing the model to simulate conversations between different personas or entities. It’s particularly useful in dialogue systems, role-playing scenarios, or for generating creative writing (e.g., fictional dialogues).

#### **Why It Works**:
By providing the model with a prompt to simulate a conversation, it mimics natural interactions and can explore multiple perspectives or points of view in a dynamic way.

#### **Example Prompt**:
**Task**: Simulate a dialogue between a student and a teacher.

- **Prompt**: "Simulate a conversation between a student and a teacher where the student asks about the causes of climate change."
  
  **Model Response**:
  - **Student**: "What causes climate change?"
  - **Teacher**: "Climate change is mainly caused by the increase in greenhouse gases in the atmosphere. These gases trap heat from the sun, warming the Earth."
  - **Student**: "How do we reduce greenhouse gases?"
  - **Teacher**: "We can reduce them by using cleaner energy sources like wind or solar, driving less, and reducing waste."

This prompt encourages the model to generate a multi-turn conversation with fluid responses.

---

### **Learning Outcomes**

1. **Refining Prompts**: Students will learn how small changes in prompt wording can significantly impact the quality of the model's output.
   
2. **Structured Reasoning**: Techniques like **"step by step"** and **"chain of thought"** help guide the model to reason more logically and accurately.

3. **Multiple Use Cases**: These prompting techniques can be applied across a variety of domains, from problem-solving in mathematics to creative writing or complex decision-making.
   
4. **Interactive Dialogues**: Techniques like **roleplay** and **conversation simulation** are useful for generating more natural, interactive dialogues between users and LLMs.

---

### **Assignment Extension Ideas**

1. **Experiment with Prompts**: Explore how different prompting techniques (e.g., "ELI5", "step by step", "show your work") affect the model's response quality on different types of tasks (e.g., math problems, creative writing, technical explanations).
   
2. **Multi-Step Complex Problems**: Create multi-step problems that require structured reasoning (e.g., solving logic puzzles, multi-stage workflows), and apply "chain of thought" and "show your work" prompts.

3. **Simulating Debates**: Using roleplay and simulation prompts, generate a conversation between two personas (e.g., a debate on a controversial topic) and compare how the model handles different perspectives.

---

### **Summary**

By applying **prompt engineering** techniques like **"step by step"**, **"chain of thought"**, **"explain like I’m 5"**, and others, you can guide LLMs to generate better, more logical, and contextually appropriate responses. These techniques allow for deeper reasoning, clearer explanations, and more interactive dialogues, making LLMs more powerful and adaptable across a wide range of tasks. Prompt engineering not only enhances the model's performance but also makes it more useful in real-world applications.


**USER**

brainstorming with llms


---

preceding: [[step by step and other common prompting tricks]]  


following: [[brainstorming with large language models (llms)]]

See also: [[step by step and other common prompting tricks]]