---
date: 1717826770.107677
tags:
- autogenerated
- source__oai
- conversation_id__ac8c3253-a669-4989-bf7c-c535d52c8140
- msg_aaa255c9-10cb-4b70-b29d-f63837524ca4
- msg_c302d9e5-ecce-4467-827d-7503705f60c5
- msg_aaa2b942-33bc-4ca6-a21f-7e5d29b5432f
- msg_748863af-bfd9-414a-bfac-400848824ec0
- colorclass/vector-space
title: upper hessenberg form
---

**USER**

upper Hessenberg form


**ASSISTANT**

An upper Hessenberg matrix is a square matrix that has zero entries below the first subdiagonal. Formally, a matrix \(H \in \mathbb{R}^{n \times n}\) is in upper Hessenberg form if \(h_{ij} = 0\) for all \(i > j + 1\). This structure allows for more efficient numerical algorithms, especially for eigenvalue problems and solving linear systems.

## Definition

A matrix \(H = (h_{ij})\) is in upper Hessenberg form if:

$$
h_{ij} = 0 \quad \text{for} \quad i > j + 1
$$

Explicitly, this means \(H\) looks like:

$$
H = \begin{pmatrix}
h_{11} & h_{12} & h_{13} & \cdots & h_{1n} \\
h_{21} & h_{22} & h_{23} & \cdots & h_{2n} \\
0 & h_{32} & h_{33} & \cdots & h_{3n} \\
0 & 0 & h_{43} & \cdots & h_{4n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & h_{nn}
\end{pmatrix}
$$

## Properties

1. **Tridiagonal as a Special Case**: An upper Hessenberg matrix becomes a tridiagonal matrix if it is also lower Hessenberg, meaning that \(h_{ij} = 0\) for \(i < j - 1\).
2. **Structure**: The upper Hessenberg form retains some sparsity of the matrix while making it easier to perform certain numerical operations.
3. **Stability**: Many numerical algorithms, such as the QR algorithm for eigenvalue decomposition, become more stable and efficient when applied to upper Hessenberg matrices.

## Applications

### QR Algorithm

The QR algorithm, used to find eigenvalues of a matrix, works more efficiently when the matrix is in upper Hessenberg form. The algorithm involves the following steps:

1. **Hessenberg Reduction**: Transform the original matrix \(A\) into an upper Hessenberg matrix \(H\) using orthogonal similarity transformations.
2. **QR Iteration**: Apply the QR iteration to \(H\):
   - Compute the QR decomposition of \(H\): \(H = QR\).
   - Form the next matrix: \(H_{k+1} = RQ\).

### Arnoldi Iteration

The Arnoldi iteration generalizes the Lanczos algorithm for non-symmetric matrices and reduces a general square matrix to upper Hessenberg form. The steps are:

1. **Initialization**:
   - Choose an initial vector \(v_1\) such that \(\|v_1\| = 1\).
   - Compute \(w = Av_1\).

2. **Orthogonalization**:
   - Orthogonalize \(w\) against \(v_1\):
     $$ h_{11} = v_1^T w $$
     $$ w = w - h_{11} v_1 $$
   - Compute \(h_{21} = \|w\|\).
   - Normalize: \(v_2 = \frac{w}{h_{21}}\).

3. **Iteration** (for \(j = 2, 3, \ldots, m\)):
   - Compute \(w = Av_j\).
   - Orthogonalize \(w\) against \(\{v_1, v_2, \ldots, v_j\}\):
     $$ h_{ij} = v_i^T w \quad \text{for } i = 1, 2, \ldots, j $$
     $$ w = w - \sum_{i=1}^j h_{ij} v_i $$
   - Compute \(h_{j+1,j} = \|w\|\).
   - Normalize: \(v_{j+1} = \frac{w}{h_{j+1,j}}\).

The resulting matrix \(H_m\) is an \(m \times m\) upper Hessenberg matrix that approximates the behavior of the original matrix \(A\).

### Numerical Example

Consider a matrix \(A\):

$$
A = \begin{pmatrix}
4 & 1 & 0 \\
1 & 4 & 1 \\
0 & 1 & 4
\end{pmatrix}
$$

To reduce \(A\) to upper Hessenberg form using Householder transformations:

1. **Householder Transformation**: Compute the first Householder vector to zero out the subdiagonal elements below \(a_{21}\).
   - Define \(x = \begin{pmatrix} 1 & 0 \end{pmatrix}^T\), the subvector of the first column below the diagonal.
   - Compute the Householder vector \(v = x + \|x\|e_1\).
   - Form the Householder matrix \(H_1 = I - 2vv^T / v^Tv\).

2. **Apply Transformation**:
   - Compute \(H_1A\).
   - Apply \(H_1\) on the left to zero out the subdiagonal elements below \(a_{21}\).

After a series of such transformations, the matrix \(A\) is reduced to upper Hessenberg form \(H\).

## Related Topics

- [[Householder Transformation]]: A method to zero out specific elements of vectors or matrices.
- [[QR Decomposition]]: Factorizes a matrix into an orthogonal matrix \(Q\) and an upper triangular matrix \(R\).
- [[Schur Decomposition]]: Reduces a matrix to upper triangular form via unitary transformations, often starting from an upper Hessenberg form.

Understanding the upper Hessenberg form is crucial for efficient implementation of eigenvalue algorithms and iterative methods in numerical linear algebra.


**USER**

>Many numerical algorithms, such as the QR algorithm for eigenvalue decomposition, become more stable and efficient when applied to upper Hessenberg matrices
elaborate


**ASSISTANT**

Applying numerical algorithms such as the QR algorithm to upper Hessenberg matrices enhances their stability and efficiency due to several key factors related to the structure and properties of these matrices. Let's delve deeper into the reasons:

## Structure and Sparsity

### Reduced Complexity

1. **Tridiagonal Structure for Symmetric Matrices**: For symmetric matrices, the upper Hessenberg form becomes tridiagonal. This significantly reduces the number of non-zero elements, making operations like matrix multiplication and QR decomposition computationally less expensive.
   
2. **Sparse Non-Symmetric Matrices**: For non-symmetric matrices, the upper Hessenberg form ensures that most elements below the first subdiagonal are zero. This sparsity improves computational efficiency by focusing on a smaller number of non-zero elements.

### Stability and Efficiency in QR Algorithm

The QR algorithm, used to compute the eigenvalues and eigenvectors of a matrix, operates more efficiently on upper Hessenberg matrices due to the following reasons:

1. **Efficient QR Decomposition**:
   - When decomposing an upper Hessenberg matrix \(H\) into \(QR\) (where \(Q\) is orthogonal and \(R\) is upper triangular), only \(O(n^2)\) operations are required instead of \(O(n^3)\) for a general matrix. This is because \(H\) has only \(2n-1\) non-zero elements to consider.
   - Specifically, Givens rotations or Householder reflections can be applied more efficiently, leveraging the zero entries below the first subdiagonal.

2. **QR Iteration**:
   - In each iteration of the QR algorithm, the matrix is factored as \(A_k = Q_k R_k\) and then updated as \(A_{k+1} = R_k Q_k\). For an upper Hessenberg matrix, this process preserves the Hessenberg form, avoiding the introduction of fill-in (non-zero elements where there were originally zeros).
   - This preservation means that subsequent iterations remain computationally efficient, as the Hessenberg structure is maintained throughout.

3. **Numerical Stability**:
   - The inherent structure of upper Hessenberg matrices reduces the likelihood of numerical instability, such as rounding errors and loss of orthogonality in the orthogonal matrix \(Q\). These issues can be more pronounced in full, dense matrices.
   - The reduced number of operations and simpler structure help mitigate error propagation, making the QR algorithm more stable when dealing with upper Hessenberg matrices.

## Process of Reduction to Upper Hessenberg Form

### Householder Transformations

1. **Step-by-Step Reduction**:
   - The process of reducing a general matrix \(A\) to upper Hessenberg form involves a sequence of Householder transformations. Each transformation zeros out elements below the subdiagonal in a systematic way.
   - This reduction requires \(O(n^3)\) operations, similar to matrix-matrix multiplication, but itâ€™s a one-time preprocessing step before applying the QR algorithm.

2. **Preservation of Eigenvalues**:
   - Householder transformations are orthogonal, thus preserving the eigenvalues of the original matrix \(A\). The eigenvalues of the resulting Hessenberg matrix \(H\) are the same as those of \(A\), ensuring that the reduction does not affect the accuracy of the eigenvalue computation.

### Example

Consider a matrix \(A\):

$$
A = \begin{pmatrix}
4 & 1 & 0 & 0 \\
1 & 4 & 1 & 0 \\
0 & 1 & 4 & 1 \\
0 & 0 & 1 & 4
\end{pmatrix}
$$

To apply the QR algorithm:

1. **Reduction to Hessenberg Form**:
   - Apply Householder transformations to reduce \(A\) to upper Hessenberg form \(H\). For symmetric matrices like \(A\), \(H\) will be tridiagonal.

2. **QR Iteration on \(H\)**:
   - Perform QR decomposition on \(H\): \(H = QR\).
   - Update: \(H \leftarrow RQ\).
   - The matrix \(H\) remains tridiagonal through each iteration, preserving the computational efficiency.

3. **Eigenvalue Convergence**:
   - Iterate until \(H\) converges to an upper triangular form, where the diagonal elements approximate the eigenvalues of the original matrix \(A\).

## Advantages Summarized

1. **Reduced Computational Complexity**: Fewer operations due to sparsity.
2. **Maintenance of Structure**: Hessenberg form is preserved through iterations.
3. **Improved Numerical Stability**: Less error accumulation and better orthogonality preservation.
4. **Efficient Eigenvalue Computation**: Direct application of QR iterations without increasing fill-in.

Overall, converting a matrix to upper Hessenberg form before applying the QR algorithm harnesses these benefits, leading to more efficient and stable numerical computations, particularly for large-scale problems.


---

preceding: [[krylov subspace methods]]  


following: [[tridiagonal structure]]

See also: [[error propagation]]