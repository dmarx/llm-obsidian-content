---
date: '2024-12-11T02:55:29.508754Z'
tags:
- autogenerated
- source__claude
- conversation_id__567935de-c057-4864-95bb-aefbf2902fdd
- msg_a60a43f1-57fc-4f3e-88eb-d6220c9d9f98
- msg_6851fd8c-6137-4c23-ba57-65b493d67509
- colorclass/system-dynamics
title: optimal estimation theory
---

**USER**

optimal estimation theory


**ASSISTANT**

# Optimal Estimation Theory

[[Optimal estimation theory]] provides a mathematical framework for inferring the state of a system from noisy measurements and uncertain models. It combines concepts from [[probability theory]], [[linear algebra]], and [[optimization]] to derive estimators that are optimal under specified criteria.

## Mathematical Foundations

### State Space Formulation

Consider a system with:
- State vector x ∈ ℝ^n
- Measurement vector z ∈ ℝ^m
- System model f: ℝ^n → ℝ^n
- Measurement model h: ℝ^n → ℝ^m

The general state estimation problem can be formalized as:

x_{k+1} = f(x_k) + w_k
z_k = h(x_k) + v_k

where:
- w_k represents [[process noise]]
- v_k represents [[measurement noise]]
- k denotes the discrete time index

### Optimality Criteria

Common optimality criteria include:

1. [[Minimum Mean Square Error]] (MMSE):
   E[||x - x̂||^2] → min

2. [[Maximum A Posteriori]] (MAP):
   x̂ = argmax_x p(x|z)

3. [[Maximum Likelihood]] (ML):
   x̂ = argmax_x p(z|x)

## Key Estimation Approaches

### Batch Estimation

[[Batch estimation]] processes all measurements simultaneously:

x̂ = argmin_x J(x, Z)

where:
- J is a [[cost function]]
- Z is the complete measurement history

### Recursive Estimation

[[Recursive estimation]] updates estimates sequentially:

x̂_k = g(x̂_{k-1}, z_k)

where g is an update function.

## Linear Gaussian Systems

For [[linear Gaussian systems]], the optimal estimator has a closed form:

### System Model
x_{k+1} = Fx_k + w_k
z_k = Hx_k + v_k

where:
- F is the [[state transition matrix]]
- H is the [[measurement matrix]]
- w_k ~ N(0, Q)
- v_k ~ N(0, R)

### Optimal Solution
The [[Kalman filter]] provides the optimal solution with:
- [[Prediction step]]: x̂_k^- = Fx̂_{k-1}
- [[Update step]]: x̂_k = x̂_k^- + K_k(z_k - Hx̂_k^-)

## Nonlinear Systems

For [[nonlinear systems]], various approximation methods exist:

1. [[Extended Kalman Filter]] (EKF):
   - Linearizes about current estimate
   - Uses Jacobian matrices

2. [[Unscented Kalman Filter]] (UKF):
   - Propagates sigma points
   - Captures higher-order moments

3. [[Particle Filter]]:
   - [[Sequential Monte Carlo]] method
   - Approximates posterior distribution

## Information Metrics

Key metrics for assessing estimator performance:

1. [[Fisher Information Matrix]]:
   I(θ) = E[∇_θ log p(z|θ)∇_θ log p(z|θ)^T]

2. [[Cramér-Rao Lower Bound]]:
   cov(θ̂) ≥ I(θ)^{-1}

3. [[Kullback-Leibler Divergence]]:
   D_KL(p||q) = ∫ p(x)log(p(x)/q(x))dx

## Applications

Optimal estimation theory finds applications in:

- [[Navigation Systems]]
- [[Target Tracking]]
- [[System Identification]]
- [[Signal Processing]]
- [[Machine Learning]]

## Advanced Topics

1. [[Robust Estimation]]:
   - Handles outliers and model uncertainties
   - Uses robust cost functions

2. [[Distributed Estimation]]:
   - Multiple sensors/estimators
   - Network constraints

3. [[Adaptive Estimation]]:
   - Time-varying parameters
   - Online parameter tuning

## See Also

- [[Bayesian Inference]]
- [[State Space Models]]
- [[Stochastic Processes]]
- [[Estimation Theory]]
- [[Filtering Theory]]


---

preceding: [[kalman gain]]