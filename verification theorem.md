---
date: 1712011153.807687
tags:
- autogenerated
- source__oai
- conversation_id__0beda6c8-c75a-44e1-b2c0-0904cd4a353a
- msg_aaa2b517-cbff-4ffc-8048-2847895ec68a
- msg_4d709825-bb88-43c0-a775-01bc4f8fe61f
- colorclass/system-dynamics
title: verification theorem
---

**USER**

verification theorem


**ASSISTANT**

The [[Verification Theorem|Verification Theorem]] plays a pivotal role in the realm of control theory and mathematical finance, particularly in the context of stochastic control problems solved via the [[Hamilton–Jacobi–Bellman Equation|Hamilton–Jacobi–Bellman (HJB) equation]]. This theorem provides a rigorous framework for validating a proposed optimal control policy and the associated value function, ensuring they indeed solve the given control problem.

### Overview

In the setting of optimal control, a control policy is a function that specifies the action to be taken in every possible state of the system. The Verification Theorem states that if a certain value function satisfies specific conditions (typically, a solution to the HJB equation under constraints), and a control policy is derived based on this value function, then this policy is indeed optimal.

### Mathematical Formulation

Consider a stochastic control problem with state dynamics governed by a stochastic differential equation (SDE):

$$dx(t) = f(x(t), u(t), t) dt + \sigma(x(t), u(t), t) dW(t),$$

where $x(t) \in \mathbb{R}^n$ is the state variable, $u(t) \in \mathbb{R}^m$ is the control variable, $f$ and $\sigma$ represent the drift and diffusion terms respectively, and $W(t)$ is a standard Brownian motion.

The objective is to minimize a cost functional of the form:

$$J(u(\cdot); x_0) = \mathbb{E} \left[ \int_{0}^{T} L(x(t), u(t), t) dt + g(x(T)) \right],$$

where $L$ is the running cost, $g$ is the terminal cost, and $T$ is the terminal time.

The Verification Theorem asserts conditions under which a smooth function $V(x,t)$, which solves the HJB equation

$$-V_t = \min_u \left\{ L(x,u,t) + V_x f(x,u,t) + \frac{1}{2} \text{tr}(\sigma \sigma^T V_{xx}) \right\},$$

with the terminal condition $V(x,T) = g(x)$, can be considered as the value function of the problem, thereby verifying the optimality of the corresponding control policy $u^*(x,t)$ that achieves the minimum in the HJB equation.

### Key Components of the Verification Theorem

- **Existence of a Smooth Solution**: The function $V(x,t)$ must be sufficiently smooth (typically, twice continuously differentiable) and satisfy the HJB equation.
- **Admissibility of the Control Policy**: The control policy derived from $V(x,t)$ must be admissible, meaning it must be feasible within the context of the problem and ensure the existence of a unique solution to the state dynamics.
- **Boundary Conditions**: The value function $V(x,t)$ must satisfy the appropriate boundary conditions, typically including the terminal condition $V(x,T) = g(x)$.

### Significance and Application

The Verification Theorem provides a crucial link between the theoretical solution of the HJB equation and its practical implementation in optimal control problems. It ensures that if a candidate solution to the HJB equation can be found, and if this solution satisfies the conditions outlined by the theorem, then the associated control policy is indeed the optimal solution to the control problem.

This theorem is extensively used in financial mathematics, for example, in the pricing and hedging of financial derivatives, as well as in engineering fields such as robotics and aerospace for trajectory optimization and control strategy verification.


---

preceding: [[hamilton–jacobi–bellman equations]]

See also: [[bellman equations]]


See also: [[control theory]]