---
date: '2025-05-06T03:41:25.775667Z'
tags:
- autogenerated
- source__claude
- conversation_id__0511aaca-7e35-4b99-9727-ba35e690dc1d
- msg_96295123-2568-469a-8eb1-71ca02911217
- msg_a28c339f-4f87-4e11-8b63-30a0407cd0c3
- colorclass/information-theory
title: koopman operator theory
---

**USER**

Koopman operator theory


**ASSISTANT**

I'll explore Koopman operator theory in depth for your knowledge base.

# Koopman Operator Theory

Koopman operator theory is a powerful mathematical framework that transforms complex, nonlinear [[dynamical systems]] into infinite-dimensional but linear systems, enabling the application of linear analysis techniques to nonlinear problems. Originally developed by [[Bernard Koopman]] in 1931, this approach has experienced a renaissance in recent decades due to its applications in [[data-driven modeling]], [[system identification]], and [[control theory]].

## Mathematical Foundation

### Definition and Basic Properties

The [[Koopman operator]] $\mathcal{K}$ is an infinite-dimensional linear operator that acts on [[observable functions]] in the space of square-integrable functions $L^2(X)$ over the [[state space]] $X$. For a dynamical system with flow map $F: X \rightarrow X$, the Koopman operator advances observables forward in time:

$$(\mathcal{K}g)(x) = g(F(x))$$

Where:
- $g: X \rightarrow \mathbb{R}$ is an observable function
- $x \in X$ is a point in state space
- $F(x)$ is the state after one time step (for discrete-time systems) or after time $t$ (for continuous-time systems)

For continuous-time systems with flow $F^t$, we can define the family of Koopman operators $\{\mathcal{K}^t\}_{t \geq 0}$ as:

$$(\mathcal{K}^t g)(x) = g(F^t(x))$$

A key property is that this family forms a [[semigroup]]:
$$\mathcal{K}^{t+s} = \mathcal{K}^t \circ \mathcal{K}^s$$

### Koopman Eigenfunctions and Eigenvalues

The [[spectral decomposition]] of the Koopman operator reveals fundamental dynamic structures. The [[Koopman eigenfunction]] $\phi_\lambda: X \rightarrow \mathbb{C}$ associated with eigenvalue $\lambda$ satisfies:

$$\mathcal{K}\phi_\lambda = \lambda \phi_\lambda$$

For continuous-time systems, this becomes:
$$\mathcal{K}^t \phi_\lambda = e^{\lambda t} \phi_\lambda$$

Where the eigenvalues $\lambda$ are generally complex numbers with:
- Real part representing growth/decay rates
- Imaginary part representing oscillation frequencies

The eigenfunctions serve as [[intrinsic coordinates]] for the system, capturing coherent dynamic patterns.

### Koopman Mode Decomposition

Any observable function $g \in L^2(X)$ can be expanded in terms of Koopman eigenfunctions:

$$g(x) = \sum_{j} v_j \phi_j(x) + \int_{\sigma_c} v(\lambda)\phi_\lambda(x) d\mu(\lambda)$$

Where:
- $\phi_j$ are eigenfunctions corresponding to discrete eigenvalues
- $v_j$ are the associated [[Koopman modes]]
- The integral represents the continuous spectrum contribution
- $\sigma_c$ is the continuous spectrum
- $\mu$ is a spectral measure

For vector-valued observables $\mathbf{g} = [g_1, g_2, \ldots, g_m]^T$, we obtain vector-valued Koopman modes $\mathbf{v}_j$.

## Computational Approaches

### Dynamic Mode Decomposition

[[Dynamic Mode Decomposition]] (DMD) provides a finite-dimensional approximation to the Koopman operator from data. For a sequence of snapshots $\{\mathbf{x}_0, \mathbf{x}_1, \ldots, \mathbf{x}_N\}$, DMD:

1. Arranges the data into matrices:
   $$\mathbf{X} = [\mathbf{x}_0, \mathbf{x}_1, \ldots, \mathbf{x}_{N-1}]$$
   $$\mathbf{Y} = [\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_N]$$

2. Computes the best-fit linear operator $\mathbf{A}$ such that:
   $$\mathbf{Y} \approx \mathbf{A} \mathbf{X}$$

3. Performs [[eigendecomposition]] of $\mathbf{A}$ to find DMD modes and eigenvalues

The [[DMD modes]] approximate the Koopman modes, and the DMD eigenvalues approximate the Koopman eigenvalues.

### Extended Dynamic Mode Decomposition

[[Extended Dynamic Mode Decomposition]] (EDMD) expands the state space using a dictionary of observables $\{\psi_1, \psi_2, \ldots, \psi_K\}$ to better capture nonlinear dynamics:

1. Defines the lifted state:
   $$\mathbf{g}(x) = [\psi_1(x), \psi_2(x), \ldots, \psi_K(x)]^T$$

2. Constructs data matrices in the lifted space:
   $$\mathbf{G} = [\mathbf{g}(x_0), \mathbf{g}(x_1), \ldots, \mathbf{g}(x_{N-1})]$$
   $$\mathbf{H} = [\mathbf{g}(x_1), \mathbf{g}(x_2), \ldots, \mathbf{g}(x_N)]$$

3. Computes the finite-dimensional approximation of the Koopman operator:
   $$\mathbf{K} = \mathbf{H}\mathbf{G}^{\dagger}$$
   
   Where $\mathbf{G}^{\dagger}$ is the [[Moore-Penrose pseudoinverse]].

### Kernel-Based Methods

[[Kernel DMD]] replaces explicit feature vectors with a [[kernel function]] $k(x,y)$ that computes inner products in a high-dimensional (potentially infinite-dimensional) feature space:

$$k(x,y) = \langle \mathbf{g}(x), \mathbf{g}(y) \rangle$$

This allows EDMD to be performed implicitly in the feature space without explicitly computing the feature vectors, using the [[kernel trick]]:

$$\mathbf{K} = \mathbf{\Psi}_Y(\mathbf{\Psi}_X^T \mathbf{\Psi}_X)^{-1}\mathbf{\Psi}_X^T$$

Where $\mathbf{\Psi}_X$ and $\mathbf{\Psi}_Y$ are matrices with entries $[\mathbf{\Psi}_X]_{ij} = k(x_i, x_j)$ and $[\mathbf{\Psi}_Y]_{ij} = k(y_i, x_j)$.

## Theoretical Extensions

### Generator of the Koopman Semigroup

For continuous-time systems, the [[Koopman generator]] $\mathcal{L}$ is defined as:

$$\mathcal{L} = \lim_{t \rightarrow 0} \frac{\mathcal{K}^t - \mathcal{I}}{t}$$

For a system with dynamics $\dot{x} = f(x)$, the generator acts as a differential operator:

$$(\mathcal{L}g)(x) = \nabla g(x) \cdot f(x)$$

This is the [[Lie derivative]] of $g$ along the vector field $f$.

### Relationship to Perron-Frobenius Operator

The [[Perron-Frobenius operator]] $\mathcal{P}$ is the dual of the Koopman operator, acting on probability density functions rather than observables:

$$\int_X (\mathcal{K}g)(x) \rho(x) dx = \int_X g(x) (\mathcal{P}\rho)(x) dx$$

For all observables $g$ and densities $\rho$.

For a system with flow map $F$, the Perron-Frobenius operator evolves densities according to:

$$(\mathcal{P}\rho)(y) = \int_X \rho(x) \delta(y - F(x)) dx$$

Where $\delta$ is the [[Dirac delta function]].

### Koopman Theory for Control Systems

For a controlled system $\dot{x} = f(x, u)$, the Koopman operator becomes input-dependent:

$$\mathcal{K}_u g(x) = g(F_u(x))$$

Where $F_u$ is the flow map under control input $u$.

Recent work has developed the [[bilinear Koopman representation]]:

$$\frac{d}{dt}\mathbf{z}(t) = \mathbf{A}\mathbf{z}(t) + \sum_{j=1}^m u_j(t)\mathbf{B}_j\mathbf{z}(t)$$

Where $\mathbf{z}(t)$ is the vector of observable functions, $\mathbf{A}$ represents the uncontrolled dynamics, and $\mathbf{B}_j$ captures the effect of control input $u_j$.

## Applications

### Fluid Dynamics

In [[fluid dynamics]], Koopman analysis identifies [[coherent structures]] and [[modal decompositions]]:

1. **[[Flow separation]]**: Koopman modes capture the dominant spatial patterns
2. **[[Periodic shedding]]**: Eigenvalues corresponding to oscillatory dynamics
3. **[[Transition to turbulence]]**: Spectrum changes indicating bifurcations
4. **[[Reduced-order modeling]]**: Low-dimensional representations preserving key dynamics

### Power Systems

In [[power grid analysis]], Koopman methods provide:

1. **[[Stability assessment]]**: Eigenvalues indicate system stability margins
2. **[[Mode identification]]**: Koopman modes reveal coherent oscillation patterns
3. **[[Precursor detection]]**: Early warning indicators for critical transitions
4. **[[Model reduction]]**: Simplified representations capturing essential dynamics

### Neuroscience

Applications in [[neuroscience]] include:

1. **[[Neural dynamics]]**: Extracting fundamental spatiotemporal patterns
2. **[[State-space reconstruction]]**: From limited measurements of neural activity
3. **[[Functional connectivity]]**: Identifying dynamically linked neural regions
4. **[[Cognitive state transitions]]**: Detecting shifts between mental states

### Molecular Dynamics

In [[molecular dynamics]], Koopman analysis provides:

1. **[[Reaction coordinates]]**: Eigenfunctions representing [[slow degrees of freedom]]
2. **[[Metastable states]]**: Identification of long-lived conformational states
3. **[[Transition pathways]]**: Dominant paths between stable configurations
4. **[[Markov state models]]**: Connection to discrete state representations

## Advanced Topics

### Stochastic Systems

For [[stochastic systems]], the Koopman operator describes the evolution of [[expected observables]]:

$$(\mathcal{K}g)(x) = \mathbb{E}[g(X_{t+1}) | X_t = x]$$

The corresponding generator for continuous-time stochastic processes is the [[backward Kolmogorov operator]]:

$$\mathcal{L}g = \sum_i b_i(x) \frac{\partial g}{\partial x_i} + \frac{1}{2} \sum_{i,j} a_{ij}(x) \frac{\partial^2 g}{\partial x_i \partial x_j}$$

Where $b_i$ are drift coefficients and $a_{ij}$ are diffusion coefficients.

### Data-Driven Forecasting

The Koopman framework enables forecasting through:

$$g(x_{t+n}) = (\mathcal{K}^n g)(x_t) \approx \sum_j \lambda_j^n v_j \phi_j(x_t)$$

This provides a principled approach to [[predictive modeling]] for complex systems.

### Machine Learning Approaches

Recent advances couple Koopman theory with [[machine learning]]:

1. **[[Deep Koopman models]]**: Using neural networks to learn Koopman embeddings:
   $$\phi(x) = \text{Encoder}(x)$$
   $$\phi(F(x)) = \mathbf{K}\phi(x)$$
   $$\hat{x} = \text{Decoder}(\phi(x))$$

2. **[[Sparse identification]]**: Finding parsimonious representations of the Koopman operator

3. **[[Variational approaches]]**: Optimizing the Koopman approximation via variational principles

4. **[[Reservoir computing]]**: Using recurrent neural networks for Koopman approximation

## Numerical Considerations

### Choice of Observable Functions

The selection of observables critically impacts the quality of Koopman approximations:

1. **[[Polynomial observables]]**: $\psi_j(x) = x_1^{p_1} x_2^{p_2} \cdots x_n^{p_n}$
2. **[[Radial basis functions]]**: $\psi_j(x) = \exp(-\gamma \|x - c_j\|^2)$
3. **[[Fourier bases]]**: $\psi_j(x) = \exp(i k_j \cdot x)$
4. **[[Learned dictionaries]]**: Data-driven basis selection

### Regularization Techniques

[[Regularization]] methods improve robustness:

1. **[[Tikhonov regularization]]**: $\mathbf{K} = \mathbf{H}\mathbf{G}^T(\mathbf{G}\mathbf{G}^T + \alpha \mathbf{I})^{-1}$
2. **[[Sparsity-promoting methods]]**: Enforcing sparse Koopman representations
3. **[[Cross-validation]]**: Determining optimal regularization parameters
4. **[[Energy-based filtering]]**: Retaining only energetically significant modes

### Computational Complexity

Scalability considerations include:

1. **[[Dimensionality reduction]]**: Pre-processing with PCA or other techniques
2. **[[Randomized methods]]**: Approximate matrix factorizations
3. **[[Incremental algorithms]]**: Online updating of Koopman approximations
4. **[[Parallelization strategies]]**: Distributing computation across cores/nodes

## Theoretical Connections

### Relationship to Other Frameworks

Koopman theory connects to several mathematical frameworks:

1. **[[Transfer operators]]**: Koopman and Perron-Frobenius as complementary perspectives
2. **[[Spectral theory]]**: Connections to functional analysis and operator theory
3. **[[Ergodic theory]]**: Links to mixing properties and invariant measures
4. **[[Lie algebra theory]]**: Generator as element of dynamical Lie algebra

### Geometric Interpretation

From a [[geometric perspective]], Koopman eigenfunctions define:

1. **[[Isochrons]]**: Level sets of eigenfunctions as generalized phase concepts
2. **[[Invariant manifolds]]**: Zero level sets of specific eigenfunctions
3. **[[Coherent sets]]**: Regions with similar dynamic evolution
4. **[[Lagrangian coherent structures]]**: Transport barriers in flow fields

## Recent Developments and Frontiers

### Data-Driven Coordinate Systems

[[Data-driven coordinates]] based on Koopman eigenfunctions provide:

1. **[[Intrinsic parameterizations]]**: Coordinates adapted to system dynamics
2. **[[Slow manifolds]]**: Subspaces corresponding to slowly evolving dynamics
3. **[[Separatrices]]**: Boundaries between dynamical regimes
4. **[[Linearizing transformations]]**: Maps that render nonlinear dynamics linear

### Koopman Theory for Hybrid Systems

Extensions to [[hybrid systems]] with both continuous and discrete dynamics:

$$\mathcal{K} = \sum_i \chi_i \mathcal{K}_i + \sum_{i,j} \delta_{ij} \mathcal{T}_{ij}$$

Where $\chi_i$ are indicator functions for different regimes, $\mathcal{K}_i$ are regime-specific Koopman operators, and $\mathcal{T}_{ij}$ are transition operators.

### Information-Theoretic Perspectives

[[Information-theoretic measures]] provide insights into:

1. **[[Predictive information]]**: Future predictability quantified via mutual information
2. **[[Transfer entropy]]**: Directional information flow in multivariate systems
3. **[[Entropy production]]**: Irreversibility in Koopman dynamics
4. **[[Information bottleneck]]**: Optimal compression preserving predictive power

## Related Mathematical Concepts

- [[Operator theory]]
- [[Functional analysis]]
- [[Dynamical systems]]
- [[Spectral theory]]
- [[Modal decomposition]]
- [[Ergodic theory]]
- [[Transfer operators]]
- [[Invariant manifolds]]
- [[Data-driven modeling]]
- [[System identification]]


---

preceding: [[imaginary frequency]]  


following: [[perron-frobenius operator]]

See also: [[koopman operator]]


See also: [[mutual information]]


See also: [[stochastic processes]]


See also: [[operator theory]]


See also: [[vector field]]


See also: [[system dynamics]]