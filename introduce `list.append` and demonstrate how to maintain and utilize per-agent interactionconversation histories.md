---
date: 1726441003.292677
tags:
- autogenerated
- source__oai
- conversation_id__66e757d1-0534-8008-bb6a-afa8342b5ee2
- msg_aaa28eaa-46d9-4683-adb7-2919ca92eb38
- msg_d7f91be3-1771-4ec4-a941-43a46fea4233
- colorclass/edge-case
title: introduce `list.append` and demonstrate how to maintain and utilize per-agent
  interactionconversation histories
---

**USER**

introduce `list.append` and demonstrate how to maintain and utilize per-agent interaction/conversation histories


**ASSISTANT**

Great! Now that students have a basic understanding of **classes** and how to define an **agent**, we can introduce **`list.append`** to demonstrate how to maintain a per-agent **interaction history** or **conversation log**. This is a natural extension of the `Agent` abstraction, as each agent can keep track of its interactions with the OpenAI model, making the conversation dynamic and contextual.

The primary goal here is to show students how to store multiple pieces of data (prompts, responses) over time using a **list** and how to update that list using the `list.append()` method.

---

### **Tenth Assignment: Maintaining Conversation History with `list.append`**

### **Objective**:
1. Introduce the **`list.append`** method to maintain a history of interactions (prompts and responses) for each agent.
2. Show how to **store**, **update**, and **retrieve** conversation logs for each agent.
3. Demonstrate how to utilize the conversation history during subsequent interactions, creating a context-aware agent.

### **Step 1: Introducing `list.append`**

First, explain the basics of `list.append()`. Lists are dynamic collections in Python that allow you to store multiple items. The `append()` method adds an element to the end of a list.

#### **Simple Example of `list.append()`**:
```python
# Create an empty list
history = []

# Append items to the list
history.append("Hello")
history.append("How are you?")
history.append("I'm fine, thanks!")

# Print the history
print(history)
```

**Output**:
```bash
['Hello', 'How are you?', "I'm fine, thanks!"]
```

This basic principle will be used to track interactions (prompts and responses) for each agent.

---

### **Step 2: Extending the `Agent` Class to Track History**

We can now extend the `Agent` class to maintain a **conversation history**. The history will be stored in a list, and each time the agent interacts with the OpenAI model, both the prompt and response will be appended to this list.

#### **Updated `Agent` Class with Conversation History**:

```python
import openai
from jinja2 import Template

# Extend the Agent class to maintain a conversation history
class Agent:
    def __init__(self, name, system_prompt_template):
        self.name = name
        self.system_prompt_template = system_prompt_template
        self.history = []  # Initialize an empty list to track conversation history
    
    def get_system_prompt(self):
        template = Template(self.system_prompt_template)
        return template.render(name=self.name)
    
    def query_openai(self, prompt, max_tokens=50, temperature=0.7, top_p=1.0, **kwargs):
        """
        Send a prompt to the OpenAI API and maintain conversation history.

        Arguments:
        - prompt: The specific prompt for this interaction.
        - max_tokens: Maximum number of tokens to generate.
        - temperature: Controls randomness in the output.
        - top_p: Controls diversity of word choices.
        - **kwargs: Additional options to pass to the OpenAI API.

        Returns:
        - The response from the OpenAI API.
        """
        # Add the prompt to the history before making the API call
        self.history.append({"prompt": prompt})
        
        # Make the API call
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            **kwargs
        )
        
        # Extract the text from the API response
        response_text = response.choices[0].text.strip()

        # Add the response to the history
        self.history.append({"response": response_text})
        
        return response_text
    
    def get_history(self):
        """
        Retrieve the conversation history.
        
        Returns:
        - A list of all prompts and responses for this agent.
        """
        return self.history
```

### **Explanation**:

1. **`self.history = []`**: 
   - We initialize an empty list called `history` for each agent. This will store the conversation as a sequence of dictionaries, where each entry contains either a prompt or a response.
   
2. **`list.append()`**:
   - In the `query_openai()` method, before sending the prompt to the API, we append the prompt to the agent's `history` using `self.history.append({"prompt": prompt})`.
   - After receiving the API response, we append the response to the `history` using `self.history.append({"response": response_text})`.

3. **`get_history()`**:
   - This method returns the entire conversation history for the agent. It’s useful for retrieving all interactions (prompts and responses) when needed.

---

### **Step 3: Using the Agent Class with History Tracking**

Now, we can create agents, interact with them using the OpenAI model, and maintain the conversation history for each agent.

#### **Example Usage**:

```python
# Define different system prompt templates for each agent
agent1_template = "Hello, my name is {{ name }}. I specialize in research."
agent2_template = "Hi, I'm {{ name }}. I'm great at creative writing."

# Create two agents
agent1 = Agent(name="Alice", system_prompt_template=agent1_template)
agent2 = Agent(name="Bob", system_prompt_template=agent2_template)

# Agent 1 interacts with the model
response1 = agent1.query_openai(prompt="Tell me about quantum mechanics.", max_tokens=100)
print(f"Alice's response: {response1}")

# Agent 2 interacts with the model
response2 = agent2.query_openai(prompt="Write me a short story about space.", max_tokens=100)
print(f"Bob's response: {response2}")

# Agent 1 asks a follow-up question
response3 = agent1.query_openai(prompt="How does quantum mechanics relate to black holes?", max_tokens=100)
print(f"Alice's follow-up response: {response3}")

# Print conversation history for each agent
print("\nAlice's conversation history:")
for entry in agent1.get_history():
    print(entry)

print("\nBob's conversation history:")
for entry in agent2.get_history():
    print(entry)
```

#### **Expected Output**:
```bash
Alice's response: Quantum mechanics is a fundamental theory in physics that describes physical properties of nature at the scale of atoms and subatomic particles...

Bob's response: Once upon a time, in the far reaches of space, there lived a group of explorers who journeyed beyond the stars...

Alice's follow-up response: Quantum mechanics and black holes are connected through various principles of modern physics...

Alice's conversation history:
{'prompt': 'Tell me about quantum mechanics.'}
{'response': 'Quantum mechanics is a fundamental theory in physics...'}
{'prompt': 'How does quantum mechanics relate to black holes?'}
{'response': 'Quantum mechanics and black holes are connected through...'}

Bob's conversation history:
{'prompt': 'Write me a short story about space.'}
{'response': 'Once upon a time, in the far reaches of space...'}
```

### **Explanation**:

1. **Conversation History**:
   - Each agent stores its interactions (both prompts and responses) in its `history` attribute. For example, Alice’s conversation history contains her initial question about quantum mechanics, her follow-up question about black holes, and the corresponding responses from the model.
   
2. **Using `list.append()`**:
   - We append each prompt and response to the history as they occur, allowing us to maintain a running log of the entire conversation. This is especially useful in conversational agents where context is important.

3. **Retrieving History**:
   - The `get_history()` method allows us to retrieve and display the entire interaction history for each agent, showing both the prompts and responses in sequence.

---

### **Step 4: Using History in Future Interactions**

One of the key benefits of maintaining a conversation history is that it allows for context-aware interactions. For example, we could use the history to construct more complex, contextually-aware prompts by referencing previous exchanges.

#### **Example**:
```python
def build_contextual_prompt(agent):
    """
    Builds a contextual prompt by concatenating the agent's conversation history.
    
    Arguments:
    - agent: The agent whose history we are using.
    
    Returns:
    - A prompt that includes the agent's past prompts and responses.
    """
    context = ""
    for entry in agent.get_history():
        if "prompt" in entry:
            context += f"User: {entry['prompt']}\n"
        elif "response" in entry:
            context += f"Agent: {entry['response']}\n"
    return context

# Build a contextual prompt for Alice
contextual_prompt = build_contextual_prompt(agent1)
print(f"\nAlice's contextual prompt:\n{contextual_prompt}")

# Alice asks a new question with context
new_response = agent1.query_openai(prompt=contextual_prompt + "What is the role of quantum entanglement?", max_tokens=100)
print(f"Alice's new response: {new_response}")
```

---

### **Learning Outcomes**:

1. **Using `list.append()`**:
   - Students learn how to maintain a dynamic list of interaction data using `list.append()`.
   
2. **Tracking Conversation History**:
   - By appending both prompts and responses, students see how to maintain a running log of interactions, which can be retrieved and used later.

3. **Contextual Conversations**:
   - Students are introduced to the idea of context-aware conversations, where past interactions are used to build more informative and relevant responses in subsequent queries.

---

### **Summary**:

In this assignment


---

preceding: [[introduce classes through the context of a simple `agent` abstraction, where we assign each agent a system prompt and a name, and use  jinja to resolve each respective agent's system prompt]]  


following: [[we glossed over system prompt previously. let's dive deeper into what that is, how it works, what to expect with respect to pre-existing system prompts embedded in product apis the learner may interac]]