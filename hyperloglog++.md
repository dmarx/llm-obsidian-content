---
date: 1725830676.645415
tags:
- autogenerated
- source__oai
- conversation_id__66de140c-9b4c-8008-9479-3ee3815ba4e8
- msg_aaa22602-fd0f-4ffc-8382-c465073db73c
- msg_df995dcc-0b76-498a-b9fc-a3b4ec3d5224
- colorclass/vector-space
title: hyperloglog++
---

**USER**

HLL++


**ASSISTANT**

### HyperLogLog++

#### Overview

**HyperLogLog++ (HLL++)** is an improvement over the original **HyperLogLog (HLL)** algorithm, primarily designed to enhance the accuracy and address some of the biases in HLL's cardinality estimation. HLL++ offers better performance, especially in terms of handling small and large cardinalities, while maintaining the space-efficiency that makes HyperLogLog useful in large-scale systems.

HLL++ was introduced by Google in 2013 as a refined version of HLL. It incorporates several key optimizations, including **better bias correction** and **sparse representation** for small cardinalities, which allows the algorithm to offer both higher accuracy and improved memory efficiency in practical applications.

#### Enhancements in HyperLogLog++
The key improvements in HLL++ over the original HyperLogLog include:

1. **Bias Correction with Empirical Data**:
   - HLL uses a theoretical bias correction factor, which results in biased estimates, especially for large cardinalities.
   - HLL++ replaces this with a correction method based on **empirical measurements** of bias, derived from large-scale simulations of hash functions. This empirical bias correction reduces the error in the estimation, particularly when the cardinality is large.

2. **Improved Small-Range Estimation with Sparse Representation**:
   - When the cardinality of the set is small, HyperLogLog++ switches to a **sparse representation**, which uses significantly less memory compared to the original algorithm. 
   - In this mode, rather than maintaining the full set of registers, HLL++ keeps a list of the actual hash values seen so far, and directly counts the distinct elements when the cardinality is low.
   - This technique allows HLL++ to consume less memory in cases where only a few distinct elements have been encountered, transitioning to the full register-based HLL mode only when the number of distinct elements becomes large enough.

3. **Better Handling of Large Cardinalities**:
   - When estimating large cardinalities, HLL++ uses **extended precision registers** to mitigate the estimation errors caused by the original algorithm's use of finite-length hash functions. This allows the algorithm to make more accurate estimates for extremely large datasets, where the original HLL might encounter bias due to register overflow or hash collisions.
   - The improved error control in this case leads to reduced variance in estimates for very large datasets, typically in the range of billions of unique elements.

#### How HyperLogLog++ Works

The overall structure and workflow of HyperLogLog++ remains similar to that of the original HyperLogLog algorithm, but with the key refinements mentioned above.

1. **Hashing**:
   - As in HLL, each element $s \in S$ is hashed to a bitstring using a high-quality hash function. The hash is split into two parts:
     - The first $p$ bits are used to index the array of registers.
     - The remaining bits are used to track the position of the **first 1-bit**, which is used to estimate the cardinality.

2. **Sparse Mode**:
   - For small datasets, HLL++ operates in **sparse mode**, where the algorithm tracks the raw hash values in a compressed format. This allows it to avoid allocating memory for the full set of registers when the dataset is small (e.g., when the number of distinct elements is below a certain threshold).
   - When the cardinality crosses a predefined threshold, HLL++ transitions to the standard **dense mode**, where it maintains a full set of registers.

3. **Register Update**:
   - In dense mode, as with HLL, each hashed value updates the corresponding register by storing the maximum position of the first 1-bit found in the hash. The update rule is:
     $$ M[i] = \max(M[i], \rho(h(s))) $$
   - Here, $\rho(h(s))$ represents the position of the first 1-bit in the hash of element $s$, and $M[i]$ is the $i$-th register.

4. **Cardinality Estimation**:
   - After processing all the elements, HLL++ estimates the cardinality using the harmonic mean of the register values, just like HLL:
     $$ \hat{n} = C_m \cdot m^2 \cdot \left( \sum_{i=1}^{m} 2^{-M[i]} \right)^{-1} $$
   - However, HLL++ applies a more sophisticated **bias correction** that is empirically derived from large-scale simulations, which allows for greater accuracy in practice.

5. **Improved Bias Correction**:
   - The bias correction function in HLL++ is based on empirical data rather than theoretical estimates, which results in more accurate estimates, especially for large datasets. This correction is crucial when cardinalities exceed millions, where the original HLL may begin to suffer from biases.

#### Memory Efficiency and Performance

- **Sparse Mode**: In sparse mode, HLL++ uses very little memory since it only tracks individual hash values, making it far more efficient than the dense representation used by the original HLL for small datasets.
  
- **Dense Mode**: When in dense mode, HLL++ has the same memory footprint as the original HLL. However, due to the improvements in bias correction and handling of large cardinalities, it produces more accurate results for the same memory usage.

- **Time Complexity**: The time complexity of HLL++ remains the same as HLL, with $O(1)$ insertions and $O(m)$ complexity for merging or estimating cardinality. Here, $m = 2^p$ is the number of registers in the dense mode.

#### Error Rate

Like HLL, the relative error of HLL++ is still determined by the number of registers $m$, but with the added improvements, the empirical error is slightly lower in most cases. The relative error for HLL++ is still approximately:
$$ \text{Relative Error} \approx \frac{1.04}{\sqrt{m}} $$

However, the error rate is generally improved due to the empirical bias correction and enhanced handling of sparse and large data regimes.

#### Applications

- **Web Analytics**: Counting unique visitors to websites with much higher accuracy in cases where visitors may number in the millions or billions.
- **Database Systems**: For distinct counting in large databases, especially in high-throughput systems.
- **Network Monitoring**: Estimating unique IP addresses or other identifiers in high-volume network traffic analysis.
- **Distributed Systems**: HyperLogLog++ is highly mergeable, meaning estimates from multiple systems can be combined efficiently, making it ideal for distributed data processing platforms like [[MapReduce]] or [[Apache Spark]].

#### Comparison with Other Methods

- **Bloom Filters**: HLL++ focuses on cardinality estimation, whereas Bloom filters are designed for set membership testing.
- **Original HyperLogLog**: HLL++ offers better accuracy, especially for small and large cardinalities, and introduces a sparse representation for memory efficiency.
- **MinHash**: While both algorithms are used for estimating properties of sets, MinHash is used for **set similarity** estimation (e.g., Jaccard index), whereas HLL++ is optimized for **distinct counting**.

#### Conclusion

**HyperLogLog++** significantly enhances the accuracy and memory efficiency of the original HyperLogLog algorithm by incorporating empirical bias correction and a sparse representation for small datasets. It has become a widely adopted technique in large-scale data systems where efficient and accurate cardinality estimation is critical. Its ability to handle billions of unique elements while using a small, constant amount of memory makes it indispensable in real-world applications.

#### Related Concepts
- [[HyperLogLog]]
- [[Cardinality Estimation Algorithms]]
- [[Sparse Representation]]
- [[Probabilistic Data Structures]]


---

preceding: [[hyperloglog algorithm]]